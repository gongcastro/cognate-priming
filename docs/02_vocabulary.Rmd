---
title: "Vocabulary"
output: github_document
always_allow_html: true
date: "`r paste0('Updated: ', format(Sys.Date(), '%d/%m/%Y'))`"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = TRUE,
	warning = TRUE, 
	cache.extra = knitr::rand_seed,
	out.width = "80%",
	results = "asis",
	dpi = 300,
	dev.args = list(png = list(type = "cairo"))
)
options(
	knitr.kable.NA = '-',
	knitr.duplicate.label = "allow",
	ggplot2.discrete.fill = ggsci::pal_futurama()(7),
	ggplot2.discrete.slab_color = ggsci::pal_futurama()(7),
	ggplot2.discrete.colour = ggsci::pal_futurama()(7)
)


```


```{r params, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

# load objects
tar_load_globals()
tar_load_all()

theme_set(theme_minimal()) # in utils.R

attrition <- attrition %>% 
	mutate(
		valid_gaze = valid_gaze_prime & valid_gaze_target,
		valid_status = case_when(
			!valid_vocab ~ "Invalid vocabulary",
			!valid_gaze ~ "Invalid gaze",
			!valid_participant ~ "Invalid participant",
			TRUE ~ "Valid"
		))


participants <- participants %>% 
	left_join(distinct(attrition, participant, age_group, valid_participant)) %>% 
	drop_na(participant) %>% 
	left_join(vocabulary) %>% 
	mutate(vocab_size_l1_center = scale(vocab_size_l1)[,1]) %>% 
	filter(location=="Barcelona")
```


We collected vocabulary data from participants. In Oxford, participants were sent the online version of the Oxford Communicative Development Inventory [OCDI; @hamilton2000] two weeks before each appointment. In Barcelona, participants were sent the online vocabulary inventory [MultiLex](https://github.com/gongcastro/multilex) immediately after the appointment, and were given two weeks to fill it. In Oxford, families filled the vocabulary checklist in the testing language, and when the participant was monolingual, also in the second language. In Barcelona, all participants filled the Catalan and the Spanish versions of the vocabulary checklists. All checklists included the words involved in the trial lists. When filling the vocabulary checklist, families checked each word as being *understood*, *understood and produced* or *none*. Each response to either checklist was aggregated to produce several vocabulary measures:

* **Total vocabulary**: total number of words the child knows, summing up both languages. For instance, a child who knows 210 words in Catalan and 100 words in Spanish would have a total vocabulary size of 210 words.
* **L1 vocabulary**: number of words the child knows in the languages of higher exposure (i.e., testing language). For instance, for a child exposed to 75% Catalan who knows 210 words in Catalan and 100 words in Spanish, their L1 vocabulary size would be 210 words.
* **Conceptual vocabulary**: number of lexicalised concepts, that is, the number of concepts for which the child knows a word in at least one of the languages. For example, a Catalan-Spanish bilingual that knows *taula* and *mesa* -- Catalan and Spanish translations of *table*-- would have a conceptual vocabulary size of 1.

Vocabulary sizes of participants whose families failed to complete the vocabulary checklists were imputed, by assigning them the most likely vocabulary size from a distribution of vocabulary sizes of children of similar age ($\pm$ 1 month) and language profile (similar exposure to a second language, $\pm$ 10%) that completed the same vocabulary checklist previously.


# L1 vocabulary

This figure represents the vocabulary size in the dominant language of participants in the Y-axis and their linguistic profile in the X-axis. Results are presented separately for each age group. The shape of the violins, represents the distribution of the vocabulary sizes. The box-plot inside each violin represents the median, 25th and 75th percentiles, and the vertical lines represent the minimum and maximum values. vocabulary sizes in the dominant language were calculated as the proportion of items each participant was reported to *understand* or *understand and say* in the language of most exposure. for example, for a participant exposed mostly to Catalan, their vocabulary size in the dominant language was calculated as the proportion of words they were reported to understand and/or say in Catalan, from a total of ~200 words.

```{r vocabulary_l1, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=4}
sample_size <- participants %>% 
	filter(
		participant %in% fit_l1_4$data$participant
	) %>% 
	count(age_group, location)

sample_size_lp <- participants %>% 
	filter(
		participant %in% fit_l1_4$data$participant
	) %>% 
	count(age_group, lp, location) %>% 
	mutate(
		age_group = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) 

# vocabulary
participants %>% 
	mutate(
		age_group = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) %>% 
	drop_na(lp) %>%
	filter(valid_participant) %>% 
	ggplot() +
	facet_wrap(~age_group, scales = "free_x") +
	geom_hline(yintercept = 0.5, colour = "black", linetype = "dotted") +
	stat_pointinterval(
		aes(lp, vocab_size_l1, group = lp),
		position = position_nudge(x = 0.2),
		.width = c(0.95, 0.89, 0.50),
		point_size = 3
	) +
	geom_point(
		aes(lp, vocab_size_l1, color = lp),
		shape = 1, size = 3, stroke = 1.5, alpha = 0.75,
		position = position_jitter(width = 0.1, seed = 888)
	) +
	geom_text(
		data = sample_size_lp,
		aes(x = 1.5, y = 0, label = paste0("N = ", n), group = lp),
		show.legend = FALSE, position = position_dodge(width = 2)
	) +
	labs(
		y = "Receptive vocabulary (L1)", colour = "Group", fill = "Group",
		title = "L1 vocabulary size",
		subtitle = "Percentage of words in L1 reported to be understood from the vocabulary checklist"
	) +
	guides(colour = "none") +
	scale_color_manual(aesthetics = "slab_color", values = pal_futurama()(2)) +
	scale_y_continuous(limits = c(0, 1), labels = percent) +
	theme(
		legend.title = element_blank(),
		legend.position = "top",
		panel.grid.major.x = element_blank(),
		axis.title.x = element_blank(),
		axis.text = element_text(size = 9)
	)

ggsave(here("img", "vocab_l1.png"))

```


# Total vocabulary

```{r vocabulary_total, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=4}
sample_size <- participants %>% 
	filter(participant %in% fit_total_4$data$participant) %>% 
	count(age_group, location)

sample_size_lp <- participants %>% 
	filter(participant %in% fit_total_4$data$participant) %>% 
	count(age_group, lp, location) %>% 
	mutate(
		age_group = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) 

# vocabulary
participants %>% 
	mutate(
		age_group = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) %>% 
	drop_na(lp) %>%
	filter(valid_participant) %>% 
	ggplot() +
	facet_wrap(~age_group, scales = "free_x") +
	geom_hline(yintercept = 0.5, colour = "black", linetype = "dotted") +
	stat_pointinterval(
		aes(lp, vocab_size_total, group = lp),
		position = position_nudge(x = 0.2),
		.width = c(0.95, 0.89, 0.50),
		point_size = 3
	) +
	geom_point(
		aes(lp, vocab_size_total, color = lp),
		shape = 1, size = 3, stroke = 1.5, alpha = 0.75,
		position = position_jitter(width = 0.1, seed = 888)
	) +
	geom_text(
		data = sample_size_lp,
		aes(x = 1.5, y = 0, label = paste0("N = ", n), group = lp),
		show.legend = FALSE, position = position_dodge(width = 2)
	) +
	labs(
		y = "Receptive vocabulary (total)", colour = "Group", fill = "Group",
		title = "Total vocabulary size",
		subtitle = "Percentage of words in L1+L2 reported to be understood from the vocabulary checklist"
	) +
	guides(colour = "none") +
	scale_color_manual(aesthetics = "slab_color", values = pal_futurama()(2)) +
	scale_y_continuous(limits = c(0, 1), labels = percent) +
	theme(
		legend.title = element_blank(),
		legend.position = "top",
		panel.grid.major.x = element_blank(),
		axis.title.x = element_blank(),
		axis.text = element_text(size = 9)
	)

ggsave(here("img", "vocab_total.png"))
```


# Conceptual vocabulary


```{r vocabulary_conceptual, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=4}
sample_size <- participants %>% 
	filter(valid_participant, !is.na(vocab_size_conceptual)) %>% 
	count(age_group, location)

sample_size_lp <- participants %>% 
	filter(valid_participant, !is.na(vocab_size_total)) %>% 
	count(age_group, lp, location) %>% 
	mutate(
		age_group = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) 

# vocabulary
participants %>% 
	mutate(
		age_group = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) %>% 
	drop_na(lp) %>%
	filter(valid_participant) %>% 
	ggplot() +
	facet_wrap(~age_group, scales = "free_x") +
	geom_hline(yintercept = 0.5, colour = "black", linetype = "dotted") +
	stat_pointinterval(
		aes(lp, vocab_size_conceptual, group = lp),
		position = position_nudge(x = 0.2),
		.width = c(0.95, 0.89, 0.50),
		point_size = 3
	) +
	geom_point(
		aes(lp, vocab_size_conceptual, color = lp),
		shape = 1, size = 3, stroke = 1.5, alpha = 0.75,
		position = position_jitter(width = 0.1, seed = 888)
	) +
	geom_text(
		data = sample_size_lp,
		aes(x = 1.5, y = 0, label = paste0("N = ", n), group = lp),
		show.legend = FALSE, position = position_dodge(width = 2)
	) +
	labs(
		y = "Receptive vocabulary (L1)", colour = "Group", fill = "Group",
		title = "Conceptual vocabulary size",
		subtitle = "Percentage of lexicalised concepts reported to be understood from the vocabulary checklist"
	) +
	guides(colour = "none") +
	scale_color_manual(aesthetics = "slab_color", values = pal_futurama()(2)) +
	scale_y_continuous(limits = c(0, 1), labels = percent) +
	theme(
		legend.title = element_blank(),
		legend.position = "top",
		panel.grid.major.x = element_blank(),
		axis.title.x = element_blank(),
		axis.text = element_text(size = 9)
	)

```


# Results

## Model comparison

## Model outputs

```{r fixed_effects_table, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
str_repl <- c(
	
	# 3-way interactions
	"b_time_bin_center:trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab (total)",
	"b_time_bin_center:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab (total)",
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_total_center" =
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab (total)",
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_total_center" =
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab (total)",
	
	# 2-way interactions
	"b_time_bin_center:trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (total)",
	"b_time_bin_center:trial_typePrimeNCvs.C:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (total)",
	
	"b_time_bin_center:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_time_bin_center:trial_typePrimeNCvs.C:lpLPMonvs.Bil" = 
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_time_bin_center:trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (total)",
	"b_time_bin_center:trial_typePrimeNCvs.C:vocab_size_total_center" =
		"Trial type (C vs. NC) \u00d7 Vocab (total)",
	
	"b_time_bin_center:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" =
		"Trial type (U vs. C+NC) \u00d7 Group",  
	"b_time_bin_center:lpLPMonvs.Bil:vocab_size_total_center" =
		"Group \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (total)",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:lpLPMonvs.Bil" =
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (total)",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",  
	"b_Itime_bin_centerE2:lpLPMonvs.Bil:vocab_size_total_center" = 
		"Group \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (total)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:lpLPMonvs.Bil" = 
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (total)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (total)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",  
	"b_Itime_bin_centerE3:lpLPMonvs.Bil:vocab_size_total_center" = 
		"Group \u00d7 Vocab (total)",
	
	
	# main effects (linear)
	"b_time_bin_center:trial_typePrimeUvs.CPNC" =
		"Trial type (U vs. C+NC)",
	"b_time_bin_center:trial_typePrimeNCvs.C" = 
		"Trial type (C vs. NC)",
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC" = 
		"Trial type (U vs. C+NC)",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C" = 
		"Trial type (C vs. NC)",
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC" = 
		"Trial type (U vs. C+NC)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C" = 
		"Trial type (C vs. NC)",
	
	"b_time_bin_center:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	"b_Itime_bin_centerE2:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	"b_Itime_bin_centerE3:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	
	"b_time_bin_center:vocab_size_total_center" = 
		"Vocab. (total, +1 SD)",
	"b_Itime_bin_centerE2:vocab_size_total_center" = 
		"Vocab. (total, +1 SD)",
	"b_Itime_bin_centerE3:vocab_size_total_center" = 
		"Vocab. (total, +1 SD)",
	
	
	# 3-way interaction linear effects
	"b_trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_total_center" =
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab. (total, +1 SD)",
	"b_trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_total_center" =
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab. (total, +1 SD)",
	
	# 2-way interaction linear effects
	"b_trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_trial_typePrimeNCvs.C:lpLPMonvs.Bil" = 
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_trial_typePrimeUvs.CPNC:vocab_size_total_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab. (total, +1 SD)",
	"b_trial_typePrimeNCvs.C:vocab_size_total_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab. (total, +1 SD)",
	
	
	"b_lpLPMonvs.Bil:vocab_size_total_center" =
		"Group \u00d7 Vocab. (total, +1 SD)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC" =
		"Trial type (U vs. C+NC)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C" =
		"Trial type (C vs. NC)",
	
	"b_Itime_bin_centerE3:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	
	# main linear effects
	"b_Intercept" = "Intercept",
	"b_Itime_bin_centerE2" = "Time bin 2",
	"b_Itime_bin_centerE3" = "Time bin 3",
	"b_time_bin_center" = "Time bin",
	"b_vocab_size_total_center" = "Vocab. (total, +1 SD)",
	
	"b_trial_typePrimeUvs.CPNC" = "Trial type (U vs. C+NC)",
	"b_trial_typePrimeNCvs.C" = "Trial type (C vs. NC)",
	"b_lpLPMonvs.Bil" = "Group (Mon. vs. Bil.)",
	
	# sigma
	"sigma" = "Sigma"
)



draws <- gather_draws(fit_total_4, `b_.*`, `sigma`, regex = TRUE) %>% 
	mutate(
		.value = ifelse(.variable=="sigma", inv_logit(.value), .value),
		.variable_name = str_replace_all(.variable, str_repl),
		type = case_when(
			str_detect(.variable, "E2") ~ "Quadratic time",
			str_detect(.variable, "E3") ~ "Cubic time",
			str_detect(.variable, "time_bin") ~ "Linear time",
			str_detect(.variable, "sigma") ~ "Error",
			TRUE ~ "Main effects"
		) %>% 
			factor(levels = c("Main effects", "Linear time", "Quadratic time", "Cubic time", "Error"), ordered = TRUE)
	)

draws %>% 
	group_by(.variable, .variable_name, type) %>% 
	mean_qi() %>% 
	select(type, .variable_name, .value, .lower, .upper) %>% 
	gt(rowname_col = ".variable", groupname_col = "type")  %>% 
	fmt_percent(3) %>%
	fmt_number(4:5, scale_by = 100) %>% 
	cols_merge(c(".lower", ".upper"), pattern = "[{1}, {2}]") %>% 
	cols_label(
		.variable_name = md("**Predictor**"),
		.value = md("**Mean**"),
		.lower = md("**95% CrI**")
	) %>% 
	tab_style(
		style = list(
			cell_text(weight = "bold", style = "italic")
		),
		locations = list(
			cells_row_groups()
		)
	) %>% 
	tab_style(
		style = list(
			cell_text(weight = "bold")
		),
		locations = list(
			cells_column_labels()
		)
	) %>% 
	as_raw_html()
```


```{r main_effects_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.height=10, fig.width=5}

draws_intercept <- draws %>% 
	filter(str_detect(.variable, "Intercept")) %>% 
	ggplot(aes(.value, .variable_name)) +
	geom_vline(xintercept = 0.5, colour = "black", linetype = "dashed") +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		size = 0.5,
		color = "#FF6F00FF",
		fill = "#FF6F00FF"
	) +
	labs(
		x = "Value", 
		y = "Variable", 
		fill = "CrI", 
		title = "Intercept",
		alpha = "CrI"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent, limits = c(0, 1)) 


draws_predictors <- draws %>% 
	filter(str_detect(.variable, "Intercept|sigma|sd|time_bin", negate = TRUE)) %>% 
	ggplot(aes(.value, .variable_name)) +
	geom_vline(xintercept = 0, colour = "black", linetype = "dashed") +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		size = 0.5, 
		color = "#C71000FF", 
		fill = "#C71000FF") +
	labs(
		x = "Value", 
		y = "Variable", 
		fill = "CrI", 
		alpha = "CrI",
		title = "Main effects"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent, limits = c(-0.2, 0.2)) 

draws_time <- draws %>%
	filter(str_detect(.variable, "time_bin")) %>% 
	ggplot(aes(.value, .variable_name)) +
	facet_wrap(~type, scales = "free_x") +
	geom_vline(xintercept = 0, colour = "black", linetype = "dashed") +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		size = 0.5, 
		color = "#008EA0FF", 
		fill = "#008EA0FF"
	) +
	labs(
		x = "Value", 
		y = "Variable", 
		fill = "CrI", 
		alpha = "CrI",
		title = "Polynomial effects"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent) 


draws_sigma <- draws %>% 
	filter(str_detect(.variable, "sigma")) %>% 
	ggplot(aes(.value, .variable_name)) +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		size = 0.5, 
		color = "#8A4198FF", 
		fill = "#8A4198FF"
	) +
	labs(
		x = "Value", 
		y = "Variable", 
		alpha = "CrI",
		fill = "CrI", 
		title = "Error"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent, limits = c(0.92, 0.97)) 

((draws_intercept / draws_sigma / guide_area()) | draws_predictors) /
	draws_time + 
	plot_layout(heights = c(0.5, 0.5)) &
	guides(fill = "none", color = "none") &
	theme(
		panel.background = element_rect(fill = NA, colour = "grey"),
		axis.text.y = element_text(size = 7),
		axis.text.x = element_text(size = 7),
		axis.title = element_blank(),
		legend.position = c(1, 1.2),
		legend.direction = "horizontal",
		legend.justification = "right",
		legend.key.size = unit(0.35, "cm"),
		legend.text = element_text(size = 7),
		legend.title = element_text(size = 7),
		panel.grid.major.y = element_blank()
	)

```









