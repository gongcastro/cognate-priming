{
  "hash": "18368158e5f516c52fe1a3e71e84e259",
  "result": {
    "markdown": "---\n---\n\n::: {.cell}\n\n:::\n\n\n# Introduction\n\nBuilding a mental lexicon is a major achievement in the development of an infant. By storing representations of how familiar words sound and what they mean, an infant is able to make sense of their linguistic input. Infants start forming their first lexical representations before their first year of life [@tincoff1999some; @halle1994emergence; @vihman2004cross; @parise2012electrophysiological; @bergelson20126; @bergelson2015early]. This initial lexicon consists of only a few items; mainly words for people, interjections, body parts, and food [@tincoff2012six; @tardif2008baby], but it undergoes rapid growth during their second year of life [@ganger2004reexamining; @goldfield1990early; @bloom2002children; @mcmurray2007defusing]. According to parental reports the average 15-month-old infant already understands more than 100 words, and by two years, they understand more than 400 words [@frank2021variability]. This accelerated lexical developmental is reflected in infants' trajectories of word recognition: infants recognise familiar words faster and more efficiently as they approach their second birthday [@fernald1998rapid; @fernald2001half; @hurtado2007spoken].\n\nDespite being exposed to a more complex linguistic input, bilinguals show equivalent trajectories of word acquisition and word recognition to their monolingual peers' [@vihman2007onset; @legacy2018vocabulary; @hoff2012dual; @de2014bilingual; @pearson1994patterns; @byers-heinlein2023sometimes]. This is a remarkable deed for two reasons. First, bilingual infants receive a relative impoverished linguistic input in each of their languages compared to monolinguals [@costa2014does]. Second, they face a more complex referential context, since they often learn two labels for each referent, one in each language. The mechanisms that allow bilingual infants to keep up with monolinguals in their lexical development trajectories are still unclear.\n\nMonolinguals and bilinguals share broadly common word-recognition mechanisms. The first step towards spoken word-recognition is the acoustic-phonetic processing of the speech signal, which results in the activation of lexical representations whose associated phonological forms match the acoustic signal. The activated word-forms then compete for selection: the lexical system uses the bottom-up information provided by the auditory input, together with top-down context---provided by grammatical, supra-segmental, and semantic constraints---to select the candidate lexical representation with the best match. This sequence of events occurs in a *cascaded* fashion. As the recognition system accumulates information about the unfolding acoustic signal, matching phonological representations are activated [@marslen1987functional; @marslen1978processing; @grosjean1980spoken], and in turn activate their associated semantic representations [@neely1977semantic]. By the time lexical selection occurs, many non-selected phonological and semantic representations have been activated, potentially modulating the dynamics of word recognition. \n\nA considerable amount of evidence for such cascaded account of lexical processing has been provided by studies recording eye movements during word recognition. For example, @allopenna1998tracking designed a word-recognition task in which participants were presented, in each trial, with four objects in the screen. Participants would then listen to a command like \"Pick up the beaker; now put it below the diamond\", and perform the action. The authors manipulated the phonological relationship between the target object's label (e.g., *casket*), and the label of each of the three distractors. Two of the distractors were phonologically related with the target, sharing onset (e.g., *castle*) or offset (e.g., *basket*) with the target word, respectively. The other distractor was phonologically unrelated to the target (e.g., *nickel*). After hearing the target label, phonological distractors attracted participants' eye fixations more than unrelated distractors. Distractors sharing phonological onset did so at an earlier time window than those sharing phonological offset. This time course of distractor fixations suggests that the auditory presentation of the target label activated no only its (subsequently selected) phonological form in participants' lexicon, but also that of phonologically related word-forms, leading to competition for selection between the word forms. These results converge with cascaded models of auditory word recognition, in which the unfolding acoustic input activates multiple phonological word-forms, which in turn compete for selection, like TRACE [@mcclelland1986trace] and Shortlist [@norris1994shortlist].\n\nThe developing mental lexicon also seems to operate in this cascaded fashion. Like adults, infants activate non-selected lexical representations. This is reflected by the fact that from 21 months of age, infants' lexicon seems to also be systematically organised according to the semantic and phonological properties of its lexical representations. Priming paradigms of word recognition have provided a strong body of evidence for the existence of phonological and semantic links between early lexical representations between 18 and 21 months of age [@arias2009lexical; @styles2009infants]. For instance, using a word recognition task, @arias2009lexical found that infants' spoken word recognition (e.g., *dot*) was interfered by the previous presentation of a semantically related word (e.g., *cat*). Other studies have provided electrophysiological evidence of semantic priming at earlier ages [e.g., @rama2013development; @friedrich2005lexical]. More recent studies have provided evidence for the emergence of such semantic links, even in the absence of visual referents during the experimental task [@willits2013toddlers].\n\nPhonological priming effects have also been reported in the initial lexicon. @mani2010infant created an implicit naming task in which each trial started with the *silent* presentation of a prime picture. Then, a target-distractor picture pair was presented side-by-side. Finally, the target picture's label was presented auditorily. The authors manipulated the phonological overlap between the prime label and the target label, so that in half of the trials both labels were phonologically related, sharing phonological onset (*cat*-*cup*), or phonologically unrelated (*ball*-*comb*). Prime and target-distractor pairs were semantically unrelated. Interestingly, infants showed a stronger looking preference for the target picture after phonologically related prime pictures, compared to after phonologically unrelated primes. This suggests that infants implicitly named prime pictures despite such pictures having been presented in silence, and that the phonology of the resulting label interacted with the subsequent auditory recognition of the target label.The authors found a facilitation effect: target looking preference was stronger in phonologically related primes, indicating that the activated phonological segments of the generated prime label facilitated the subsequent activation of the phonological representation of the target label during recognition.\n\nIn a follow-up study, @mani2011phonological found the opposite effect in older toddlers. After phonologically related primes, 24 month-old toddlers showed weaker target looking preference than after phonologically unrelated primes. These results interpreted these outcome as the result of the implicitly generated prime label interfering with the subsequent recognition of the (phonologically related) target word. The authors suggested that the shift from facilitation to interference from 18 to 24 months they found in both studies might be the result of a developmental shift in which 18-month-olds' lexicon is not yet organised based on phonological similarity, while 24-month-olds' is. This would lead to the former showing a pre-lexical facilitation effect in which such facilitation occurs via the activation of phonological segments, while the latter would show an interference effect due to lateral links between lexical representation having been established.\n\n@chow2017spoken adapted the Visual World Paradigm from @huettig2007tug to explore 24- to 30-month-old toddlers' visual fixation patterns during a word recognition when presented with phonological and semantic distractors. In each trial, the authors presented participants with four semantically and phonologically pictures. Four seconds after pictures onset, a word-form was auditorily presented. The word did not refer to any of the pictures displayed on the screen, but was phonologically related to one of them (both labels shared phonological onset), and semantically related to another one of the pictures (both referents belonged to the same taxonomic category. For instance, participants might be presented with the pictures of a sandwich, a bus, a cat, and a dress. Then they would hear the carrier phrase \"Look at the *bee*!\". The authors registered participants fixations to the phonological and semantic distractors, and found evidence of a preference for the phonological distractor at earlier stages of the post-naming phase, and a preference for the semantic distractor at later stages of the trial. These results support a cascaded activation account of lexical access during the first stages of lexical development, paralleling previous findings in adults [@allopenna1998tracking].\n\nOne of the most interesting pieces of evidence in support of a cascaded account of lexical processing is provided by bilinguals. A critical property the bilingual lexicon is that its representations are accessed in a language-non selective way. Even during monolingual situations, bilinguals access their lexical representations in both of their languages [e.g., @thierry2007brain; @dunabeitia2009masked]. This is reflected in bilinguals' performance in word recognition and production tasks. For instance, @marian1999activation presented Russian-English bilinguals with a series of trials that started with an auditory instruction like \"Poloji marku nije krestika\" [\"Put the stamp below the cross\"]. The instruction would be present in Russian (dominant language for most participants). The target object (*marku* [*stamp*], in this case) would be present in the screen, together with an object whose English label shared phonological onset with the target label (e.g., *mark*), and two unrelated distractors whose labels in Russian and English did not shared phonological relationship with the target label. Converging with @allopenna1998tracking's results in monolingual adults, after hearing the target label bilinguals fixated the cross-language phonological distractor significantly more than the unrelated distractors. These findings suggest that participants activated phonologically related word-forms in both Russian *and* English, which affected their overt visual exploration patterns during the task.\n\nLanguage non-selectivity in the bilingual lexicon has also been shown to affect top-down lexical access during word production. @costa2000cognate presented Catalan-Spanish bilinguals with a series of pictures of familiar objects. For each object, participants were asked to name it in Catalan (their dominant language). Unbeknownst to participants, the authors manipulated the phonological overlap between the pictures' labels in Catalan and their translations in Spanish. Participants produced faster words that shared phonological overlap with their Spanish translations (e.g., *gat*-*gat* [*cat*]) than those unrelated to their translation (e.g., *taula*-*mesa* [*table*]). Critically, Spanish monolinguals who completed the same task, naming the pictures in Spanish, showed equivalent naming times in both conditions. These results reveal that bilinguals activated their Spanish phonology, despite performing the naming task exclusively in Catalan: the visual recognition of the presented pictures led to the activation of its associated phonological forms in both language sin parallel, which influenced the subsequent the dynamics of word production.\n\nFurther support for the parallel retrieval of phonological forms during word production is given by implicit naming paradigms. Using an adaptation of @mani2010infant's task, @von2014bilinguals provided evidence that bilingual adults generate implicit labels in both labels for visually fixated pictures. The authors presented German-English bilinguals with 120 prime-target pairs. Primes were presented as familiar pictures in silence. After prime picture offset, target words were presented auditorily. Participants' N400 ERP components were recorded from target word onset. The authors manipulated the phonological relationship between the prime and target word-forms within participants' L1 and across L1 and L2. When prime and target were phonologically identical (*Affe*-*Affe*, German for *monkey*), or similar (*Fahne*-*Sahne*, German for *flag* and *ice-cream*, respectively) within L1, participants' showed a reduced N400 amplitude, compared to when prime and target were phonologically unrelated (*Messer*-*Seil*, German for *knife* and *rope*). Critically, a similar effect was found when prime and target were phonologically related through translation (*Rustsche*-*Kleid*, German for *slide* and *dress*). This suggests that participants activated prime labels in both languages in parallel, and that both labels impacted the dynamics of target words recognition.\n\nPhonological priming paradigms have also revealed language non-selectivity in the initial bilingual lexicon [@poarch2012cross; @bosma2020cognate; @singh2014one; @jardak2019labels; @von2019impact]. For instance, @von2012language found evidence of cross-language phonological priming in 21- to 42-months-old children learning German and English. At the beginning of each trial, the authors auditorily presented an English prime word embedded in a carrier phrase. Then, the target label was also auditorily presented in German. Finally the target and distractor pictures were presented side-by-side. The authors manipulated the phonological overlap between the prime and target labels. The novelty in this study lied in the orthogonal manipulation of the phonological overlap between both English and German labels. In some trials, the auditorily presented prime and target labels were phonologically related (e.g., *slide*-*Klide* [*dress*]). In some other trials, both labels were phonologically related through translation: the auditorily presented prime label did *not* overlap with the target label (e.g., *leg*-*Stein* [*stone*]), but its translation in German did [*Bein*]. In the rest of the trials prime and target labels were phonologically unrelated in both languages. The authors found a facilitation effect of cross-language priming when both prime and target auditory labels overlapped phonologically, as revealed by a stronger target picture looking preference, as compared to that of unrelated trials. Interestingly, participants showed a weaker target preference in priming through translation trials.\n\nUsing a similar task, @floccia2020translation provided conflicting results to those of @von2012language. The authors tested 27-month-old simultaneous bilinguals in a cross-language priming paradigm. The two languages participants were learning were English, and an Additional Language (either Cantonese, Dutch, French, German, Greek, Italian, Mandarin, Polish, Portuguese, or Spanish). A prime word was embedded at the end of a carrier sentence that participants listened to. Then, participants were presented with the auditory label of the target word, and two pictures were shown side-by-side, the target picture, and a distractor picture. In Study 1, the target word was the translation equivalent of the prime word (*cheese*-*fromage* for an English-French bilingual). In other trials, prime and target words were unrelated (e.g., *sock*-*fromage*). There was no phonological overlap at onset between prime and target or distractor labels in either of the two conditions. Participants were presented with two blocks of related and unrelated trials. In one of the blocks, participants were presented with English prime words and Home Language target words (*sock*-*fromage*), and in the other block they were presented with Additional Language prime words and English target words (*fromage*-*sock*). The authors found a cross-linguistic priming effect, in which participants showed a stronger preference for the target picture in the post-naming phase in related trials, as compared to unrelated trials. This effect was found regardless of the language of the prime (English or Home Language), or the dominance of the language of the prime (i.e., whether the prime word belonged to the dominant language). Target preference exceeded chance level in both conditions. In Study 2, the authors tested a similar group of bilinguals in a cross-linguistic semantic priming task, in which participants were primed with words in English, and tested with semantically related words in the Additional Language (or vice versa). This time, prime and target words were not translation equivalents, but rather words whose referents shared semantic features. Results from Study  2 were parallel to those from Study 1. The authors found a strong semantic priming effect across languages, regardless of the language of the prime or the dominance of the language of the prime. Overall these results suggest that bilinguals recognised target words in both conditions, and benefited from a cross-linguistic facilitation effect from translation equivalents. The symmetry of such effect across both languages suggests that participants lexical access occurred in parallel for the two members of translation equivalents. As @floccia2020translation note, the stimuli set of Study 2 contains multiple cognates, especially in languages with a larger degree of phonological overlap across translation pairs, like English and Dutch. The authors run *post hoc* analyses exploring the effect of cognateness on the cross-language priming effects found, which showed no evidence of a cognateness effect on target preference. However, the cross-language effects reported in Study 2 might still reflect the confounding influence of cognateness, as the resulting effect might have been generated by an interaction by the phonological and semantic overlap between cognate primes and targets.\n\n\nPrevious studies had reported similar cross-language priming effects, but as @von2012language note, the conclusion that such effects occurred at the lexical level, as opposed to being the result of mere acoustic similarity, was not warranted. In studies where the auditorily presented prime label was phonologically overlapped with the target label [@REFERENCE], priming effects might be explained by the activation of the phonological segments of the prime label, which facilitated the recognition of the target label, which shared such phonological segments. The priming-through-translation results by @von2012language and @floccia2020translation demonstrates that cross-language activation in the developing lexicon occurs at the lexical level. Since participants' target recognition was interfered by the non-presented prime translation, such an inhibitory effect must stem at the lexical level. The fact that phonological priming facilitated the recognition of the target words (both labels belong to different languages), and that phonological priming through translation interfered target recognition (translation and target belong to the same language) points to cross-language connections playing an excitatory role, and to within-language connections playing an inhibitory role.\n\n\nPriming-though-translation paradigms, however, come with a cost. When prime words are auditorily presented, the task constrains the naming context to one of the languages. The consequence is a potential asymmetry between the activation dynamics of the lexical representation of both labels: while the participant has heard one label, the activation of its translation must spread across semantic links. This might lead to a lower strength, and higher latency of the activation of the translation. \n\n\nIn the present study, we use an adaptation of an implicit naming paradigm by @mani2010infant, in which participants are primed with a picture, instead of an auditorily presented label. This paradigm prevents infants from activating the prime label in any of their two languages, and therefore makes it more likely that they will activate the prime labels in both languages in parallel. Infants implicitly named prime pictures despite such pictures having been presented in silence, and that the phonology of the resulting label interacted with the subsequent auditory recognition of the target label. In particular, the authors found a facilitation effect: target looking preference was stronger in phonologically related primes, indicating that the activated phonological segments of the generated prime label facilitated the subsequent activation of the phonological representation of the target label during recognition.\n\n\nWhen extended to the bilingual case, this implicit naming task may offer bilingual participants with an unconstrained naming context in which the activation of both labels may occur in a truly cascaded fashion for both languages in parallel: the recognition of the prime object depicted activates the (common) semantic representation for both members of the translation equivalent, and this in turn activates the two available phonological word-forms, one in each language. \n\n\n\n\n\nThis study also provides a more suitable design for drawing conclusions about developmental change in word recognition trajectories for two reasons. First, it extends the age range of participants, compared to previous studies. Second, participants were tested at three selected age points to ensure a more balanced sample size across ages. Third, the partially longitudinal design allows modelling the performance of participants across testing sessions altogether.\n\nIn order to circumvent the problem of limited vocabulary knowledge\nin the non-dominant language, we propose to test participants only in their dominant language, therefore\ndirecting our research to the question of how possessing a second language affects processing of the\ndominant one in bilingual toddlers [@costa2014does provide a fuller description of the\nadvantages of such approach].\n\n\nThe present study is aimed at investigating the developmental trajectories of word recognition in bilingualism, and how (if at all) language non-selectivity shapes them. Using an adaptation of [@mani2010infant], we presented 20- to 32-months-old toddlers with a cross-linguistic phonological priming paradigm. We manipulated both the phonological overlap between the prime word and target word, and the cognate status of the prime word, to test the hypothesis that bilingual toddlers implicitly name familiar pictures in both languages. If so, phonological priming effect should be larger when the prime label in  both languages shares phonological overlap with the target words (cognate condition), compared to when only the label of the prime in one language overlaps phonologically with the target (non-cognate condition). We also also included a control *Unrelated* condition in which regardless of the cognate status of the prime word, neither of the prime labels in any language overlapped phonologically with the target word.\n\nWe compared the explanatory power of three measures of vocabulary size on participants' trajectories of word recognition: L1 vocabulary and total vocabulary.Previous studies suggest that same-language vocabulary size predicts better bilingual infants' performance in word recognition tasks, as compared to cross-language vocabulary size [@marchman2010vocabulary]\n\nHypothesis 1: if lexical representations linked through inhibitory links (compete for selection), like in the adult lexicon, target looking should increase faster in *Unrelated* trials compared to *Related* trials. If lexical representations are linked through excitatory links, target preference should increase faster in *Related* trials, compared to *Unrelated* trials. If lexical representations are sparsely connected, participants should show equivalent patterns of target looking in *Related* and *Unrelated* trials.\n\nHypothesis 2: if bilinguals' lexical representations linked across languages through inhibitory links (compete for selection), target looking should increase faster in this group in *Related/Non-cognate* trials compared to *Related/Cognate* trials. If lexical representations are linked across languages through excitatory links, target preference should increase faster in *Related/Cognate* trials, compared to *Unrelated/Cognate* trials. If lexical representations are sparsely connected across languages, bilinguals' patterns of target looking should be equivalent for *Related/Cognate* and *Related/Non-cognate* trials. This pattern is also expected for monolingual infants.\n\nHypothesis 3: if the emergence of within-language or cross-language phonological links is explained (if at all) by the growth of within-language vocabulary size, the difference in target looking between *Related* and *Unrelated*, or between *Related/Cognate* and *Related/Non-cognate* trials should be larger in participants with larger vocabulary sizes in their dominant language, in which they were tested. This should be reflected by a $\\text{Condition} \\times \\text{L1 vocabulary}$ two -way interaction, or a $\\text{Condition} \\times \\text{Group} \\times \\text{Dominant vocabulary}$ three-way interaction.\n\nHypothesis 4: if the emergence of within-language or cross-language phonological links is explained better by the growth of cross-language vocabulary size, compared to within-language vocabulary size, a model that incorporates total vocabulary size as a predictor instead of dominant vocabulary size should show better predictive performance. If the emergence of such links is explained at all by the growth of vocabulary size, both models incorporating vocabulary size as a predictor should show better predictive performance than a model incorporating participants' age.\n\n# Study 1\n\n## Methods\n\nAll materials, data, and reproducible code can be found at the OSF ([https://osf.io/hy984/](https://osf.io/ckydb/)) and GitHub ([https://github.com/gongcastro/cognate-priming](https://github.com/gongcastro/cognate-priming)) repositories. This study was conducted according to guidelines laid down in the Declaration of Helsinki, and was approved by the Drug Research Ethical Committee (CEIm) of the IMIM Parc de Salut Mar, reference 2020/9080/I. Before every testing session, caregivers were asked to read and sign an informed consent form, and were given a token of appreciation at the end of it.\n\n### Participants\n\n\n::: {.cell}\n\n:::\n\n\n\nWe collected data from 162 children living in the Metropolitan Area of Barcelona (Spain), tested at the Laboratori de Recerca en Infància at the Universitat Pompeu Fabra. Families were recruited from maternity rooms in private hospitals and social media, and contacted via phone when the child's age spanned between 20 and 32 months. From the 162 children that participated, 81 participated once, 55 participated twice, and 26 participated three times. Recurrent participants were tested with at least XXX months of difference. We gathered a total of 269 testing sessions. Participants were divided into monolinguals and bilinguals based on their relative degree of exposure to Catalan and Spanish, estimated using the Language Exposure Questionnaire [LEQ, @bosch2001evidence]. We categorised participants as monolingual if exposed to more than 80% or more of the time to their dominant language, and as bilingual otherwise. Eighty-three of the participants were categorised as monolinguals (49 female, 34 male) and 80 as Catalan/Spanish bilinguals (34 female, 48 male) (see @tbl-participants for a detailed summary of participants' age and language profile). Participants' vision was normal, none used glasses or any other type of vision corrector.\n\n\n\n::: {#tbl-participants .cell tbl-cap='Demographic and linguistic profile of testing sessions.'}\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrrrr}\n\\toprule\n\\multicolumn{1}{l}{} &  &  &  &  & \\multicolumn{3}{c}{Degree of Exposure (\\%)} \\\\ \n\\cmidrule(lr){6-8}\n\\multicolumn{1}{l}{} &  &  & \\multicolumn{2}{c}{Age (months)} & Spanish & Catalan & English \\\\ \n\\cmidrule(lr){4-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-7} \\cmidrule(lr){8-8}\n\\multicolumn{1}{l}{} & N sessions & N participants & M (SD) & Range & M (SD) & M (SD) & M (SD) \\\\ \n\\midrule\n\\multicolumn{8}{l}{Monolingual} \\\\ \n\\midrule\nCatalan & $95$ & $53$ & $25.7$ ($3.8$) & $20.0$ ($32.3$) & $4.3$ ($5.8$) & $95.3$ ($6.0$) & $0.3$ ($2.1$) \\\\ \nSpanish & $53$ & $30$ & $25.4$ ($3.8$) & $20.0$ ($32.0$) & $89.3$ ($13.9$) & $10.2$ ($14.0$) & $0.3$ ($0.9$) \\\\ \n\\midrule\n\\multicolumn{8}{l}{Bilingual} \\\\ \n\\midrule\nCatalan & $72$ & $51$ & $25.3$ ($3.8$) & $19.4$ ($31.7$) & $37.5$ ($10.4$) & $61.8$ ($10.7$) & $0.2$ ($0.8$) \\\\ \nSpanish & $49$ & $33$ & $25.1$ ($3.4$) & $20.2$ ($31.3$) & $61.0$ ($11.1$) & $38.7$ ($10.6$) & $0.3$ ($1.4$) \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n### Vocabulary size\n\n\n::: {.cell}\n\n:::\n\n\nWe collected vocabulary data using parental responses to the Barcelona Vocabulary Inventory [BVQ, @garcia-castro2023bvq], an online vocabulary checklist inspired in several adaptations of the the Communicative Developmental Inventory [CDI, @fenson1994variability] developed to assess the vocabulary size of Catalan-Spanish bilingual toddlers. Families received a link to the BVQ immediately after each experimental session, and were given two weeks to fill it. We calculated two measures of receptive vocabulary size for each participant: *L1 vocabulary size* (proportion of words  reported as acquired in the checklist of the dominant language), and *total vocabulary size* (proportion of the words in both checklists reported as acquired). 132 (49%) Families failed to provide a complete response to the BVQ within the two-week time limit, or did not provide a successful response to the questionnaire. For missing questionnaire responses, we imputed the vocabulary size of the participant using single imputation, using the vocabulary size scores of a pool of 586 additional participants for which a successful response for the questionnaire had been gathered. We used participants age in months and their language profile (monolingual/bilingual) as predictors. We used the `mice` R package [@van2011mice] to perform imputation using the Bayesian linear regression method. \n\nOverall, there was a substantial increase in both total and L1 vocabulary sizes associated to age (see @fig-vocabulary). Monolinguals showed overall higher L1 vocabulary sizes than monolinguals: they were reported to understand an average of 56.9% (*SD* = 17.74%) of the words at around 21 months, 75.9% (*SD* = 14.79%) at 25 months, and 82.6% (*SD* = 14.95%) at 30 months, while bilinguals  were reported to understand an average of 49.1% (*SD* = 22.51%) of the words at around 21 months, 68.0% (*SD* = 20.33%) at 25 months, and 79.0% (*SD* = 13.80%) at 30 months. Total vocabulary sizes showed the opposite pattern, with monolinguals infants being reported to understand 40.50% (*SD* = 15.989%) of the words at around 21 months, 59.83% (*SD* = 19.619%) at 25 months, and 63.30% (*SD* = 21.128%) at 30 months, and bilinguals being reported to understand 47.93% (*SD* = 23.261%) of the words at around 21 months, 64.05% (*SD* = 17.150%) at 25 months, and 75.83% (*SD* = 17.170%) at 30 months.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Participant vocabulary sizes across ages and language profiles. Vocabulary size scores are presented using two measures: L1 vocabulary size (proportion of words marked as *Understands* in the vocabulary checklist of the dominant language), and total vocabulary size (proportion of words marked as *Understands* in vocabulary checklists of both dominant and non-dominant languages). Grey lines connect vocabulary size scores from the recurrent participants. For visualisation purposes, participants were group into categorical age groups at 21, 25, 30 months, the ages around which most participants were tested.](manuscript_files/figure-pdf/fig-vocabulary-1.pdf){#fig-vocabulary}\n:::\n:::\n\n\n\n\n### Stimuli\n\n\n::: {.cell}\n\n:::\n\n\nWe used 62 distinct words included in the BVQ to create the stimuli lists. We created six stimuli lists: three in Catalan, and three in Spanish. Each list contained 32 trials, each involving a prime-target-distractor group. Each word played a role as either prime, *or* as target and distractor across the three lists in their corresponding language. For instance, the Catalan word *cadira* appeared as *prime* in the three lists, but never as *target* or *distractor*; the Catalan word *bici* appeared as *target* and *distractor* across the three lists, but never as a prime. Target-distractor pairings were held constant across the three lists in each language. For instance, in all Catalan lists the word *bici* was paired with the word *porta*. Target-distractor pairings were also yoked, so that each member of the same target-distractor pair appeared once as target and once as distractor in each list. For instance, the *bici*-*porta* paired appeared twice in each of the three Catalan lists: once with *bici* as target and *porta* as distractor, and once with *porta* as target and *bici* as distractor. This counterbalancing avoided participants encountering looking at the target word guided solely by that word having being named in a previous trial. Finally, prime words appeared only once in each list: each target-distractor pair was associated with a different prime word in both appearances. In each list, the same prime word was presented alongside a different target-distractor pair. For instance, the Catalan prime word *barret* was presented with the *bici*-*porta* target-distractor pair in one list, with the *bici*-*porta* pair in another list, and with *berenar*-*amanida* in the remaining list. The order of the trials was randomised across experimental session, so that each time a participant was tested, the order in which the prime-target-distractor was presented was randomised. Each participant was randomly assigned to one of the three lists in the corresponding (dominant) language, and always the same list across their experimental sessions in the case of a recurrent participant.\n\nIn 16 of the 32 trials of the same list (henceforth *related* trials), the prime and the target words were phonologically related, sharing phonological onset (at least first phoneme). In the other 16 trials (*unrelated* trials), prime and target did not share phonological onset. 8 of the 16 *related* trials included a cognate prime (*cognate* trials), and the other 8 included a non-cognate trials (*non-cognate* trials). A prime word was considered cognate if its Catalan and Spanish translation shared phonological onset. Especial attention was paid to avoiding semantic or taxonomic relationships between prime and target words, and between prime and distractor words. Target and distractor word pairs were phonologically unrelated (did not share phonological onset). Some of them shared semantic features or a taxonomic relationship. This is the case of words associated with especially salient referents such as animals or food. To avoid infants guiding their gaze to these objects based on their saliency, we paired animals and food items together. The position of the target and distractor pictures (right or left) for each target-distractor pair was alternated, so that in one list the target would appear on the left, in another list it would appear on the right, and so on.\n\nWe examined the overall equivalence of the three trial types by comparing them across three variables relating to the target word: lexical frequency, word prevalence, animacy\n@tbl-stimuli shows a detailed summary of the stimuli properties, broken down by trial type and testing language. Lexical frequencies were extracted from the Catalan and Spanish corpora of the CHILDES database [@macwhinney2000childes; @sanchez2019childes] as counts per million words, and transformed into Zipf scores for easier cross-language comparison [@zipf1945meaning; @van2014subtlex]. We defined word prevalence as the proportion of same-aged infants who were reported to understand the word in the BVQ database.\n\n\n#### Auditory stimuli\n\nThe auditory stimuli were natural exemplars of the selected target words, spoken by Central Catalan-Spanish proficient bilingual female speaker who was instructed to pronounce each word in a toddler-directed manner. Recordings were made with an Audio-Tecnica 328 microphone (AT2050) at a sampling rate of 44100 Hz, in a soundproof room at the *Laboratori de Recerca en Infancia* at University Pompeu Fabra. We used the Audacity and Praat [@boersma2001speak] software packages to record and edit the audio files. The speaker was presented with a list of words in Catalan. The order of the words was pseudo-randomised, and each word was produced three times in a row before moving to the next word in the list. After going through all the words in the list, the speaker went through the word list again generating three tokens for each word, now in an inverse order (from bottom of the list to the top). We then repeated the same procedure for the list of Spanish words. The resulting audios were manually chunked into individual word-forms. For each of the six tokens produced for each word, the most adequate was selected for further processing. The audios were then transformed to stereo by duplicating them into two channels, denoised, and finally normalised. The mean duration of the final audios was 1.23 (*SD* = 0.17) and 1.08 (*SD* = 0.14) seconds for the Catalan and Spanish lists.\n\nTo make the pronunciation of the words as familiar as possible to each infant, we generated additional pronunciation variants for some words in Catalan and Spanish. Catalan words involving the /\\textipa{L}/ phoneme in their Central Catalan variant (e.g., /\\textipa{'Lu.n@}) were also recorded with such phoneme replaced by /j/ (e.g., /\\textipa{'ju.n@}), a phonological process common in the Metropolitan Area of Barcelona. Spanish words involving the /\\textipa{T}/ phoneme were also generated replacing such phoneme with /\\textipa{s}/ to better accommodate Latin variants of Spanish. Before every experimental session, caregivers were asked to utter three written words involving the /\\textipa{L}/ phoneme (in the case of participants tested in Catalan) or the /\\textipa{T}/ phoneme (in the case of participants tested in Spanish). Each token contained the critical phoneme at onset, inter-vocalic position, and coda. The experimenter assigned the participant to the Catalan or Spanish stimuli list involving the closest variant to that of caregivers'.\n\n\n#### Visual stimuli\n\nFor each word, we created a picture with a typical referent. To avoid competition between target and distractor pictures, semantically related target-distractor pairs were perceptually distinct [@floccia2020translation; @arias2009lexical].\n\n\n::: {#tbl-stimuli .cell tbl-cap='Summary of stimuli properties by trial type.'}\n::: {.cell-output-display}\n\\begin{longtable}{lrrrr}\n\\toprule\n & Prevalence (\\%) & Frequency & Animacy (\\%) & Duration (s) \\\\ \n\\midrule\n\\multicolumn{5}{l}{Catalan} \\\\ \n\\midrule\nCognate & $36.8$ ($17.6$) & $3.9$ ($0.6$) & $22.9$ & $1.2$ ($0.2$) \\\\ \nNon-cognate & $37.9$ ($15.9$) & $3.8$ ($0.5$) & $25.0$ & $1.3$ ($0.2$) \\\\ \nUnrelated & $35.4$ ($14.8$) & $3.9$ ($0.5$) & $21.9$ & $1.2$ ($0.2$) \\\\ \n\\midrule\n\\multicolumn{5}{l}{Spanish} \\\\ \n\\midrule\nCognate & $30.0$ ($13.4$) & $4.2$ ($0.5$) & $12.5$ & $1.1$ ($0.1$) \\\\ \nNon-cognate & $31.4$ ($14.0$) & $4.3$ ($0.5$) & $14.6$ & $1.1$ ($0.1$) \\\\ \nUnrelated & $28.9$ ($14.8$) & $4.2$ ($0.5$) & $16.7$ & $1.1$ ($0.1$) \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n### Procedure\n\nTesting took place in a sound-proof room. Participants sat on their caregivers' lap in a dimly lit testing booth while the experimenter conducted the experiment from outside. Caregivers were instructed to keep their eyes shut (to avoid recording their gaze, instead of the participant's), to be still, and to avoid interacting with the participant verbally or non-verbally. Participants sat at approximately 65 cm from the eye-tracker and a XX-in screen of $1929\\times1080$ screen resolution. We used a custom Matlab XXXX script using the PsychToolbox-3 extension [@kleiner2007s; @brainard1997psychophysics; @pelli1997videotoolbox] to present the stimuli, and the Tobii Analytics SDK 3.0 to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 5-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented. We set a 55% grey background for the calibration and stimuli presentation. Auditory stimuli were presented through two loudspeakers located behind the screen, one to each side. The experimenter monitored the experimental from outside the room using a centrally located video camera place above the screen. After a successful calibration the experimenter triggered the onset of the first trial. Trials were presented uninterruptedly and  without intervention of the experimenter until the 32 trials were presented, or the experimental session had to be stopped because of the participant's behaviour.\n\n![Experimental task design with examples in Catalan. In each trial, the prime image is presented in silence for 3,000 ms. The the auditory target label is presented, and finally the target and distractor pictures are presented side-by-side for 2,000 ms. In cognate trials (*n* = 8), Catalan *and* Spanish prime labels shared phonological onset with the target label. In non-cognate trials (*n* = 8), only the Catalan prime label shared phonological onset with the target label. In unrelated trials (*n* = 32), none of the prime labels shared phonological onset with the target label.](_assets/img/design.png){fig-align=\"center\"}\n\nEach trial started with the presentation of an attention getter for 3,000 milliseconds. Then, the prime picture was presented in silence in the centre of the screen for 1,500 milliseconds. Fifty milliseconds after the offset of the prime image, an auditory label was played from the loudspeakers and, 700 milliseconds after the onset of the auditory label, the target and distractor pictures were presented side-by-side during 1,000 milliseconds until the end of the trial. After this, the attention getter of the next trial was immediately presented. Each experimental session took approximately 10 minutes.\n\n### Apparatus\n\nsee https://link.springer.com/article/10.3758/s13428-021-01762-8\n\n### Data analysis\n\n#### Data processing\n\n\n::: {.cell}\n\n:::\n\n\nWe defined a time windows of interest from 200 ms after target and distractor pictures onset until the end of the trial at 2,000 ms when  both pictures disappeared from screen. To avoid modelling fixations driven by processes other than auditory word recognition [@fernald1998rapid; @fernald2001half]. Missing eye-tracker samples were interpolated using the last-observation-carried-forward [see @zettersten2022peekbank for a similar approach], with a maximum of 20 maximum consecutive missing samples being interpolated (an equivalent of 166.67 ms).\n\nWe gathered data from 8,608 trials from 269 testing sessions, generated from 162 distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples (equivalent to 750 ms) during the prime phase (*n* = 1,815) or 50% valid samples (equivalent to 1,000 ms) during the target-distractor phase (*n* = 1,262). We also excluded trials in which participants did not provide at least 5% of valid samples (equivalent to 100 ms) of target or distractor looking in the test phase (*n* = 2,461) [see @floccia2020translation for a similar approach].\n\nAfter trials that matched any of the aforementioned exclusion criteria from the dataset, we excluded participants who did not provide at least two valid trials in the *Cognate* condition, the *Non-cognate* condition, or the  *Unrelated* condition (*n* = 29). The final dataset included 5,072 trials from 240 testing sessions, generated by 151 distinct participants. Of those participants, 81 provided data from one experimental session, 51 provided data from two experimental sessions, and 19 provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.\n\n\n\n::: {#tbl-attrition .cell tbl-cap='Participant-level and trial-level sample size after applying inclusion criteria. The number of excluded participants and trials is indicated between parentheses.'}\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrr}\n\\toprule\n\\multicolumn{1}{l}{} &  & \\multicolumn{3}{c}{Trials} \\\\ \n\\cmidrule(lr){3-5}\n\\multicolumn{1}{l}{} & Participants & Cognate & Non-cognate & Unrelated \\\\ \n\\midrule\nBilingual & $107$ ($14$) & $596$ ($372$) & $555$ ($413$) & $1,140$ ($796$) \\\\ \nMonolingual & $133$ ($15$) & $741$ ($443$) & $747$ ($437$) & $1,506$ ($862$) \\\\ \n\\midrule \n\\midrule \n\\emph{N} & $240$ & $1,337$ & $1,302$ & $2,646$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n#### Modelling approach\n\n\n::: {.cell}\n\n:::\n\n\nWe used multilevel General Additive Models (GAMs) to model our data and test our hypotheses [@pedersen2019hierarchical]. First, we defined our response variable as the empirical logit of target looking using @eq-elogit across all eye-tracking samples for each each participant in each condition [@barr2008analyzing; @agresti2012categorical]. We used a Gaussian distribution to model our response variable. To test our hypotheses, we then included *Condition*, *Group*, and either *Age* ($\\mathcal{M}_0$), *L1 vocabulary* ($\\mathcal{M}_1$), or *Total vocabulary* ($\\mathcal{M}_2$) as fixed effects in the model. We also added all two-way and three-way interactions between the predictors. We set two *a priori* contrasts for the *Condition* predictor: one comparing *Unrelated* and *Related/Non-cognate* trials (sum-coded as `-0.5` and `+0.5`, with *Related/Cognate* trials coded as `0`), and another comparing *Related/Non-cognate* and *Related/Cognate* trials (sum-coded as `-0.5` and `+0.5`, with *Unrelated* trials coded as `0`). We also set two *a priori* contrasts for the *Group* predictor: one comparing *Monolingual (ENG)* with *Monolingual (CAT/SPA)* participants (sum-coded as `-0.5` and `+0.5`, with *Bilingual (CAT-SPA)* participants coded as `0`), and another comparing *Monolingual (ENG)* with *Bilingual (CAT-SPA)* participants (sum-coded as `-0.5` and `+0.5`, with *Monolingual (CAT/SPA)* participants coded as `0`). Before entering the model, the numeric predictors *Age*, *L1 vocabulary*, and *Total vocabulary* were standardised by subtracting from each observation the mean of the predictor, and dividing the result from the standard deviation of the predictor.\n\n$$\n\\eta' = \\ln\\bigg(\\frac{\\text{Target} + 0.5}{ \\text{Distractor} + 0.5}\\bigg)\n$$ {#eq-elogit}\n\nWe added *Session* as grouping variable, by by-session intercept and *Condition* slopes. Each level in the *Session* variable uniquely indexes all observations generated by a participant in a single testing session. Testing sessions from the same participant are identified by different indexes. For computational limitations, adding both participants and testing sessions as grouping variable in the random effects structure of the model was not possible. We instead included testing sessions alone, as observations from the same testing session are more likely to be highly correlated than those from the same participant in different testing sessions (which were recorded at least four months apart). To model the time course of target looking across time bins, we included cubic regression splines for the main effect of *Time*, and one for an adjustment of the *Time* cubic spline by *Group* and *Relatedness* [@wood2017generalized]. For both splines, we specified $k = 9$ basis functions or *knots*--half the number of time bins---for computational convenience. @eq-model shows a formal implementation of the model.\n\n$$\n\\begin{aligned}\n\\textbf{Likelihood:} \\\\\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma_i) \\\\ \\\\\n\\textbf{Linear model:} \\\\\n\\eta'(\\mu_i) &= (\\beta_0 + u _{0_{i}}) +\n(\\beta_1 + u _{1_{i}}) \\cdot \\text{Condition} +\\\\\n&\\beta_{2} \\cdot \\text{Group} +\n\\beta_{3} \\cdot X + \\beta_{4} \\cdot (\\text{Condition} \\times \\text{Group}) +\\\\\n&\\beta_{5} \\cdot (\\text{Condition} \\times X) + \\beta_{6} \\cdot (\\text{Group} \\times X) +\\\\\n&\\beta_{7} \\cdot (\\text{Condition} \\times \\text{Group} \\times X) +\\\\\n& \\sum_{j = 1}^k b_{j_{0}} \\cdot \\beta_{8_{k}} \\cdot \\text{Time} +\n\\sum_{j = 1}^k b_{j_{1}} \\cdot\\beta_{9_{k}} \\cdot (\\text{Time} \\times \\text{Group}) \\\\\n\\text{where:} \\\\\n&\\eta'\\text{ is the empirical logit of target fixations} \\\\\n&X \\in \\{\\text{Age}, \\text{L1 vocabulary}, \\text{Total vocabulary}\\} \\\\\n&k \\text{ is the number of knots in the spline (10)} \\\\\n\\textbf{Prior:} \\\\\n\\beta_{0-9} &\\sim \\mathcal{N}(0, 0.5) \\\\\nu_{0-2} &\\sim \\mathcal{N}(0, \\sigma_{0-2})\\\\\nb_{0-1} &\\sim \\text{MVN}(0, \\tau_{0-1}) \\\\\n\\sigma_{0-2}, \\tau_{0-1} &\\sim \\text{Exponential}(6)\\\\\n\\rho_{0-2} &\\sim LKJCorr(6)\\\\\n\\text{where:}\\\\\n&\\rho_{0-2} \\text{ are the correlation parameters for } \\sigma_{0-2}\n\\end{aligned}\n$$ {#eq-model}\n\nThe comparison between the three models including *Age*, *L1 vocabulary*, *Total vocabulary* as predictors was performed using leave-one-out cross-validation (LOO-CV) as a benchmark of model performance, using Pareto-smoothed importance sampling (PSIS) to approximate it [@vehtari2017practical]. We implemented the model using `brms` [@burkner2017brms], an R interface to the Stan probabilistic language (2.33.0) [@carpenter2017stan]. We ran four iteration chains using the by-default No U-Turn Sampler algorithm with 250 iterations each and an additional 250 warm-up iterations per chain.\n\n\n## Results\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-loos .cell}\n::: {.cell-output-display}\n\\begin{longtable}{lrrrr}\n\\toprule\nmodel & ELPD (diff.) & SE ELPD (diff) & ELPD & SE ELPD \\\\ \n\\midrule\n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{2\\}\\$ & $0.00$ & $0.00$ & $-20,855.64$ & $136.98$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{4\\}\\$ & $-1.48$ & $1.49$ & $-20,857.13$ & $136.99$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{3\\}\\$ & $-3.56$ & $1.24$ & $-20,859.21$ & $136.97$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{1\\}\\$ & $-192.41$ & $31.90$ & $-21,048.06$ & $134.75$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{0\\}\\$ & $-192.60$ & $31.94$ & $-21,048.24$ & $134.88$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n@tbl-loos summarises the outputs of the LOO-CV model comparisons. Models $\\mathcal{M}_{2}$, $\\mathcal{M}_{3}$, and $\\mathcal{M}_{4}$ showed substantially better predicted performance than models $\\mathcal{M}_{0}$ and $\\mathcal{M}_{1}$, which indicates that adding the *Condition* predictor improves significantly the fit of the models. All $\\mathcal{M}_{2}$, $\\mathcal{M}_{3}$, and $\\mathcal{M}_{4}$ models showed equivalent performance, suggesting that adding the two-way and three-way interactions between *Age*, *Group*, and *Condition*, did not improve the the fit of the model. We now report a description of the posterior distribution of the regression coefficients of model $\\mathcal{M}_{4}$. We report the median and 95% highest density interval of each fixed regression coefficient. \n\nThe outcomes of $\\mathcal{M}_{0}$, which only included *Age* and as main effect, revealed successful word recognition across participants. Overall, participants' looking time exceeded chance levels, as indicated by the fact that the 95% HDI of the intercept term excluded zero ($\\beta$ = 0.222, 95% HDI = [0.177, 0.259]). The variability of participants' target preference varied significantly more between participants ($\\sigma$ = 0.155, 95% HDI = [0.037, 0.228]) than within testing sessions from the same participant ($\\sigma$ = 0.160, 95% HDI = [0.057, 0.263]). The 95% HDI of the coefficient of *Age* had a positive sign, but did not exclude zero ($\\beta$ = 0.030, 95% HDI = [-0.011, 0.071]), indicating that participants from all ages showed equivalent overall target word recognition.\n\n\nThe 95% HDI of the coefficient of *Group* in $\\mathcal{M}_{1}$ included zero ($\\beta$ = -0.013, 95% HDI = [-0.105, 0.067]), indicating an equivalent overall target preference in monolinguals and bilinguals. The 95% HDI of the first contrast of this predictor, comparing *Unrelated* and *Related/Non-cognate* trials, included zero ($\\beta$ = 0.062, 95% HDI = [-0.034, 0.151]). The 95% HDI of the second contrast, comparing *Related/Non-cognate* and *Related/Cognate* trials, also included zero ($\\beta$ = -0.018, 95% HDI = [-0.121, 0.083]). The overall target preference was equivalent across both pairwise condition comparisons. The interaction term between the first *Condition* contrast contained zero ($\\beta$ = -0.015, 95% HDI = [-0.164, 0.154]). The interaction term between the second *Condition* contrast also contained zero ($\\beta$ = 0.095, 95% HDI = [-0.109, 0.303]). The outcomes of this model indicate that lack of differences in overall target looking time across conditions remained across monolinguals and bilinguals.\n\nBoth younger and older participants showed equivalent looking time across conditions, as suggested by the fact that the 95% HDI of the two-way interaction between *Age* and the first *Condition* contrast included zero ($\\beta$ = 0.042, 95% HDI = [-0.044, 0.135]), as well as the interaction between *Age* and the second *Condition* contrast ($\\beta$ = 0.028, 95% HDI = [-0.076, 0.116]). This pattern of results was found in both monolinguals and bilinguals, as the 95% HDI of the three-way interaction between *Age*, *Group*, and *Condition* included zero both the first ($\\beta$ = 0.077, 95% HDI = [-0.089, 0.240]) and second ($\\beta$ = -0.032, 95% HDI = [-0.212, 0.177]) contrast of *Condition*.\n\n\n\n::: {.cell}\n\n:::\n\n\nAn analysis of the time course of target looking revealed a similar pattern of results (see @fig-epreds). Posterior mean prediction for the three conditions overlap across the full time course of the trial in both language groups, and also in both extrema of the age range of participants (20 and 32 months).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Posterior mean prdictions of the time course of target fixation in the test phase. Lines and intervals indicate the median and 95% credible interval of the posterior predictions, respectively.](manuscript_files/figure-pdf/fig-epreds-1.pdf){#fig-epreds}\n:::\n:::\n\n\nIn an exploratory analysis, we compared the model-estimated time points at which participants' gaze behaviour showed evidence of target looking above chance level (50%). We defined the recognition time of the trial as the earliest time point at which the lower bound of the 95% HDI posterior mean prediction of the target looking excluded zero. As expected, the recognition times were on average shorter for older infants than for younger infants. Differences between conditions were larger in bilinguals than in monolinguals, especially in the older group. The recognition time for monolingual 20-month-olds was 729.29 ms in the *Unrelated* condition, 677.78 ms in the *Related/Non-cognate* condition, and 694.95 ms in the *Related/Cognate* condition. In monolingual 30 month-olds, the recognition point was 643.43 ms in the *Unrelated* condition, 626.26 ms in the *Related/Non-cognate* condition, and 574.75 ms in the *Related/Cognate* condition. In bilingual 20 month-olds, the recognition point was 729.29 ms in the *Unrelated* condition, 677.78 ms in the *Related/Non-cognate* condition, and 694.95 ms in the *Related/Cognate* condition. In bilingual 30 month-olds, the recognition point was 729.29 ms in the *Unrelated* condition, 677.78 ms in the *Related/Non-cognate* condition, and 694.95 ms in the *Related/Cognate* condition.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Model-predicted recognition times for monlingual and bilinguals at 20 and 30 months of age.](manuscript_files/figure-pdf/fig-recognition-1.pdf){#fig-recognition}\n:::\n:::\n\n\n# Study 2\n\n## Methods\n\n### Participants\n\n\n::: {.cell}\n\n:::\n\n\nWe collected data from 112 children (41 female, 68 male, 3 sex not reported, age: *Mean* = 26.36 months, *SD* = 4.01, *Range* = [20.03-32.5]), living in the Oxfordshire area (United Kingdom), tested at the Oxford BabyLab at the University of Oxford. Families were recruited from maternity rooms in private hospitals and social media, and contacted via phone when the child's age spanned between 20 and 32 months. From the 112 children that participated, 97 participated once, and 15 participated twice. Recurrent participants were tested with at least XXX months of difference. We gathered a total of 127 testing sessions. All participants were being raised in exclusively British English monolingual homes.\n\n### Vocabulary size\n\n\n::: {.cell}\n\n:::\n\n\nWe collected vocabulary data using parental responses to the Oxford Communicative Development Inventory (OCDI) [@hamilton2000infant]. Families were sent the questionnaire immediately after each experimental session, and were given two weeks to fill it. Since all vocabulary sizes of English monolingual infants were only assessed in English, both *L1 vocabulary* and *total vocabulary* sizes were identical (see @fig-vocabulary-oxf).\n\n\n::: {.cell}\n\n:::\n\n\n\n### Stimuli\n\nNew stimuli lists were generated to adapt the experimental procedure to English-learning infants. Stimuli lists were created following the same constraints as in Study 1. Auditory stimuli were recorded following the same procedure as in Study 1, produced by Southern British English native female speaker in a toddler-directed manner. Audio and picture processing were performed following the same workflow as in Study 1.\n\n### Procedure and apparatus\n\nSame as in Study 1. The study was run using a custom Matlab script, PresentMate, based on the PsychToolbox-3 extension [@kleiner2007s; @brainard1997psychophysics; @pelli1997videotoolbox]. Visual fixations were recorded using a Tobii TX 300 eye-tracker and a 23-in screen of 1920 $\\times$ 1080 resolution. The Tobii Analytics SDK 3.0 was used to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 9-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented.\n\n\n\n### Data analysis\n\nSame as in Study 1, but removing the *Group* predictor from the models, as only monolingual infants were tested. \n\n\n::: {.cell}\n\n:::\n\n\nWe defined a time windows of interest from 200 ms after target and distractor pictures onset until the end of the trial at 2,000 ms when  both pictures disappeared from screen. To avoid modelling fixations driven by processes other than auditory word recognition [@fernald1998rapid; @fernald2001half]. Missing eye-tracker samples were interpolated using the last-observation-carried-forward [see @zettersten2022peekbank for a similar approach], with a maximum of 20 maximum consecutive missing samples being interpolated (an equivalent of 166.67 ms).\n\nWe gathered data from 3,484 trials from 110 testing sessions, generated from 97 distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples (equivalent to 750 ms) during the prime phase (*n* = 829) or 50% valid samples (equivalent to 1,000 ms) during the target-distractor phase (*n* = 650). We also excluded trials in which participants did not provide at least 5% of valid samples (equivalent to 100 ms) of target or distractor looking in the test phase (*n* = 1,003) [see @floccia2020translation for a similar approach].\n\nAfter trials that matched any of the aforementioned exclusion criteria from the dataset, we excluded participants who did not provide at least two valid trials in the *Cognate* condition, the *Non-cognate* condition, or the  *Unrelated* condition (*n* = 17). The final dataset included 1,904 trials from 80 testing sessions, generated by 81 distinct participants. Of those participants, 71 provided data from one experimental session, 10 provided data from two experimental sessions, and NA provided data from three experimental sessions. From the trials included in the final dataset dataset, 937 were *Unrelated* trials (512 previously excluded), were 479 *Related/Non-cognate* trials(246 previously excluded), and 488 were *Related/Cognate* trials (235 previously excluded).\n\n\n\n\n## Results\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-loos-oxf .cell}\n::: {.cell-output-display}\n\\begin{longtable}{lrrrr}\n\\toprule\nmodel & ELPD (diff.) & SE ELPD (diff) & ELPD & SE ELPD \\\\ \n\\midrule\n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{2\\}\\$ & $0.00$ & $0.00$ & $-8,538.07$ & $73.86$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{1\\}\\$ & $-0.21$ & $1.21$ & $-8,538.28$ & $73.86$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{3\\}\\$ & $-0.55$ & $1.56$ & $-8,538.62$ & $73.89$ \\\\ \n\\$\\textbackslash{}mathcal\\{M\\}\\_\\{0\\}\\$ & $-60.99$ & $15.99$ & $-8,599.06$ & $72.67$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n@tbl-loos summarises the outputs of the LOO-CV model comparisons. Models $\\mathcal{M}_{2}$, $\\mathcal{M}_{3}$, and $\\mathcal{M}_{4}$ showed substantially better predicted performance than models $\\mathcal{M}_{0}$ and $\\mathcal{M}_{1}$, which indicates that adding the *Condition* predictor improves significantly the fit of the models. All $\\mathcal{M}_{2}$, $\\mathcal{M}_{3}$, and $\\mathcal{M}_{4}$ models showed equivalent performance, suggesting that adding the two-way and three-way interactions between *Age*, *Group*, and *Condition*, did not improve the the fit of the model. We now report a description of the posterior distribution of the regression coefficients of model $\\mathcal{M}_{4}$. We report the median and 95% highest density interval of each fixed regression coefficient. \n\nThe outcomes of $\\mathcal{M}_{0}$, which only included *Age* and as main effect, revealed successful word recognition across participants. Overall, participants' looking time exceeded chance levels, as indicated by the fact that the 95% HDI of the intercept term excluded zero ($\\beta$ = , 95% HDI = ). The variability of participants' target preference varied significantly more between participants ($\\sigma$ = , 95% HDI = ) than within testing sessions from the same participant ($\\sigma$ = , 95% HDI = ). The 95% HDI of the coefficient of *Age* had a positive sign, but did not exclude zero ($\\beta$ = , 95% HDI = ), indicating that participants from all ages showed equivalent overall target word recognition.\n\n\nThe 95% HDI of the coefficient of *Group* in $\\mathcal{M}_{1}$ included zero ($\\beta$ = , 95% HDI = ), indicating an equivalent overall target preference in monolinguals and bilinguals. The 95% HDI of the first contrast of this predictor, comparing *Unrelated* and *Related/Non-cognate* trials, included zero ($\\beta$ = , 95% HDI = ). The 95% HDI of the second contrast, comparing *Related/Non-cognate* and *Related/Cognate* trials, also included zero ($\\beta$ = , 95% HDI = ). The overall target preference was equivalent across both pairwise condition comparisons. The interaction term between the first *Condition* contrast contained zero ($\\beta$ = , 95% HDI = ). The interaction term between the second *Condition* contrast also contained zero ($\\beta$ = , 95% HDI = ). The outcomes of this model indicate that lack of differences in overall target looking time across conditions remained across monolinguals and bilinguals.\n\nBoth younger and older participants showed equivalent looking time across conditions, as suggested by the fact that the 95% HDI of the two-way interaction between *Age* and the first *Condition* contrast included zero ($\\beta$ = , 95% HDI = ), as well as the interaction between *Age* and the second *Condition* contrast ($\\beta$ = , 95% HDI = ). This pattern of results was found in both monolinguals and bilinguals, as the 95% HDI of the three-way interaction between *Age*, *Group*, and *Condition* included zero both the first ($\\beta$ = , 95% HDI = ) and second ($\\beta$ = , 95% HDI = ) contrast of *Condition*.\n\n\n\n::: {.cell}\n\n:::\n\n\nAn analysis of the time course of target looking revealed a similar pattern of results (see @fig-epreds). Posterior mean prediction for the three conditions overlap across the full time course of the trial in both language groups, and also in both extrema of the age range of participants (20 and 32 months).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Posterior mean prdictions of the time course of target fixation in the test phase. Lines and intervals indicate the median and 95% credible interval of the posterior predictions, respectively.](manuscript_files/figure-pdf/fig-epreds-oxf-1.pdf){#fig-epreds-oxf}\n:::\n:::\n\n\nIn an exploratory analysis, we compared the model-estimated time points at which participants' gaze behaviour showed evidence of target looking above chance level (50%). We defined the recognition time of the trial as the earliest time point at which the lower bound of the 95% HDI posterior mean prediction of the target looking excluded zero. As expected, the recognition times were on average shorter for older infants than for younger infants. Differences between conditions were larger in bilinguals than in monolinguals, especially in the older group. The recognition time for monolingual 20-month-olds was  ms in the *Unrelated* condition,  ms in the *Related/Non-cognate* condition, and  ms in the *Related/Cognate* condition. In monolingual 30 month-olds, the recognition point was  ms in the *Unrelated* condition,  ms in the *Related/Non-cognate* condition, and  ms in the *Related/Cognate* condition. In bilingual 20 month-olds, the recognition point was  ms in the *Unrelated* condition,  ms in the *Related/Non-cognate* condition, and  ms in the *Related/Cognate* condition. In bilingual 30 month-olds, the recognition point was  ms in the *Unrelated* condition,  ms in the *Related/Non-cognate* condition, and  ms in the *Related/Cognate* condition.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Model-predicted recognition times for monlingual and bilinguals at 20 and 30 months of age.](manuscript_files/figure-pdf/fig-recognition-oxf-1.pdf){#fig-recognition-oxf}\n:::\n:::\n\n\n## Discussion\n\n# General discussion\n\n# References\n\n\n\n\n",
    "supporting": [
      "manuscript_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\r\n\\usepackage{longtable}\r\n\\usepackage{array}\r\n\\usepackage{multirow}\r\n\\usepackage{wrapfig}\r\n\\usepackage{float}\r\n\\usepackage{colortbl}\r\n\\usepackage{pdflscape}\r\n\\usepackage{tabu}\r\n\\usepackage{threeparttable}\r\n\\usepackage{threeparttablex}\r\n\\usepackage[normalem]{ulem}\r\n\\usepackage{makecell}\r\n\\usepackage{xcolor}\r\n\\usepackage{caption}\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}