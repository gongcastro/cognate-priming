{
  "hash": "cc6f287d96788673d3afa2f737cd4f44",
  "result": {
    "markdown": "::: {.cell}\n\n:::\n\n\n\n<!--\nThe formation of a mental lexicon is a critical developmental achievement for infants_ learning words allows infants to retrieve socially relevant concepts from fairly arbitrary linguistic forms embedded in speech.\n\nLearning words allows infants to access the rich world made of concepts through the recognition of fairly arbitrary linguistic forms, i.e., words. This remarkable developmental achievement is \n\nThe bilingual lexicon is language-non selective. \n\nThe role of cognates in lexical processing.\n\nHow does language co-activation shape lexical development?\n\nImplicit naming as a paradigm to study cross-language activation. (Mani & Plunkett, 2010, 2011a).\n\nFloccia et al. (2020) tested toddlers in a cross-language priming paradigm. A prime word was embedded at the end of a carrier sentence that participants listened to. Then participants were presented with the auditory label of the target word, and two pictures were shown side-by-side, the target picture, and a distractor picture. Some critiques:\n\n- Since participants heard the auditory label in one of the languages, priming through translation might be compromised.\n- Translation equivalents (Exp. 1) are more strongly related at the semantic level with each other than other pairs of semantically related words that are not translations of each other (table-mesa are more strongly associated than table-silla).\n- We used longitudinal participants, so we can examine the developmental trajectories of cross-language lateral inhibitory or excitatory connections better.\n- Larger sample size.\n-->\n\n\n# Methods\n\nAll materials, data, and reproducible code can be found at the OSF ([https://osf.io/hy984/](https://osf.io/ckydb/)) and GitHub ([https://github.com/gongcastro/cognate-priming](https://github.com/gongcastro/cognate-priming)) repositories. This study was conducted according to guidelines laid down in the Declaration of Helsinki, and was approved by the Drug Research Ethical Committee (CEIm) of the IMIM Parc de Salut Mar, reference 2020/9080/I. Before every testing session, caregivers were asked to read and sign an informed consent form, and were given a token of appreciation at the end of it.\n\n## Participants\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_participants_total <- length(unique(participants$id))\n\nn_participants_sessions <- count(participants, id, name = \"n_sessions\") |> \n\tcount(n_sessions) |> \n\tgroup_split(n_sessions) |> \n\tset_names(paste0(\"session_\", 1:3))\n\nn_sessions_total <- count(participants)\n\nn_sessions_age_group <- participants |> \n\tgroup_by(age_group) |> \n\tsummarise(across(age, lst(mean, sd, min, max)),\n\t\t\t  n = n(),\n\t\t\t  .groups = \"drop\") |> \n\tmutate(across(age_mean:age_max, \\(x) round(x, 2))) |> \n\tgroup_split(age_group) |> \n\tset_names(c(\"age_21\", \"age_25\", \"age_30\"))\n\nn_sessions_dominance <- count(participants, test_language) |> \n\tgroup_split(test_language) |> \n\tset_names(c(\"catalan\", \"spanish\"))\n\nn_sessions_dominance_age_group <- count(participants, age_group, test_language) |> \n\tgroup_split(test_language) |> \n\tset_names(c(\"catalan\", \"spanish\")) |> \n\tmap(\\(x) group_split(x, age_group) |> \n\t\t\tset_names(c(\"age_21\", \"age_25\", \"age_30\")))\n\nn_sessions_lp <- participants |> \n\tcount(lp) |> \n\tgroup_split(lp) |> \n\tset_names(c(\"monolingual\", \"bilingual\"))\n\nn_sessions_lp_age_group <- participants |> \n\tcount(lp, age_group) |> \n\tgroup_split(lp) |> \n\tset_names(c(\"monolingual\", \"bilingual\")) |> \n\tmap(\\(x) group_split(x, age_group) |> \n\t\t\tset_names(c(\"age_21\", \"age_25\", \"age_30\")))\n```\n:::\n\n\nWe collected data from 180 monolingual and bilingual participants living in the Metropolitan Area of Barcelona (Spain), who were exposed to at least Catalan and/or Spanish from birth. Families were recruited from maternity room in private hospitals in Barcelona, and contacted via phone when the child's age spanned between our age intervals of interest. Families were invited to participate at three age points: 21, 25, and 30 months. 94 participants were tested at one age point,  56 at two age points, and 30 at the three age points. In total, we gathered data from 296 testing sessions: 94 at 21 months (*Mean* = 20.98, *SD* = 0.97, *Range* = 20--26.35), 96 at 25 months (*Mean* = 25.15, *SD* = 0.99, *Range* = 23.35--30.77), and 106 at 30 months (*Mean* = 29.42, *SD* = 0.99, *Range* = 19.37--36.07). \n\n### Language profile {#sec-lp}\n\nWe assessed participants' language profile using the Language Exposure Questionnaire [LEQ, @bosch2001evidence]. Before each experimental session, the experimenter asked the caretakers to estimate the amount of hours per day they and other people in the infant's social circle have spent speaking to the infant in any language since birth. The output of this interview is an estimated degree of exposure (DoE) to each language, indicated by the proportion of time the infant was reported to have listened to each language. According to this estimate, we classified participants as Catalan- or Spanish-dominant if the language with highest DoE was Catalan or Spanish, respectively, and tested the participant in the stimuli set that contained words in their native language. We collected data from 178 Catalan-dominant participants in Catalan (52 at 21 months, 62 at 25 months, and 64 at 30 months). We further classified participants as monolinguals if the DoE to their dominant language exceeded 80% of the total DoE to Catalan and Spanish, and as bilinguals otherwise. Participants with DoE to language other than Catalan or Spanish were excluded from analyses. This divided the sample into 162 monolinguals ( at 21 months,  at 25 months, and  at 30 months), and 134 bilinguals ( at 21 months, 2, 2, 44 at 25 months, and 2, 3, 46 at 30 months). @tbl-participants-lp shows a detailed description of the linguistic profile of our sample.\n\n\n\n::: {#tbl-participants-lp .cell tbl-cap='Description of language profile of test participants. Data are summarised for each age group, and for monolinguals and bilinguals separately.'}\n\n```{.r .cell-code}\nparticipants |> \n\tfilter(is_valid_participant) |> \n\tselect(id, age_group, age, lp,\n\t\t   doe_catalan, doe_spanish, test_language) |> \n\tmutate(id = paste0(id, \" (\", age_group, \")\")) |>\n\tadd_count(lp, \n\t\t\t  name = \"n_lp\") |> \n\tadd_count(age_group, \n\t\t\t  name = \"n_age_group\") |> \n\tpivot_longer(starts_with(\"doe_\"),\n\t\t\t\t names_to = \"language\",\n\t\t\t\t values_to = \"doe\") |>\n\tadd_count(age_group,\n\t\t\t  test_language,\n\t\t\t  name = \"n_age_test\") |> \n\tmutate(language = str_to_sentence(str_remove_all(language, \"doe_\")),\n\t\t   age_group = paste0(age_group, \" (N = \", n_age_group, \")\"),\n\t\t   test_language = paste0(\"Tested in \", test_language, \n\t\t   \t\t\t\t\t   \" (N = \", n_age_test, \")\"),\n\t\t   lp = factor(lp, levels = rev(unique(lp))))  |> \n\tsummarise(across(c(doe, age), lst(mean, sd)),\n\t\t\t  .by = c(age_group, lp, test_language, language)) |> \n\tpivot_wider(id_cols = c(age_group, test_language),\n\t\t\t\tnames_from = c(language, lp),\n\t\t\t\tvalues_from = c(matches(\"doe\"), age_mean, age_sd),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\trelocate(age_group, test_language,\n\t\t\t matches(\"monolingual\"),\n\t\t\t matches(\"bilingual\")) |> \n\tselect(-c(age_mean_spanish_monolingual,\n\t\t\t  age_mean_spanish_bilingual,\n\t\t\t  age_sd_spanish_monolingual,\n\t\t\t  age_sd_spanish_bilingual)) |> \n\tarrange(age_group, test_language) |> \n\tgt(rowname_col = \"test_language\", \n\t   groupname_col = \"age_group\", \n\t   row_group.sep = \": \") |> \n\ttab_spanner(md(\"Monolingual (*N* = 162)\"), matches(\"monolingual\")) |> \n\ttab_spanner(md(\"Bilingual (*N* = 133)\"), matches(\"bilingual\")) |>\n\tfmt_number(matches(\"doe\"), decimals = 1, scale_by = 100) |> \n\tfmt_number(matches(\"age\"), decimals = 1) |> \n\tcols_merge_uncert(col_val = age_mean_catalan_monolingual, \n\t\t\t\t\t  col_uncert = age_sd_catalan_monolingual) |> \n\tcols_merge_uncert(col_val = age_mean_catalan_bilingual, \n\t\t\t\t\t  col_uncert = age_sd_catalan_bilingual) |> \n\tcols_merge_uncert(col_val = doe_mean_catalan_monolingual,\n\t\t\t\t\t  col_uncert = doe_sd_catalan_monolingual) |> \n\tcols_merge_uncert(col_val = doe_mean_catalan_bilingual,\n\t\t\t\t\t  col_uncert = doe_sd_catalan_bilingual) |> \n\tcols_merge_uncert(col_val = doe_mean_spanish_monolingual, \n\t\t\t\t\t  col_uncert = doe_sd_spanish_monolingual) |> \n\tcols_merge_uncert(col_val = doe_mean_spanish_bilingual, \n\t\t\t\t\t  col_uncert = doe_sd_spanish_bilingual) |> \n\tcols_label(age_mean_catalan_monolingual = \"Age (months)\",\n\t\t\t   age_mean_catalan_bilingual = \"Age (months)\",\n\t\t\t   doe_mean_catalan_monolingual = \"Catalan (%)\",\n\t\t\t   doe_mean_catalan_bilingual = \"Catalan (%)\",\n\t\t\t   doe_mean_spanish_monolingual = \"Spanish (%)\",\n\t\t\t   doe_mean_spanish_bilingual = \"Spanish (%)\") |> \n\ttab_style(cell_text(weight = \"bold\"),\n\t\t\t  list(cells_column_spanners())) |> \n\ttab_style(cell_text(size = \"medium\"),\n\t\t\t  list(cells_body(),\n\t\t\t  \t cells_stub()))\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrrr}\n\\toprule\n\\multicolumn{1}{l}{} & \\multicolumn{3}{c}{Monolingual (\\emph{N} = 162)} & \\multicolumn{3}{c}{Bilingual (\\emph{N} = 133)} \\\\ \n\\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n\\multicolumn{1}{l}{} & Catalan (\\%) & Spanish (\\%) & Age (months) & Catalan (\\%) & Spanish (\\%) & Age (months) \\\\ \n\\midrule\n\\multicolumn{7}{l}{21 months (N = 29)} \\\\ \n\\midrule\nTested in Catalan (N = 38) & $98.8$ ± $1.8$ & $1.2$ ± $1.8$ & $20.8$ ± $0.4$ & $61.6$ ± $7.3$ & $38.4$ ± $7.3$ & $21.1$ ± $0.4$ \\\\ \nTested in Spanish (N = 20) & $10.1$ ± $6.2$ & $89.9$ ± $6.2$ & $20.8$ ± $0.5$ & $56.0$ ± $17.0$ & $44.0$ ± $17.0$ & $20.4$ ± $0.3$ \\\\ \n\\midrule\n\\multicolumn{7}{l}{25 months (N = 45)} \\\\ \n\\midrule\nTested in Catalan (N = 68) & $85.5$ ± $25.1$ & $14.5$ ± $25.1$ & $25.1$ ± $0.5$ & $58.9$ ± $12.7$ & $40.3$ ± $13.1$ & $24.7$ ± $0.6$ \\\\ \nTested in Spanish (N = 22) & $45.9$ ± $44.3$ & $53.7$ ± $43.9$ & $25.5$ ± $0.4$ & $43.8$ ± $6.2$ & $55.2$ ± $6.2$ & $25.3$ ± $0.6$ \\\\ \n\\midrule\n\\multicolumn{7}{l}{30 months (N = 39)} \\\\ \n\\midrule\nTested in Catalan (N = 52) & $94.7$ ± $5.9$ & $5.3$ ± $5.8$ & $30.2$ ± $1.1$ & $59.7$ ± $8.8$ & $40.0$ ± $8.7$ & $29.6$ ± $1.3$ \\\\ \nTested in Spanish (N = 26) & $9.2$ ± $7.8$ & $89.4$ ± $6.6$ & $29.7$ ± $1.0$ & $42.5$ ± $12.2$ & $55.9$ ± $13.8$ & $29.9$ ± $1.1$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n## Vocabulary size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_imputed <- table(vocabulary$is_imputed)[2]\nprop_imputed <- scales::percent(n_imputed/nrow(vocabulary))\nn_pool <- nrow(bvq_data$vocabulary)\n```\n:::\n\n\nWe collected vocabulary data using parental responses to the Barcelona Vocabulary Inventory [BVQ, @garcia-castro2023bvq], an online vocabulary checklist inspired in several adaptations of the the Communicative Developmental Inventory [CDI, @fenson1994variability] developed to assess the vocabulary size of Catalan-Spanish bilingual toddlers. Families received a link to the BVQ immediately after each experimental session, and were given two weeks to fill it.\n\nWe calculated several measures of receptive vocabulary size from each participant's vocabulary: L1 vocabulary size (proportion of words  reported as acquired in the checklist of the dominant language), L2 vocabulary size (proportion of words  reported as acquired in the checklist of the non-dominant language), total vocabulary size (proportion of the words in both checklists reported as acquired), conceptual vocabulary (proportion of concepts for which the participant was reported to have acquired at least one label, in any language), and translation equivalent vocabulary (proportion of concepts for which the participant was reported to have acquired at two labels, one in each language).\n\n\n141 (48%) Families failed to provide a complete response to the BVQ within the two-week time limit, or did not provide a successful response to the questionnaire. For missing questionnaire responses, we imputed the vocabulary size of the participant using single imputation, using the vocabulary size scores of a pool of 600 additional participants for which a successful response for the questionnaire had been gathered. We used participants age in months and their language profile (monolingual/bilingual) as predictors. We used the `mice` R package [@van2011mice] to perform imputation using the Bayesian linear regression method. \n\n\n::: {#tbl-vocabulary .cell tbl-cap='Vocabulary sizes. Total: proportion of words in both languages marked as *Understands*. L1: proportion of words in the dominant language marked as *Understands*. L2: proportion of words in the non-cominant language marked as *Understands*. Conceptual: proportion of translation equivalents for which at least one of the words has ben marked as *Understands*. TE: proportion of translation equivalents for which *both* words have been marked as *Understands*.'}\n\n```{.r .cell-code}\nvocabulary |> \n\tleft_join(select(participants, filename, id, age_group, lp),\n\t\t\t  by = join_by(filename)) |> \n\tsummarise(across(matches(\"prop\"), \n\t\t\t\t\t tibble::lst(mean, sd)),\n\t\t\t  .by = c(age_group, lp)) |>\n\tarrange(age_group, lp) |> \n\tgt(groupname_col = \"age_group\",\n\t   rowname_col = \"lp\") |> \n\tcols_hide(lp) |> \n\ttab_spanner(\"Total \", matches(\"total\")) |> \n\ttab_spanner(\"L1\", matches(\"l1\")) |> \n\ttab_spanner(\"L2\", matches(\"l2\")) |> \n\ttab_spanner(\"Conceptual\", matches(\"concept\")) |> \n\ttab_spanner(\"TE\", matches(\"te_\")) |> \n\ttab_spanner(\"Vocabulary size (%)\", matches(\"prop_\")) |> \n\tcols_merge_uncert(total_prop_mean, total_prop_sd) |> \n\tcols_merge_uncert(l1_prop_mean, l1_prop_sd) |> \n\tcols_merge_uncert(l2_prop_mean, l2_prop_sd) |> \n\tcols_merge_uncert(concept_prop_mean, concept_prop_sd) |> \n\tcols_merge_uncert(te_prop_mean, te_prop_sd) |> \n\tfmt_number(is.numeric, \n\t\t\t   drop_trailing_zeros = FALSE) |> \n\tcols_label(total_prop_mean = \"Mean (SD)\",\n\t\t\t   l1_prop_mean = \"Mean (SD)\",\n\t\t\t   l2_prop_mean = \"Mean (SD)\",\n\t\t\t   concept_prop_mean = \"Mean (SD)\",\n\t\t\t   te_prop_mean = \"Mean (SD)\") |> \n\ttab_stub_indent(rows = everything(),\n\t\t\t\t\tindent = 2) |> \n\ttab_style(cell_text(align = \"left\"),\n\t\t\t  cells_stub())\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrr}\n\\toprule\n\\multicolumn{1}{l}{} & \\multicolumn{5}{c}{Vocabulary size (\\%)} \\\\ \n\\cmidrule(lr){2-6}\n\\multicolumn{1}{l}{} & Total  & L1 & L2 & Conceptual & TE \\\\ \n\\cmidrule(lr){2-2} \\cmidrule(lr){3-3} \\cmidrule(lr){4-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6}\n\\multicolumn{1}{l}{} & Mean (SD) & Mean (SD) & Mean (SD) & Mean (SD) & Mean (SD) \\\\ \n\\midrule\n\\multicolumn{6}{l}{21 months} \\\\ \n\\midrule\n\\hspace*{10px} Monolingual & $0.39$ ± $0.18$ & $0.53$ ± $0.18$ & $0.26$ ± $0.22$ & $0.61$ ± $0.18$ & $0.19$ ± $0.20$ \\\\ \n\\hspace*{10px} Bilingual & $0.42$ ± $0.23$ & $0.50$ ± $0.22$ & $0.42$ ± $0.24$ & $0.56$ ± $0.21$ & $0.33$ ± $0.23$ \\\\ \n\\midrule\n\\multicolumn{6}{l}{25 months} \\\\ \n\\midrule\n\\hspace*{10px} Monolingual & $0.55$ ± $0.22$ & $0.76$ ± $0.14$ & $0.48$ ± $0.29$ & $0.77$ ± $0.14$ & $0.39$ ± $0.27$ \\\\ \n\\hspace*{10px} Bilingual & $0.64$ ± $0.20$ & $0.71$ ± $0.17$ & $0.57$ ± $0.25$ & $0.75$ ± $0.20$ & $0.51$ ± $0.24$ \\\\ \n\\midrule\n\\multicolumn{6}{l}{30 months} \\\\ \n\\midrule\n\\hspace*{10px} Monolingual & $0.67$ ± $0.20$ & $0.81$ ± $0.16$ & $0.53$ ± $0.28$ & $0.83$ ± $0.15$ & $0.43$ ± $0.29$ \\\\ \n\\hspace*{10px} Bilingual & $0.76$ ± $0.18$ & $0.79$ ± $0.14$ & $0.71$ ± $0.23$ & $0.85$ ± $0.10$ & $0.64$ ± $0.21$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n## Stimuli\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_words <- length(unique(with(stimuli, unlist(prime, target, distractor))))\n```\n:::\n\n\nWe used 62 distinct words included in the BVQ to create the stimuli lists. We created six stimuli lists: three in Catalan, and three in Spanish. Each list contained 32 trials, each involving a prime-target-distractor group. Each word played a role as either prime, *or* as target and distractor across the three lists in their corresponding language. For instance, the Catalan word *cadira* appeared as *prime* in the three lists, but never as *target* or *distractor*; the Catalan word *bici* appeared as *target* and *distractor* across the three lists, but never as a prime. Target-distractor pairings were held constant across the three lists in each language. For instance, in all Catalan lists the word *bici* was paired with the word *porta*. Target-distractor pairings were also yoked, so that each member of the same target-distractor pair appeared once as target and once as distractor in each list. For instance, the *bici*-*porta* paired appeared twice in each of the three Catalan lists: once with *bici* as target and *porta* as distractor, and once with *porta* as target and *bici* as distractor. This counterbalancing avoided participants encountering looking at the target word guided solely by that word having being named in a previous trial. Finally, prime words appeared only once in each list: each target-distractor pair was associated with a different prime word in both appearances. In each list, the same prime word was presented alongside a different target-distractor pair. For instance, the Catalan prime word *barret* was presented with the *bici*-*porta* target-distractor pair in one list, with the *bici*-*porta* pair in another list, and with *berenar*-*amanida* in the remaining list. The order of the trials was randomised across experimental session, so that each time a participant was tested, the order in which the prime-target-distractor was presented was randomised. Each participant was randomly assigned to one of the three lists in the corresponding language (their dominant language, see @sec-lp), and always the same list across their experimental sessions in the case of a recurrent participant.\n\nIn 16 of the 32 trials of the same list (henceforth *related* trials), the prime and the target words were phonologically related, sharing phonological onset (at least first phoneme). In the other 16 trials (*unrelated* trials), prime and target did not share phonological onset. 8 of the 16 *related* trials included a cognate prime (*cognate* trials), and the other 8 included a non-cognate trials (*non-cognate* trials). A prime word was considered cognate if its Catalan and Spanish translation shared phonological onset. Especial attention was paid to avoiding semantic or taxonomic relationships between prime and target words, and between prime and distractor words. Target and distractor word pairs were phonologically unrelated (did not share phonological onset). Some of them shared semantic features or a taxonomic relationship. This is the case of words associated with especially salient referents such as animals or food. To avoid infants guiding their gaze to these objects based on their saliency, we paired animals and food items together. The position of the target and distractor pictures (right or left) for each target-distractor pair was alternated, so that in one list the target would appear on the left, in another list it would appear on the right, and so on.\n\nWe examined the overall equivalence of the three trial types by comparing them across three variables relating to the target word: lexical frequency, word prevalence, animacy\n@tbl-stimuli shows a detailed summary of the stimuli properties, broken down by trial type and testing language. Lexical frequencies were extracted from the Catalan and Spanish corpora of the CHILDES database [@reference; @reference] as counts per million words, and transformed into Zipf scores for easier cross-language comparison [@reference; @reference]. We defined word prevalence as the proportion of same-aged infants who were reported to understand the word in the BVQ database.\n\n\n### Auditory stimuli\n\nThe auditory stimuli were natural exemplars of the selected target words, spoken by Catalan-Spanish proficient bilingual female speaker who was instructed to pronounce each word in a toddler-directed manner. Recordings were made with an Audio-Tecnica 328 microphone (AT2050) at a sampling rate of 44100 Hz, in a soundproof room at the *Laboratori de Recerca en Infancia* at University Pompeu Fabra. We used the Audacity [@reference] and Praat [@boersma2001speak] to record and edit the audio files. The speaker was presented with a list of words in Catalan. The order of the words was pseudo-randomised, and each word was produced three times in a row before moving to the next word in the list. After going through all the words in the list, the speaker went through the word list again generating three tokens for each word, now in an inverse order (from bottom of the list to the top). We then repeated the same procedure for the list of Spanish words. The resulting audios were manually chunked into individual word-forms. For each of the six tokens produced for each word, the most adequate was selected for further processing. The audios were then transformed to stereo by duplicating them into two channels, denoised, and finally normalised. The mean duration of the final audios was 1.23 (*SD* = 0.17) and 1.08 (*SD* = 0.14) seconds for the Catalan and Spanish lists.\n\nTo make the pronunciation of the words as familiar as possible to each infant, we generated additional pronunciation variants for some words in Catalan and Spanish. Catalan words involving the /\\textipa{L}/ phoneme in their Central Catalan variant (e.g., /\\textipa{'Lu.n@}) were also recorded with such phoneme replaced by /j/ (e.g., /\\textipa{'ju.n@}), a phonological process common in the Metropolitan Area of Barcelona [@reference]. Spanish words involving the /\\textipa{T}/ phoneme were also generated replacing such phoneme with /\\textipa{s}/ to better accommodate Latin variants of Spanish. Before every experimental session, caregivers were asked to utter three written words involving the /\\textipa{L}/ phoneme (in the case of participants tested in Catalan) or the /\\textipa{T}/ phoneme (in the case of participants tested in Spanish). Each token contained the critical phoneme at onset, inter-vocalic position, and coda. The experimenter assigned the participant to the Catalan or Spanish stimuli list involving the closest variant to that of caregivers'.\n\n\n### Visual stimuli\n\nFor each word, we created a picture with a typical referent. To avoid competition between target and distractor pictures, semantically related target-distractor pairs were perceptually distinct [@floccia2020translation; @arias-trejo2010].\n\n\n::: {#tbl-stimuli .cell tbl-cap='Summary of stimuli properties by trial type.'}\n\n```{.r .cell-code}\nstimuli |> \n\tsummarise(across(c(matches(\"familiarity_|freq_|animate_\"), duration),\n\t\t\t\t\t tibble::lst(mean, sd, min, max)),\n\t\t\t  .by = c(test_language, trial_type)) |> \n\tselect(-matches(\"familiarity_se\"), -matches(\"prime\"),\n\t\t   -c(is_animate_target_sd,\n\t\t      is_animate_target_min,\n\t\t      is_animate_target_max)) |> \n\tgt(groupname_col = \"test_language\",\n\t   rowname_col = \"list\") |> \n\ttab_spanner(\"Prevalence (%)\", matches(\"familiarity\")) |> \n\ttab_spanner(\"Frequency (Zipf)\", matches(\"freq\")) |>\n\ttab_spanner(\"Animacy (%)\", matches(\"animate\")) |> \n\ttab_spanner(\"Duration (s)\", matches(\"duration\")) |> \n\tfmt_number(is.numeric) |> \n\tcols_merge_range(familiarity_target_min, familiarity_target_max) |> \n\tcols_merge_range(freq_target_min, freq_target_max) |> \n\tcols_merge_range(duration_min, duration_max) |>\n\tcols_merge_uncert(freq_target_mean, freq_target_sd) |> \n\tcols_merge_uncert(familiarity_target_mean, familiarity_target_sd) |> \n\tcols_merge_uncert(duration_mean, duration_sd) |> \n\tcols_label(trial_type = \"\",\n\t\t\t   familiarity_target_mean = \"Mean ± SD\",\n\t\t\t   # familiarity_target_sd = \"SD\",\n\t\t\t   familiarity_target_min = \"Range\",\n\t\t\t   freq_target_mean = \"Mean ± SD\",\n\t\t\t   # freq_target_sd = \"SD\",\n\t\t\t   freq_target_min = \"Range\",\n\t\t\t   is_animate_target_mean = \"\",\n\t\t\t   duration_mean = \"Mean ± SD\",\n\t\t\t   # duration_sd = \"SD\",\n\t\t\t   duration_min = \"Range\") \n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lrrrrrrr}\n\\toprule\n & \\multicolumn{2}{c}{Prevalence (\\%)} & \\multicolumn{2}{c}{Frequency (Zipf)} & Animacy (\\%) & \\multicolumn{2}{c}{Duration (s)} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n & Mean ± SD & Range & Mean ± SD & Range &  & Mean ± SD & Range \\\\ \n\\midrule\n\\multicolumn{8}{l}{Catalan} \\\\ \n\\midrule\nCognate & $0.37$ ± $0.18$ & $0.09$–$0.84$ & $3.90$ ± $0.61$ & $3.04$–$5.05$ & $0.21$ & $1.20$ ± $0.17$ & $0.86$–$1.55$ \\\\ \nNon-cognate & $0.38$ ± $0.16$ & $0.09$–$0.84$ & $3.90$ ± $0.52$ & $3.04$–$5.05$ & $0.25$ & $1.25$ ± $0.17$ & $0.88$–$1.55$ \\\\ \nUnrelated & $0.36$ ± $0.15$ & $0.09$–$0.84$ & $3.86$ ± $0.58$ & $2.94$–$5.05$ & $0.22$ & $1.23$ ± $0.17$ & $0.86$–$1.55$ \\\\ \n\\midrule\n\\multicolumn{8}{l}{Spanish} \\\\ \n\\midrule\nCognate & $0.29$ ± $0.13$ & $0.04$–$0.50$ & $4.21$ ± $0.51$ & $2.94$–$5.11$ & $0.10$ & $1.11$ ± $0.14$ & $0.85$–$1.45$ \\\\ \nNon-cognate & $0.30$ ± $0.14$ & $0.04$–$0.50$ & $4.27$ ± $0.53$ & $2.94$–$5.11$ & $0.15$ & $1.09$ ± $0.14$ & $0.83$–$1.45$ \\\\ \nUnrelated & $0.28$ ± $0.14$ & $0.04$–$0.50$ & $4.23$ ± $0.46$ & $2.94$–$5.11$ & $0.17$ & $1.07$ ± $0.15$ & $0.83$–$1.54$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n## Procedure\n\nTesting took place in a sound-proof room. Participants sat on their caregivers' lap in a dimly lit testing booth while the experimenter conducted the experiment from outside. Caregivers were instructed to keep their eyes shut (to avoid recording their gaze, instead of the participant's), to be still, and to avoid interacting with the participant verbally or non-verbally. Participants sat at approximately 65 cm from the eye-tracker and a XX-in screen of $1929\\times1080$ screen resolution. We used a custom Matlab XXXX script using the PsychToolbox XXX extension [@brainard] to present the stimuli, and the Tobii Analytics SDK 3.0 to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 5-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented. We set a 55% grey background for the calibration and stimuli presentation. Auditory stimuli were presented through two loudspeakers located behind the screen, one to each side. The experimenter monitored the experimental from outside the room using a centrally located video camera place above the screen. After a successful calibration the experimenter triggered the onset of the first trial. Trials were presented uninterruptedly and  without intervention of the experimenter until the 32 trials were presented, or the experimental session had to be stopped because of the participant's behaviour.\n\nEach trial started with the presentation of an attention getter for 3,000 milliseconds. Then, the prime picture was presented in silence in the centre of the screen for 1,500 milliseconds. Fifty milliseconds after the offset of the prime image, an auditory label was played from the loudspeakers and, 700 milliseconds after the onset of the auditory label, the target and distractor pictures were presented side-by-side during 1,000 milliseconds until the end of the trial. After this, the attention getter of the next trial was immediately presented. Each experimental session took approximately 10 minutes.\n\n## Data analysis\n\nWe defined our time window of interest from 300 ms after the onset of the test phase (target and distractor presentation) until the end of the test phase (2,000 ms). For each trial, we chunked the time domain into 17 time bins of 100 ms of duration. We then calculated, for each experimental session, time bin, and condition, participant's proportion of target and distractor fixations. Finally, we computed the empirical logit of target fixations, which we introduced in the statistical analyses as our response variable. Missing eye-tracker samples were interpolated using the last-observation-carried-forward [see @zettersten2022peekbank for a similar approach].\n\nWe conducted two main analyses. First, we estimated the effect of phonological priming on participants' target looking, comparing *related* trials with *unrelated* trials. This analysis included all trials on the data set. Second, we estimated the effect of cognateness on phonological priming, comparing *cognate* with *non-cognate* trials, leaving out *unrelated* trials. In both analyses, we used General Additive Mixed Models (GAMMs) to model the probability of target fixations across the time course of the trial using a normal distribution.\n\nIn the first analysis. We included *Relatedness* (`Related` vs. `Unrelated`, sum-coded as `-0.5` and `+0.5`), *Group* (`Monolingual` vs. `Bilingual`, sum-coded as `-0.5` and `+0.5`), and *Age* (participants' standardised age in months) as fixed, main effects. We also included cubic regression splines for the main effect of *Time*, and one for an adjustment of the previous cubic spline by *Group* [@wood2017generalized]. For both splines, we specified $k = 10$ basis functions or *knots*--half the number of time bins, for computational convenience. Finally, we added by-participant random intercepts, and random slopes for the main effect of *Relatedness* and the main effect of *Age*, both including repeated measures per participant.\n\nTo test the contribution of each of the predictors of interest--*Relatedness*/*Cognateness*, and *Group*--, we compared each model ($\\mathcal{M_0}$) against a simplified model dropping each of the main effects, *Relatedness*/*Cognateness* ($\\mathcal{M}_1$) or *Group* ($\\mathcal{M_2}$). In both simplified models, the interaction term was dropped. We used leave-one-out cross-validation (LOO-CV) as a benchmark of model performance, using Pareto-smoothed importance sampling (PSIS) to approximate it. We then examined the posterior predictions of the best-performing model for interpretation.\n\n$$\n\\begin{aligned}\n\\textbf{Likelihood:} \\\\\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma_i) \\\\ \\\\\n\\textbf{Linear model} \\\\\n\\text{logit}(\\mu_i) &= (\\beta_0 + u _{0_{i}}) + (\\beta_1 + u _{1_{i}}) \\cdot \\text{Relatedness} + \\beta_{2} \\cdot \\text{Group} + \\\\\n&\\beta_{3} \\cdot (\\text{Relatedness} \\times \\text{Group}) + (\\beta_4 + u_{3_{i}}) \\cdot \\text{Age} + \\\\\n&\\sum_{j = 1}^k b_{j_{1}}(\\beta_{5_{k}} + u_{4_{i}}) \\cdot \\text{Time} + \\\\\n&\\sum_{j = 1}^k b_{j_{1}} (\\beta_{6_{k }} + u_{5_{i}}) \\cdot (\\text{Time} \\times \\text{Group}) \\\\\n\\text{where:} \\\\\n&k \\text{ is the number of knots in the spline (10)} \\\\\n\\textbf{Prior:} \\\\\n\\beta_{0-6} &\\sim \\mathcal{N}(0, 1) \\\\\nb_{0-1} &\\sim MVN(0, 1) \\\\\n\\sigma_i &\\sim Exp(4) \n\\end{aligned}\n$$\n\n# Results\n\nWe know present the results under four different trial-level inclusion criteria In Analysis 1, the child is required to understand the prime *and* the target words, on top of having to fixate both target and distractor  for at last 50 ms each during the target-distractor phase. In Analysis 2, the child is required to understand the target word, on top of having to fixate both target and distractor  for at last 50 ms each during the target-distractor phase. In Analysis 3, the child is not required to understand any word, but is still required to fixate both target and distractor for at last 50 ms each during the target-distractor phase. In Analysis 4, the child is not required to understand any word, nor to fixate at both target and distractor.\n\nFor reference:\n\n* [@floccia2020] requires participants to know prime and target, but not to look at target *and* distractor (looking at at least one of them is enough).\n\nThe fact that in some time course analyses participants seem to be looking predominantly towards one of the objects (despite the target and distractor pictures having been presented less than 300 ms before) is a common finding in previous studies using preferential looking procedures [e.g., @floccia2020translation].\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::lst(data_time_related,\n\t\t\tdata_time_related_vtarget,\n\t\t\tdata_time_related_vnone,\n\t\t\tdata_time_related_noeach,\n\t\t\tdata_time_related_vnoeach) |> \n\tbind_rows(.id = \"analysis\") |>\n\tmutate(analysis = case_when(\n\t\tanalysis==\"data_time_related\" ~ \"Analysis 1\",\n\t\tanalysis==\"data_time_related_vtarget\" ~ \"Analysis 2\",\n\t\tanalysis==\"data_time_related_vnone\" ~ \"Analysis 3\",\n\t\tanalysis==\"data_time_related_noeach\" ~ \"Analysis 4\",\n\t\tanalysis==\"data_time_related_vnoeach\" ~ \"Analysis 5\"\n\t)) |> \n\t# summarise(.elog_mean = mean(.elog),\n\t# \t\t  n = n(),\n\t# \t\t  .elog_std = sd(.elog),\n\t# \t\t  .by = c(condition, timebin, analysis, lp)) |>\n\t# mutate(.elog_se = .elog_std/n) |> \n\tggplot(aes(timebin, .elog,\n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition)) +\n\tfacet_grid(analysis~lp) +\n\tgeom_hline(yintercept = 0.5, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tgeom_smooth(method = lm, \n\t\t\t\tse = FALSE, \n\t\t\t\tformula = y ~ splines::bs(x, 4)) +\n\t# geom_errorbar(aes(ymin = .elog_mean - .elog_se*1.96, \n\t# \t\t\t\t  ymax = .elog_mean + .elog_se*1.96),\n\t# \t\t\t  width = 0.25,\n\t# \t\t\t  linewidth = 3/4) + \n\t# geom_line(size = 3/4) + \n\tstat_summary(fun = mean, geom = \"point\") +\n\tstat_summary(fun.data = mean_se,\n\t\t\t\t geom = \"errorbar\",\n\t\t\t\t width = 0.25) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Condition\",\n\t\t fill = \"Condition\",\n\t\t linetype = \"Condition\",\n\t\t shape = \"Condition\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) +\n\t# scale_shape_manual(values = c(1, 2)) +\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-related-summary-1.pdf){#fig-related-summary fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::lst(data_time_cognate,\n\t\t\tdata_time_cognate_vtarget,\n\t\t\tdata_time_cognate_vnone,\n\t\t\tdata_time_cognate_noeach,\n\t\t\tdata_time_cognate_vnoeach) |> \n\tbind_rows(.id = \"analysis\") |>\n\tmutate(analysis = case_when(\n\t\tanalysis==\"data_time_cognate\" ~ \"Analysis 1\",\n\t\tanalysis==\"data_time_cognate_vtarget\" ~ \"Analysis 2\",\n\t\tanalysis==\"data_time_cognate_vnone\" ~ \"Analysis 3\",\n\t\tanalysis==\"data_time_cognate_noeach\" ~ \"Analysis 4\",\n\t\tanalysis==\"data_time_cognate_vnoeach\" ~ \"Analysis 5\"\n\t)) |> \n\t# summarise(.elog_mean = mean(.elog),\n\t# \t\t  n = n(),\n\t# \t\t  .elog_std = sd(.elog),\n\t# \t\t  .by = c(condition, timebin, analysis, lp)) |>\n\t# mutate(.elog_se = .elog_std/n) |> \n\tggplot(aes(timebin, .elog,\n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition)) +\n\tfacet_grid(analysis~lp) +\n\tgeom_hline(yintercept = 0.5, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tgeom_smooth(method = lm, \n\t\t\t\tse = FALSE, \n\t\t\t\tformula = y ~ splines::bs(x, 4)) +\n\t# geom_errorbar(aes(ymin = .elog_mean - .elog_se*1.96, \n\t# \t\t\t\t  ymax = .elog_mean + .elog_se*1.96),\n\t# \t\t\t  width = 0.25,\n\t# \t\t\t  linewidth = 3/4) + \n\t# geom_line(size = 3/4) + \n\tstat_summary(fun = mean, geom = \"point\") +\n\tstat_summary(fun.data = mean_se,\n\t\t\t\t geom = \"errorbar\",\n\t\t\t\t width = 0.25) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Condition\",\n\t\t fill = \"Condition\",\n\t\t linetype = \"Condition\",\n\t\t shape = \"Condition\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) +\n\t# scale_shape_manual(values = c(1, 2)) +\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-cognate-summary-1.pdf){#fig-cognate-summary fig-pos='H'}\n:::\n:::\n\n## Analysis 1\n\nParticipants must know **prime** *and* **target** words, and must look at least 10 ms to each target and distractor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_trials <- nrow(attrition_trials)\nn_total <- n_distinct(attrition_trials$id)\nn_trials_valid <- inner_join(attrition_participants,\n\t\t\t\t\t\t\t attrition_trials,\n\t\t\t\t\t\t\t by = join_by(id)) |> \n\tfilter(is_valid_participant) |> \n\tpull(is_valid_trial) |> \n\tsum()\nn_participants_valid <- sum(attrition_participants$is_valid_participant)\nn_exc_prime <- sum(!attrition_trials$is_valid_gaze_prime)\nn_exc_test <- sum(!attrition_trials$is_valid_gaze_test)\nn_exc_test_each <- sum(!attrition_trials$is_valid_gaze_test_each)\nn_exc_vocab <- sum(!attrition_trials$is_valid_vocab)\nn_exc_cognate <- sum(!attrition_participants$is_valid_cognate)\nn_exc_noncognate <- sum(!attrition_participants$is_valid_noncognate)\nn_exc_unrelated <- sum(!attrition_participants$is_valid_unrelated)\n\nn_longitudinal <- attrition_participants |>\n\tfilter(is_valid_participant) |>\n\tcount(id, name = \"times\") |> \n\tcount(times)\n```\n:::\n\n\n\nWe gathered data from 9,472 trials from 180 distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = 1,810) or during the target-distractor phase (*n* = 1,493). We also excluded trials in which participants did not provide at least 5% of valid samples to *both* target and distractor in the test phase (*n* = 2,793). Finally, we excluded trials in which participants did not understand the prime *or* the target word, according to a supplementary vocabulary checklist filled by their caregivers upon experiment completion (*n* = 5,884). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = 173), the *non-cognate prime* condition (*n* = 168), or the *unrelated prime* condition (*n* = 157). The resulting dataset included 3,393 trials from 113 participants. Of those participants, 60 provided data from one experimental session, 19 provided data from two experimental sessions, and 5 provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.\n\n\n\n::: {#tbl-attrition-trials .cell tbl-cap='Trial attrition rate by condition for included participants. Additional excluded trials are indicated between parentheses.'}\n\n```{.r .cell-code}\nattrition_trials |> \n\tfilter(id %in% attrition_participants$id[attrition_participants$is_valid_participant]) |> \n\tleft_join(select(participants, filename, id, age_group),\n\t\t\t  by = join_by(filename, id, age_group)) |> \n\tsummarise(n_valid = sum(is_valid_trial),\n\t\t\t  n_total = n(),\n\t\t\t  .by = c(id, age_group, trial_type)) |> \n\tsummarise(across(n_valid, lst(sum, mean, sd),\n\t\t\t\t\t .names = \"{.fn}\"),\n\t\t\t  n_total = sum(n_total),\n\t\t\t  .by = c(age_group, trial_type)) |> \n\tmutate(n_excluded = n_total-sum) |> \n\tselect(-c(n_total)) |> \n\tpivot_wider(names_from = trial_type,\n\t\t\t\tvalues_from = c(sum:sd, n_excluded),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\trename_with(\\(x) gsub(\"non_cognate\", \n\t\t\t\t\t\t  \"noncognate\",\n\t\t\t\t\t\t  x)) |> \n\tarrange(age_group) |> \n\trelocate(age_group,\n\t\t\t matches(\"_cognate\"),\n\t\t\t matches(\"noncognate\")) |> \n\tgt(rowname_col = \"age_group\") |> \n\tgrand_summary_rows(columns = matches(\"mean_\"),\n\t\t\t\t\t   fns = lst(Mean ~ mean(.)),\n\t\t\t\t\t   fmt = ~fmt_number(.)) |>\n\tgrand_summary_rows(columns = matches(\"sum_\"),\n\t\t\t\t\t   fns = lst(Sum ~ sum(.)),\n\t\t\t\t\t   fmt = ~fmt_integer(.)) |>\n\tcols_merge(c(sum_cognate, n_excluded_cognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_noncognate, n_excluded_noncognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_unrelated, n_excluded_unrelated),\n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge_uncert(mean_cognate, sd_cognate) |> \n\tcols_merge_uncert(mean_noncognate, sd_noncognate) |> \n\tcols_merge_uncert(mean_unrelated, sd_unrelated) |> \n\ttab_spanner(\"Cognate trials\", ends_with(\"_cognate\")) |>\n\ttab_spanner(\"Non-cognate trials\", ends_with(\"noncognate\")) |> \n\ttab_spanner(\"Unrelated trials\", ends_with(\"unrelated\")) |> \n\ttab_spanner(\"Related trials\", matches(\"cognate\")) |>\n\tfmt_number(matches(\"mean|sd\")) |> \n\tfmt_integer(matches(\"sum\"), sep_mark = \",\") |> \n\tcols_label(sum_cognate = \"N\",\n\t\t\t   sum_noncognate = \"N\",\n\t\t\t   sum_unrelated = \"N\",\n\t\t\t   mean_cognate = \"Mean\",\n\t\t\t   mean_noncognate = \"Mean\",\n\t\t\t   mean_unrelated = \"Mean\")\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrrr}\n\\toprule\n\\multicolumn{1}{l}{} & \\multicolumn{4}{c}{Related trials} &  &  \\\\ \n\\cmidrule(lr){2-5}\n\\multicolumn{1}{l}{} & \\multicolumn{2}{c}{Cognate trials} & \\multicolumn{2}{c}{Non-cognate trials} & \\multicolumn{2}{c}{Unrelated trials} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n\\multicolumn{1}{l}{} & N & Mean & N & Mean & N & Mean \\\\ \n\\midrule\n21 months & $131$ (245) & $2.79$ ± $2.25$ & $140$ (236) & $2.98$ ± $1.98$ & $237$ (515) & $5.04$ ± $3.61$ \\\\ \n25 months & $208$ (272) & $3.47$ ± $2.28$ & $203$ (277) & $3.38$ ± $2.37$ & $369$ (591) & $6.15$ ± $4.03$ \\\\ \n30 months & $218$ (230) & $3.89$ ± $2.89$ & $214$ (234) & $3.82$ ± $2.80$ & $379$ (517) & $6.77$ ± $5.08$ \\\\ \n\\midrule \n\\midrule \nMean & — & $3.38$ & — & $3.39$ & — & $5.99$ \\\\ \nSum & $557$ & — & $557$ & — & $985$ & — \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n### Phonological priming: Related vs. Unrelated\n\nA model including the *Relatedness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Relatedness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -5.146, *SE* = 4.634). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_2}}$ = -55.182, *SE* = 42.373). This indicates that including the *Relatedness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_related$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_related$age),\n\t\t\t\t\t  lp = levels(data_time_related$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_related[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA, \n\t\t\t\t\tvalue = \".value\") |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .value,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = related - unrelated) \n\n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tmutate(is_cluster = .lower > 0 | .upper < 0) \n# \n# clusters <- rle(diff(diff_rect$is_cluster))\n# diff_rect$cluster_id <- c(0, rep(clusters$values, clusters$lengths))\n# \n# diff_rect <- diff_rect |> \n# \tarrange(lp, timebin)\n# \n# diff_rect <- \n# \tcluster_number = \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = c(lp, is_cluster)) |> \n# \tfilter(is_cluster)\n\n# diff_obs <- data_time_related |>\n# \tpivot_wider(names_from = condition, \n# \t\t\t\tvalues_from = elog,\n# \t\t\t\tnames_repair = janitor::make_clean_names) |> mutate(diff = related - unrelated)\n\ndata_time_related |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition,\n\t\t\t   linetype = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .value),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .value,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 1/2, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Condition\",\n\t\t fill = \"Condition\",\n\t\t linetype = \"Condition\",\n\t\t shape = \"Condition\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\t# geom_point(data = diff_obs) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-related-1.pdf){#fig-related fig-pos='H'}\n:::\n:::\n\n\n\n\n### Cognate priming: Cognate vs. Non-cognate\n\nA model including the *Cognateness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Cognateness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -25.189, *SE* = 5.023). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -60.098, *SE* = 41.472). This indicates that including the *Cognateness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_cognate$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_cognate$age),\n\t\t\t\t\t  lp = levels(data_time_cognate$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_cognate[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA) |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .epred,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = cognate - non_cognate) \n# \n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tfilter(.lower > 0 | .upper < 0) |> \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = lp)\n\ndata_time_cognate |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -1.5,\n\t# \t\t  \tymax = 1.5),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .epred),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .epred,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0.5, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Prime type\",\n\t\t fill = \"Prime type\",\n\t\t linetype = \"Prime type\",\n\t\t shape = \"Prime type\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -3/4,\n\t# \t\t  \tymax = 3/4),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-cognate-1.pdf){#fig-cognate fig-pos='H'}\n:::\n:::\n\n\n## Analysis 2\n\nParticipants must know the target **target** word (no need to know the prime word), and must look at least 10 ms to each target and distractor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_trials <- nrow(attrition_trials_vtarget)\nn_trials_valid <- inner_join(attrition_participants_vtarget,\n\t\t\t\t\t\t\t attrition_trials_vtarget) |> \n\tfilter(is_valid_participant) |> \n\tpull(is_valid_trial) |> \n\tsum()\nn_participants_valid <- sum(attrition_participants_vtarget$is_valid_participant)\nn_exc_prime <- sum(!attrition_trials_vtarget$is_valid_gaze_prime)\nn_exc_test <- sum(!attrition_trials_vtarget$is_valid_gaze_test)\nn_exc_test_each <- sum(!attrition_trials_vtarget$is_valid_gaze_test_each)\nn_exc_vocab <- sum(!attrition_trials_vtarget$is_valid_vocab)\nn_exc_cognate <- sum(!attrition_participants_vtarget$is_valid_cognate)\nn_exc_noncognate <- sum(!attrition_participants_vtarget$is_valid_noncognate)\nn_exc_unrelated <- sum(!attrition_participants_vtarget$is_valid_unrelated)\n\nn_longitudinal <- attrition_participants_vtarget |>\n\tfilter(is_valid_participant) |>\n\tcount(id, name = \"times\") |> \n\tcount(times)\n```\n:::\n\n\n\nWe gathered data from 9,472 trials from 180 distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = 1,810) or during the target-distractor phase (*n* = 1,493). We also excluded trials in which participants did not provide at least 5% of valid samples to *both* target and distractor in the test phase (*n* = 2,793). Finally, we excluded trials in which participants did not understand the target word, according to a supplementary vocabulary checklist filled by their caregivers upon experiment completion (*n* = 5,539). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = 165), the *non-cognate prime* condition (*n* = 165), or the *unrelated prime* condition (*n* = 151). The resulting dataset included 2,219 trials from 121 participants. Of those participants, 62 provided data from one experimental session, 22 provided data from two experimental sessions, and 5 provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.\n\n\n\n::: {#tbl-attrition-trials-vtarget .cell tbl-cap='Trial attrition rate by condition for included participants. Additional excluded trials are indicated between parentheses.'}\n\n```{.r .cell-code}\nattrition_trials_vtarget |> \n\tfilter(id %in% attrition_participants_vtarget$id[attrition_participants_vtarget$is_valid_participant]) |> \n\tleft_join(select(participants, filename, id, age_group),\n\t\t\t  by = join_by(filename, id, age_group)) |> \n\tsummarise(n_valid = sum(is_valid_trial),\n\t\t\t  n_total = n(),\n\t\t\t  .by = c(id, age_group, trial_type)) |> \n\tsummarise(across(n_valid, lst(sum, mean, sd),\n\t\t\t\t\t .names = \"{.fn}\"),\n\t\t\t  n_total = sum(n_total),\n\t\t\t  .by = c(age_group, trial_type)) |> \n\tmutate(n_excluded = n_total-sum) |> \n\tselect(-c(n_total)) |> \n\tpivot_wider(names_from = trial_type,\n\t\t\t\tvalues_from = c(sum:sd, n_excluded),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\trename_with(\\(x) gsub(\"non_cognate\", \n\t\t\t\t\t\t  \"noncognate\",\n\t\t\t\t\t\t  x)) |> \n\tarrange(age_group) |> \n\trelocate(age_group,\n\t\t\t matches(\"_cognate\"),\n\t\t\t matches(\"noncognate\")) |> \n\tgt(rowname_col = \"age_group\") |> \n\tgrand_summary_rows(columns = matches(\"mean_\"),\n\t\t\t\t\t   fns = lst(Mean ~ mean(.)),\n\t\t\t\t\t   fmt = ~fmt_number(.)) |>\n\tgrand_summary_rows(columns = matches(\"sum_\"),\n\t\t\t\t\t   fns = lst(Sum ~ sum(.)),\n\t\t\t\t\t   fmt = ~fmt_integer(.)) |>\n\tcols_merge(c(sum_cognate, n_excluded_cognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_noncognate, n_excluded_noncognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_unrelated, n_excluded_unrelated),\n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge_uncert(mean_cognate, sd_cognate) |> \n\tcols_merge_uncert(mean_noncognate, sd_noncognate) |> \n\tcols_merge_uncert(mean_unrelated, sd_unrelated) |> \n\ttab_spanner(\"Cognate trials\", ends_with(\"_cognate\")) |>\n\ttab_spanner(\"Non-cognate trials\", ends_with(\"noncognate\")) |> \n\ttab_spanner(\"Unrelated trials\", ends_with(\"unrelated\")) |> \n\ttab_spanner(\"Related trials\", matches(\"cognate\")) |>\n\tfmt_number(matches(\"mean|sd\")) |> \n\tfmt_integer(matches(\"sum\"), sep_mark = \",\") |> \n\tcols_label(sum_cognate = \"N\",\n\t\t\t   sum_noncognate = \"N\",\n\t\t\t   sum_unrelated = \"N\",\n\t\t\t   mean_cognate = \"Mean\",\n\t\t\t   mean_noncognate = \"Mean\",\n\t\t\t   mean_unrelated = \"Mean\")\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrrr}\n\\toprule\n\\multicolumn{1}{l}{} & \\multicolumn{4}{c}{Related trials} &  &  \\\\ \n\\cmidrule(lr){2-5}\n\\multicolumn{1}{l}{} & \\multicolumn{2}{c}{Cognate trials} & \\multicolumn{2}{c}{Non-cognate trials} & \\multicolumn{2}{c}{Unrelated trials} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n\\multicolumn{1}{l}{} & N & Mean & N & Mean & N & Mean \\\\ \n\\midrule\n21 months & $152$ (256) & $2.98$ ± $2.10$ & $158$ (250) & $3.10$ ± $1.94$ & $317$ (499) & $6.22$ ± $3.80$ \\\\ \n25 months & $220$ (284) & $3.49$ ± $2.39$ & $214$ (290) & $3.40$ ± $2.46$ & $416$ (592) & $6.60$ ± $4.51$ \\\\ \n30 months & $226$ (254) & $3.77$ ± $2.96$ & $219$ (261) & $3.65$ ± $2.85$ & $409$ (551) & $6.82$ ± $5.31$ \\\\ \n\\midrule \n\\midrule \nMean & — & $3.41$ & — & $3.38$ & — & $6.55$ \\\\ \nSum & $598$ & — & $591$ & — & $1,142$ & — \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n### Phonological priming: Related vs. Unrelated\n\nA model including the *Relatedness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Relatedness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -14.134, *SE* = 5.25). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_2}}$ = -38.505, *SE* = 38.46). This indicates that including the *Relatedness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_related_vtarget$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_related_vtarget$age),\n\t\t\t\t\t  lp = levels(data_time_related_vtarget$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_related_vtarget[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA, \n\t\t\t\t\tvalue = \".value\") |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .value,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = related - unrelated) \n\n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tmutate(is_cluster = .lower > 0 | .upper < 0) \n# \n# clusters <- rle(diff(diff_rect$is_cluster))\n# diff_rect$cluster_id <- c(0, rep(clusters$values, clusters$lengths))\n# \n# diff_rect <- diff_rect |> \n# \tarrange(lp, timebin)\n# \n# diff_rect <- \n# \tcluster_number = \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = c(lp, is_cluster)) |> \n# \tfilter(is_cluster)\n\n# diff_obs <- data_time_related |>\n# \tpivot_wider(names_from = condition, \n# \t\t\t\tvalues_from = elog,\n# \t\t\t\tnames_repair = janitor::make_clean_names) |> mutate(diff = related - unrelated)\n\ndata_time_related_vtarget |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition,\n\t\t\t   linetype = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .value),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .value,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 1/2, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Condition\",\n\t\t fill = \"Condition\",\n\t\t linetype = \"Condition\",\n\t\t shape = \"Condition\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\t# geom_point(data = diff_obs) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-related-vtarget-1.pdf){#fig-related-vtarget fig-pos='H'}\n:::\n:::\n\n\n\n\n### Cognate priming: Cognate vs. Non-cognate\n\nA model including the *Cognateness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Cognateness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -3.684, *SE* = 4.241). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -50.588, *SE* = 43.666). This indicates that including the *Cognateness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_cognate_vtarget$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_cognate_vtarget$age),\n\t\t\t\t\t  lp = levels(data_time_cognate_vtarget$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_cognate_vtarget[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA) |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .epred,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = cognate - non_cognate) \n# \n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tfilter(.lower > 0 | .upper < 0) |> \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = lp)\n\ndata_time_cognate_vtarget |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -1.5,\n\t# \t\t  \tymax = 1.5),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .epred),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .epred,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0.5, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Prime type\",\n\t\t fill = \"Prime type\",\n\t\t linetype = \"Prime type\",\n\t\t shape = \"Prime type\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -3/4,\n\t# \t\t  \tymax = 3/4),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-cognate-vtarget-1.pdf){#fig-cognate-vtarget fig-pos='H'}\n:::\n:::\n\n\n## Analysis 3\n\nParticipants do not need to know the prime or target words, but must look at least 10 ms to each target and distractor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_trials <- nrow(attrition_trials_vnone)\nn_trials_valid <- inner_join(attrition_participants_vnone,\n\t\t\t\t\t\t\t attrition_trials_vnone) |> \n\tfilter(is_valid_participant) |> \n\tpull(is_valid_trial) |> \n\tsum()\nn_participants_valid <- sum(attrition_participants_vnone$is_valid_participant)\nn_exc_prime <- sum(!attrition_trials_vnone$is_valid_gaze_prime)\nn_exc_test <- sum(!attrition_trials_vnone$is_valid_gaze_test)\nn_exc_test_each <- sum(!attrition_trials_vnone$is_valid_gaze_test_each)\nn_exc_vocab <- sum(!attrition_trials_vnone$is_valid_vocab)\nn_exc_cognate <- sum(!attrition_participants_vnone$is_valid_cognate)\nn_exc_noncognate <- sum(!attrition_participants_vnone$is_valid_noncognate)\nn_exc_unrelated <- sum(!attrition_participants_vnone$is_valid_unrelated)\n\nn_longitudinal <- attrition_participants_vnone |>\n\tfilter(is_valid_participant) |>\n\tcount(id, name = \"times\") |> \n\tcount(times)\n```\n:::\n\n\n\nWe gathered data from 9,472 trials from 180 distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = 1,810) or during the target-distractor phase (*n* = 1,493). We also excluded trials in which participants did not provide at least 5% of valid samples to *both* target and distractor in the test phase (*n* = 2,793). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = 22), the *non-cognate prime* condition (*n* = 23), or the *unrelated prime* condition (*n* = 12). The resulting dataset included 5,671 trials from 264 participants. Of those participants, 92 provided data from one experimental session, 53 provided data from two experimental sessions, and 22 provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.\n\n\n\n::: {#tbl-attrition-trials-vnone .cell tbl-cap='Trial attrition rate by condition for included participants. Additional excluded trials are indicated between parentheses.'}\n\n```{.r .cell-code}\nattrition_trials_vnone |> \n\tfilter(id %in% attrition_participants_vnone$id[attrition_participants_vnone$is_valid_participant]) |> \n\tleft_join(select(participants, filename, id, age_group),\n\t\t\t  by = join_by(filename, id, age_group)) |> \n\tsummarise(n_valid = sum(is_valid_trial),\n\t\t\t  n_total = n(),\n\t\t\t  .by = c(id, age_group, trial_type)) |> \n\tsummarise(across(n_valid, lst(sum, mean, sd),\n\t\t\t\t\t .names = \"{.fn}\"),\n\t\t\t  n_total = sum(n_total),\n\t\t\t  .by = c(age_group, trial_type)) |> \n\tmutate(n_excluded = n_total-sum) |> \n\tselect(-c(n_total)) |> \n\tpivot_wider(names_from = trial_type,\n\t\t\t\tvalues_from = c(sum:sd, n_excluded),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\trename_with(\\(x) gsub(\"non_cognate\", \n\t\t\t\t\t\t  \"noncognate\",\n\t\t\t\t\t\t  x)) |> \n\tarrange(age_group) |> \n\trelocate(age_group,\n\t\t\t matches(\"_cognate\"),\n\t\t\t matches(\"noncognate\")) |> \n\tgt(rowname_col = \"age_group\") |> \n\tgrand_summary_rows(columns = matches(\"mean_\"),\n\t\t\t\t\t   fns = lst(Mean ~ mean(.)),\n\t\t\t\t\t   fmt = ~fmt_number(.)) |>\n\tgrand_summary_rows(columns = matches(\"sum_\"),\n\t\t\t\t\t   fns = lst(Sum ~ sum(.)),\n\t\t\t\t\t   fmt = ~fmt_integer(.)) |>\n\tcols_merge(c(sum_cognate, n_excluded_cognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_noncognate, n_excluded_noncognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_unrelated, n_excluded_unrelated),\n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge_uncert(mean_cognate, sd_cognate) |> \n\tcols_merge_uncert(mean_noncognate, sd_noncognate) |> \n\tcols_merge_uncert(mean_unrelated, sd_unrelated) |> \n\ttab_spanner(\"Cognate trials\", ends_with(\"_cognate\")) |>\n\ttab_spanner(\"Non-cognate trials\", ends_with(\"noncognate\")) |> \n\ttab_spanner(\"Unrelated trials\", ends_with(\"unrelated\")) |> \n\ttab_spanner(\"Related trials\", matches(\"cognate\")) |>\n\tfmt_number(matches(\"mean|sd\")) |> \n\tfmt_integer(matches(\"sum\"), sep_mark = \",\") |> \n\tcols_label(sum_cognate = \"N\",\n\t\t\t   sum_noncognate = \"N\",\n\t\t\t   sum_unrelated = \"N\",\n\t\t\t   mean_cognate = \"Mean\",\n\t\t\t   mean_noncognate = \"Mean\",\n\t\t\t   mean_unrelated = \"Mean\")\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrrr}\n\\toprule\n\\multicolumn{1}{l}{} & \\multicolumn{4}{c}{Related trials} &  &  \\\\ \n\\cmidrule(lr){2-5}\n\\multicolumn{1}{l}{} & \\multicolumn{2}{c}{Cognate trials} & \\multicolumn{2}{c}{Non-cognate trials} & \\multicolumn{2}{c}{Unrelated trials} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n\\multicolumn{1}{l}{} & N & Mean & N & Mean & N & Mean \\\\ \n\\midrule\n21 months & $428$ (300) & $4.70$ ± $2.00$ & $425$ (303) & $4.67$ ± $1.87$ & $854$ (602) & $9.38$ ± $3.30$ \\\\ \n25 months & $481$ (247) & $5.29$ ± $1.81$ & $469$ (259) & $5.15$ ± $1.78$ & $952$ (504) & $10.46$ ± $3.36$ \\\\ \n30 months & $556$ (236) & $5.62$ ± $1.91$ & $536$ (256) & $5.41$ ± $2.11$ & $1,068$ (516) & $10.79$ ± $3.54$ \\\\ \n\\midrule \n\\midrule \nMean & — & $5.20$ & — & $5.08$ & — & $10.21$ \\\\ \nSum & $1,465$ & — & $1,430$ & — & $2,874$ & — \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n### Phonological priming: Related vs. Unrelated\n\nA model including the *Relatedness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Relatedness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -6.303, *SE* = 7.273). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_2}}$ = -135.716, *SE* = 52.934). This indicates that including the *Relatedness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_related_vnone$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_related_vnone$age),\n\t\t\t\t\t  lp = levels(data_time_related_vnone$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_related_vnone[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA, \n\t\t\t\t\tvalue = \".value\") |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .value,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = related - unrelated) \n\n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tmutate(is_cluster = .lower > 0 | .upper < 0) \n# \n# clusters <- rle(diff(diff_rect$is_cluster))\n# diff_rect$cluster_id <- c(0, rep(clusters$values, clusters$lengths))\n# \n# diff_rect <- diff_rect |> \n# \tarrange(lp, timebin)\n# \n# diff_rect <- \n# \tcluster_number = \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = c(lp, is_cluster)) |> \n# \tfilter(is_cluster)\n\n# diff_obs <- data_time_related |>\n# \tpivot_wider(names_from = condition, \n# \t\t\t\tvalues_from = elog,\n# \t\t\t\tnames_repair = janitor::make_clean_names) |> mutate(diff = related - unrelated)\n\ndata_time_related_vnone |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition,\n\t\t\t   linetype = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .value),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .value,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 1/2, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Condition\",\n\t\t fill = \"Condition\",\n\t\t linetype = \"Condition\",\n\t\t shape = \"Condition\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\t# geom_point(data = diff_obs) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-related-vnone-1.pdf){#fig-related-vnone fig-pos='H'}\n:::\n:::\n\n\n\n\n### Cognate priming: Cognate vs. Non-cognate\n\nA model including the *Cognateness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Cognateness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -1.476, *SE* = 5.759). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -131.841, *SE* = 49.45). This indicates that including the *Cognateness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_cognate_vnone$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_cognate_vnone$age),\n\t\t\t\t\t  lp = levels(data_time_cognate_vnone$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_cognate_vnone[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA) |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .epred,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = cognate - non_cognate) \n# \n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tfilter(.lower > 0 | .upper < 0) |> \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = lp)\n\ndata_time_cognate_vnone |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -1.5,\n\t# \t\t  \tymax = 1.5),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .epred),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .epred,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0.5, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Prime type\",\n\t\t fill = \"Prime type\",\n\t\t linetype = \"Prime type\",\n\t\t shape = \"Prime type\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -3/4,\n\t# \t\t  \tymax = 3/4),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-cognate-vnone-1.pdf){#fig-cognate-vnone fig-pos='H'}\n:::\n:::\n\n\n## Analysis 4\n\nParticipants do not need to know the prime or target words, and do not need to look to both pictures. \n\n::: {.cell}\n\n```{.r .cell-code}\nn_trials <- nrow(attrition_trials_noeach)\nn_trials_valid <- inner_join(attrition_participants_noeach,\n\t\t\t\t\t\t\t attrition_trials_noeach) |> \n\tfilter(is_valid_participant) |> \n\tpull(is_valid_trial) |> \n\tsum()\nn_participants_valid <- sum(attrition_participants_noeach$is_valid_participant)\nn_exc_prime <- sum(!attrition_trials_noeach$is_valid_gaze_prime)\nn_exc_test <- sum(!attrition_trials_noeach$is_valid_gaze_test)\nn_exc_test_each <- sum(!attrition_trials_noeach$is_valid_gaze_test_each)\nn_exc_vocab <- sum(!attrition_trials_noeach$is_valid_vocab)\nn_exc_cognate <- sum(!attrition_participants_noeach$is_valid_cognate)\nn_exc_noncognate <- sum(!attrition_participants_noeach$is_valid_noncognate)\nn_exc_unrelated <- sum(!attrition_participants_noeach$is_valid_unrelated)\n\nn_longitudinal <- attrition_participants_noeach |>\n\tfilter(is_valid_participant) |>\n\tcount(id, name = \"times\") |> \n\tcount(times)\n```\n:::\n\n\n\nWe gathered data from 9,472 trials from 180 distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = 1,810) or during the target-distractor phase (*n* = 1,493). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = 15), the *non-cognate prime* condition (*n* = 17), or the *unrelated prime* condition (*n* = 7). The resulting dataset included 7,078 trials from 277 participants. Of those participants, 93 provided data from one experimental session, 53 provided data from two experimental sessions, and 26 provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.\n\n\n\n::: {#tbl-attrition-trials-noeach .cell tbl-cap='Trial attrition rate by condition for included participants. Additional excluded trials are indicated between parentheses.'}\n\n```{.r .cell-code}\nattrition_trials_noeach |> \n\tfilter(id %in% attrition_participants_noeach$id[attrition_participants_noeach$is_valid_participant]) |> \n\tleft_join(select(participants, filename, id, age_group),\n\t\t\t  by = join_by(filename, id, age_group)) |> \n\tsummarise(n_valid = sum(is_valid_trial),\n\t\t\t  n_total = n(),\n\t\t\t  .by = c(id, age_group, trial_type)) |> \n\tsummarise(across(n_valid, lst(sum, mean, sd),\n\t\t\t\t\t .names = \"{.fn}\"),\n\t\t\t  n_total = sum(n_total),\n\t\t\t  .by = c(age_group, trial_type)) |> \n\tmutate(n_excluded = n_total-sum) |> \n\tselect(-c(n_total)) |> \n\tpivot_wider(names_from = trial_type,\n\t\t\t\tvalues_from = c(sum:sd, n_excluded),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\trename_with(\\(x) gsub(\"non_cognate\", \n\t\t\t\t\t\t  \"noncognate\",\n\t\t\t\t\t\t  x)) |> \n\tarrange(age_group) |> \n\trelocate(age_group,\n\t\t\t matches(\"_cognate\"),\n\t\t\t matches(\"noncognate\")) |> \n\tgt(rowname_col = \"age_group\") |> \n\tgrand_summary_rows(columns = matches(\"mean_\"),\n\t\t\t\t\t   fns = lst(Mean ~ mean(.)),\n\t\t\t\t\t   fmt = ~fmt_number(.)) |>\n\tgrand_summary_rows(columns = matches(\"sum_\"),\n\t\t\t\t\t   fns = lst(Sum ~ sum(.)),\n\t\t\t\t\t   fmt = ~fmt_integer(.)) |>\n\tcols_merge(c(sum_cognate, n_excluded_cognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_noncognate, n_excluded_noncognate), \n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge(c(sum_unrelated, n_excluded_unrelated),\n\t\t\t   pattern = \"{1} ({2})\") |> \n\tcols_merge_uncert(mean_cognate, sd_cognate) |> \n\tcols_merge_uncert(mean_noncognate, sd_noncognate) |> \n\tcols_merge_uncert(mean_unrelated, sd_unrelated) |> \n\ttab_spanner(\"Cognate trials\", ends_with(\"_cognate\")) |>\n\ttab_spanner(\"Non-cognate trials\", ends_with(\"noncognate\")) |> \n\ttab_spanner(\"Unrelated trials\", ends_with(\"unrelated\")) |> \n\ttab_spanner(\"Related trials\", matches(\"cognate\")) |>\n\tfmt_number(matches(\"mean|sd\")) |> \n\tfmt_integer(matches(\"sum\"), sep_mark = \",\") |> \n\tcols_label(sum_cognate = \"N\",\n\t\t\t   sum_noncognate = \"N\",\n\t\t\t   sum_unrelated = \"N\",\n\t\t\t   mean_cognate = \"Mean\",\n\t\t\t   mean_noncognate = \"Mean\",\n\t\t\t   mean_unrelated = \"Mean\")\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{l|rrrrrr}\n\\toprule\n\\multicolumn{1}{l}{} & \\multicolumn{4}{c}{Related trials} &  &  \\\\ \n\\cmidrule(lr){2-5}\n\\multicolumn{1}{l}{} & \\multicolumn{2}{c}{Cognate trials} & \\multicolumn{2}{c}{Non-cognate trials} & \\multicolumn{2}{c}{Unrelated trials} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n\\multicolumn{1}{l}{} & N & Mean & N & Mean & N & Mean \\\\ \n\\midrule\n21 months & $541$ (195) & $5.88$ ± $1.94$ & $561$ (175) & $6.10$ ± $1.82$ & $1,089$ (383) & $11.84$ ± $3.46$ \\\\ \n25 months & $579$ (173) & $6.16$ ± $1.94$ & $586$ (166) & $6.23$ ± $1.85$ & $1,169$ (335) & $12.44$ ± $3.43$ \\\\ \n30 months & $649$ (167) & $6.36$ ± $2.01$ & $644$ (172) & $6.31$ ± $2.16$ & $1,300$ (332) & $12.75$ ± $3.65$ \\\\ \n\\midrule \n\\midrule \nMean & — & $6.13$ & — & $6.22$ & — & $12.34$ \\\\ \nSum & $1,769$ & — & $1,791$ & — & $3,558$ & — \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n### Phonological priming: Related vs. Unrelated\n\nA model including the *Relatedness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Relatedness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -27.368, *SE* = 5.299). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_2}}$ = -93.323, *SE* = 42.373). This indicates that including the *Relatedness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_related_noeach$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_related_noeach$age),\n\t\t\t\t\t  lp = levels(data_time_related_noeach$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_related_noeach[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA, \n\t\t\t\t\tvalue = \".value\") |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .value,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = related - unrelated) \n\n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tmutate(is_cluster = .lower > 0 | .upper < 0) \n# \n# clusters <- rle(diff(diff_rect$is_cluster))\n# diff_rect$cluster_id <- c(0, rep(clusters$values, clusters$lengths))\n# \n# diff_rect <- diff_rect |> \n# \tarrange(lp, timebin)\n# \n# diff_rect <- \n# \tcluster_number = \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = c(lp, is_cluster)) |> \n# \tfilter(is_cluster)\n\n# diff_obs <- data_time_related |>\n# \tpivot_wider(names_from = condition, \n# \t\t\t\tvalues_from = elog,\n# \t\t\t\tnames_repair = janitor::make_clean_names) |> mutate(diff = related - unrelated)\n\ndata_time_related_noeach |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition,\n\t\t\t   linetype = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .value),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .value,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 1/2, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Condition\",\n\t\t fill = \"Condition\",\n\t\t linetype = \"Condition\",\n\t\t shape = \"Condition\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -Inf,\n\t# \t\t  \tymax = Inf),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\t# geom_point(data = diff_obs) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-related-noeach-1.pdf){#fig-related-noeach fig-pos='H'}\n:::\n:::\n\n\n\n\n### Cognate priming: Cognate vs. Non-cognate\n\nA model including the *Cognateness* $\\times$ *Group* interaction showed the best of-of-sample predictive performance, although the model including only *Cognateness* performed equivalently ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -25.189, *SE* = 5.023). Both models showed substantially better predictive performance than the model including only *Group* ($\\text{ELPD}_{\\mathcal{M_0}} - \\text{ELPD}_{\\mathcal{M_1}}$ = -60.098, *SE* = 41.472). This indicates that including the *Cognateness* predictor improved the predictive performance of the model significantly, that including its interaction with *Group* slightly increased the performance of the model, and that the main effect of *Group* by itself barely changed the predictive performance of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepreds <- expand_grid(condition = levels(data_time_cognate_noeach$condition),\n\t\t\t\t\t  timebin = seq(0, 17, length.out = 100),\n\t\t\t\t\t  age = mean(data_time_cognate_noeach$age),\n\t\t\t\t\t  lp = levels(data_time_cognate_noeach$lp),\n\t\t\t\t\t  .nsamples = 1) |>\n\tadd_epred_draws(model_fits_cognate_noeach[[4]],\n\t\t\t\t\tndraws = NULL,\n\t\t\t\t\tre_formula = NA) |> \n\tmutate(lp = factor(lp, levels = c(\"Monolingual\", \"Bilingual\")))\n\nepreds_diff <- epreds |> \n\tpivot_wider(names_from = condition,\n\t\t\t\tvalues_from = .epred,\n\t\t\t\tid_cols = c(timebin, age, lp, .draw),\n\t\t\t\tnames_repair = janitor::make_clean_names) |> \n\tmutate(diff = cognate - non_cognate) \n# \n# diff_rect <- epreds_diff |> \n# \tmean_qi(diff) |> \n# \tfilter(.lower > 0 | .upper < 0) |> \n# \tsummarise(xmin = min(timebin),\n# \t\t\t  xmax = max(timebin),\n# \t\t\t  .by = lp)\n\ndata_time_cognate_noeach |> \n\tsummarise(.prop = mean(.prop),\n\t\t\t  .by = c(id, timebin, lp, condition, age)) |> \n\tggplot(aes(timebin, .prop, \n\t\t\t   colour = condition,\n\t\t\t   fill = condition,\n\t\t\t   shape = condition)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -1.5,\n\t# \t\t  \tymax = 1.5),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\t# geom_line(data = epreds,\n\t# \t\t  aes(y = .epred,\n# \t\t  \tgroup = interaction(condition, .draw)),\n# \t\t  linetype = \"solid\",\n# \t\t  alpha = 0.1,\n# \t\t  linewidth = 3/4) +\nstat_summary(data = epreds,\n\t\t\t aes(y = .epred),\n\t\t\t fun.data = \\(x) mean_qi(x, .width = 0.95),\n\t\t\t geom = \"ribbon\",\n\t\t\t alpha = 0.5,\n\t\t\t linewidth = 0) +\n\tstat_summary(data = epreds,\n\t\t\t\t aes(y = .epred,\n\t\t\t\t \tlinetype = condition),\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0.5, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tstat_summary(fun = mean,\n\t\t\t\t geom = \"point\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t size = 2.5,\n\t\t\t\t stroke = 3/4) +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t colour = \"Prime type\",\n\t\t fill = \"Prime type\",\n\t\t linetype = \"Prime type\",\n\t\t shape = \"Prime type\") +\n\ttheme(legend.title = element_blank(),\n\t\t  axis.title.x = element_blank()) +\n\t\n\tepreds_diff |> \n\tggplot(aes(timebin, diff)) +\n\tfacet_wrap(~lp) +\n\t# geom_rect(data = diff_rect,\n\t# \t\t  aes(xmin = xmin,\n\t# \t\t  \txmax = xmax,\n\t# \t\t  \tymin = -3/4,\n\t# \t\t  \tymax = 3/4),\n\t# \t\t  colour = NA,\n\t# \t\t  fill = \"orange\",\n\t# \t\t  alpha = 1/2,\n\t# \t\t  inherit.aes = FALSE) +\n\tstat_lineribbon(.width = 0.95,\n\t\t\t\t\tlinewidth = 0,\n\t\t\t\t\tfill = \"grey\") +\n\tstat_summary(data = epreds_diff,\n\t\t\t\t fun = \"mean\",\n\t\t\t\t geom = \"line\",\n\t\t\t\t colour = \"black\",\n\t\t\t\t linewidth = 3/4) +\n\tgeom_hline(yintercept = 0, \n\t\t\t   linewidth = 1/2,\n\t\t\t   colour = \"black\",\n\t\t\t   linetype = \"dotted\") +\n\tlabs(x = \"Time (ms)\",\n\t\t y = \"P(Target looking)\",\n\t\t fill = \"CrI\") +\n\ttheme(strip.text = element_blank(),\n\t\t  legend.position = \"none\") +\n\t\n\tplot_layout(ncol = 1) &\n\tplot_annotation(tag_levels = \"A\") +\n\tscale_linetype_manual(values = rev(c(\"solid\", \"dashed\"))) &\n\tscale_shape_manual(values = c(1, 2)) &\n\tscale_x_continuous(labels = \\(x) format((x * 1e2)+300, \n\t\t\t\t\t\t\t\t\t\t\tbig.mark = \",\")) &\n\ttheme(panel.grid = element_blank(),\n\t\t  legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero.](manuscript_files/figure-pdf/fig-cognate-noeach-1.pdf){#fig-cognate-noeach fig-pos='H'}\n:::\n:::\n\n\n# Discussion\n\n# Appendix\n\n## Appendix A: imputing voabulary size scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvocabulary_tmp <- vocabulary |> \n\tleft_join(select(participants, id = id_db, age, age_group, filename),\n\t\t\t  by = join_by(filename)) |> \n\trelocate(id, age) |> \n\tselect(-filename) |> \n\tfilter(is_imputed) |> \n\tmutate(id = as.character(id))\n\nbvq_data$vocabulary |> \n\tinner_join(distinct(bvq_data$logs, id, age_group, age),\n\t\t\t   by = join_by(id, age_group)) |> \n\tmutate(is_imputed = FALSE) |> \n\tbind_rows(vocabulary_tmp) |> \n\tpivot_longer(ends_with(\"_prop\"),\n\t\t\t\t names_to = \"measure\",\n\t\t\t\t values_to = \"prop\") |> \n\tdrop_na(prop) |> \n\tmutate(is_imputed = ifelse(is_imputed, \"Imputed\", \"Observed\"),\n\t\t   measure = factor(measure,\n\t\t   \t\t\t\t levels = c(\"total_prop\",\n\t\t   \t\t\t\t \t\t   \"l1_prop\",\n\t\t   \t\t\t\t \t\t   \"l2_prop\",\n\t\t   \t\t\t\t \t\t   \"concept_prop\",\n\t\t   \t\t\t\t \t\t   \"te_prop\"),\n\t\t   \t\t\t\t labels = c(\"Total\",\n\t\t   \t\t\t\t \t\t   \"L1\",\n\t\t   \t\t\t\t \t\t   \"L2\",\n\t\t   \t\t\t\t \t\t   \"Conceptual\",\n\t\t   \t\t\t\t \t\t   \"TE\"))) |> \n\tggplot(aes(age, prop, \n\t\t\t   colour = is_imputed,\n\t\t\t   fill = is_imputed)) +\n\tfacet_wrap(~measure) +\n\tgeom_point(alpha = 1/4, size = 1) +\n\tgeom_smooth(method = \"glm\", \n\t\t\t\tformula = \"y ~ x\",\n\t\t\t\tmethod.args = list(family = \"binomial\"), \n\t\t\t\t# se = FALSE,\n\t\t\t\tsize = 1) +\n\tlabs(x = \"Age (months)\",\n\t\t y = \"Vocabulary size\",\n\t\t colour = \"Imputed\") +\n\ttheme(legend.position = c(1, 0),\n\t\t  legend.justification = c(1, 0),\n\t\t  legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](manuscript_files/figure-pdf/fig-vocabulary-imputation-1.pdf){#fig-vocabulary-imputation fig-pos='H'}\n:::\n:::\n\n\n## Appendix B: distribution of prime and target looking times\n\n```{fig-dist-prime}\nlooking_times |> \n\tmutate(prime_time = cut(prime_time, \n\t\t\t\t\t\t\tseq(0, 1.5, 0.1),\n\t\t\t\t\t\t\tlabels = FALSE,\n\t\t\t\t\t\t\tinclude.lowest = TRUE)) |> \n\tadd_count(lp, age_group, name = \"n_total\") |> \n\tcount(lp, age_group, prime_time, n_total) |> \n\tmutate(n = n / n_total) |> \n\tggplot(aes(prime_time, n)) +\n\tfacet_grid(lp~age_group) +\n\tannotate(geom = \"rect\",\n\t\t\t fill = \"orange\",\n\t\t\t ymin = -Inf,\n\t\t\t ymax = Inf,\n\t\t\t xmin = 0,\n\t\t\t xmax = 0.75*10,\n\t\t\t alpha = 1/3,\n\t\t\t colour = NA) +\n\t# annotate(label = \"Excluded trials\",\n\t# \t\t geom = \"text\",\n\t# \t\t  x = (0.75/2)*10,\n\t# \t\t  y = 1)\n\tgeom_col(fill = \"black\") +\n\tlabs(x = \"Prime looking time (s)\",\n\t\t y = \"Proportion of trials\") +\n\tscale_x_continuous(labels = \\(x) x/10) +\n\ttheme(panel.grid.major.y = element_line(linetype = \"dotted\",\n\t\t\t\t\t\t\t\t\t\t\tcolour = \"grey\"))\n```\n\n```{fig-dist-target}\nlooking_times |> \n\tmutate(target_time = cut(target_time, \n\t\t\t\t\t\t\tseq(0, 2, 0.1),\n\t\t\t\t\t\t\tlabels = FALSE,\n\t\t\t\t\t\t\tinclude.lowest = TRUE)) |> \n\tadd_count(lp, age_group, name = \"n_total\") |> \n\tcount(lp, age_group, target_time, n_total) |> \n\tmutate(n = n / n_total) |> \n\tggplot(aes(target_time, n)) +\n\tfacet_grid(lp~age_group) +\n\t# annotate(label = \"Excluded trials\",\n\t# \t\t geom = \"text\",\n\t# \t\t  x = (0.75/2)*10,\n\t# \t\t  y = 1)\n\tgeom_col(fill = \"black\") +\n\tlabs(x = \"Targets looking time (s)\",\n\t\t y = \"Proportion of trials\") +\n\tscale_x_continuous(labels = \\(x) x/10) +\n\ttheme(panel.grid.major.y = element_line(linetype = \"dotted\",\n\t\t\t\t\t\t\t\t\t\t\tcolour = \"grey\"))\n```\n\n## Appendix C: prime and test looking times\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlooking_times |>\n\tleft_join(select(attrition_trials, \n\t\t\t\t\t filename, trial, is_valid_trial),\n\t\t\t  by = join_by(filename, trial)) |>\n\tfilter(is_valid_trial) |> \n\tggplot(aes(duration,\n\t\t\t   prime_time,\n\t\t\t   colour = trial_type, \n\t\t\t   fill = trial_type,\n\t\t\t   shape = trial_type)) +\n\tfacet_grid(lp~age_group) +\n\tgeom_point(alpha = 0.5, \n\t\t\t   size = 0.5) +\n\tgeom_smooth(method = \"lm\") +\n\tlabs(x = \"Audio duration (s)\",\n\t\t y = \"Looking time (1.0-2.0 seconds)\",\n\t\t colour = \"Prime type\",\n\t\t fill = \"Prime type\",\n\t\t shape = \"Prime type\")\n```\n\n::: {.cell-output-display}\n![Looking time (s) to the prime AOI against audio duration. In longer audios, participants are expected to look longer to the target picture.](manuscript_files/figure-pdf/fig-looking-times-1.pdf){#fig-looking-times fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlooking_times |>\n\tleft_join(select(attrition_trials, \n\t\t\t\t\t filename, trial, is_valid_trial),\n\t\t\t  by = join_by(filename, trial)) |>\n\tfilter(is_valid_trial) |> \n\tggplot(aes(duration,\n\t\t\t   target_time,\n\t\t\t   colour = trial_type, \n\t\t\t   fill = trial_type,\n\t\t\t   shape = trial_type)) +\n\tfacet_grid(lp~age_group) +\n\tgeom_point(alpha = 0.5,\n\t\t\t   size = 0.5) +\n\tgeom_smooth(method = \"lm\",\n\t\t\t\tformula = \"y ~ x\") +\n\tlabs(x = \"Audio duration (s)\",\n\t\t y = \"Looking time (1.0-2.0 seconds)\",\n\t\t colour = \"Prime type\",\n\t\t fill = \"Prime type\",\n\t\t shape = \"Prime type\")\n```\n\n::: {.cell-output-display}\n![Looking time (s) to the prime AOI against audio duration. In longer audios, participants are expected to look longer to the target picture.](manuscript_files/figure-pdf/fig-target-times-1.pdf){#fig-target-times fig-pos='H'}\n:::\n:::\n",
    "supporting": [
      "manuscript_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\r\n\\usepackage{longtable}\r\n\\usepackage{array}\r\n\\usepackage{multirow}\r\n\\usepackage{wrapfig}\r\n\\usepackage{float}\r\n\\usepackage{colortbl}\r\n\\usepackage{pdflscape}\r\n\\usepackage{tabu}\r\n\\usepackage{threeparttable}\r\n\\usepackage{threeparttablex}\r\n\\usepackage[normalem]{ulem}\r\n\\usepackage{makecell}\r\n\\usepackage{xcolor}\r\n\\usepackage{caption}\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}