```{r setup}
#| label: setup
#| echo: false
#| message: false
#| warning: false
# load objects -----------------------------------------------------------------

targets::tar_config_set(store = here::here('_targets'),
						script = here::here('_targets.R'))

targets::tar_load_globals()

targets::tar_load(
	c(participants,
	  participants_oxf,
	  stimuli,
	  stimuli_oxf,
	  vocabulary,
	  vocabulary_oxf,
	  attrition_trials, 
	  attrition_participants,
	  attrition_trials_vtarget,
	  attrition_participants_vtarget,
	  attrition_trials_vnone, 
	  attrition_participants_vnone,
	  attrition_trials_noeach,
	  attrition_participants_noeach,
	  attrition_trials_vnoeach,
	  attrition_participants_vnoeach,
	  attrition_trials_oxf, 
	  attrition_participants_oxf,
	  attrition_trials_vtarget_oxf,
	  attrition_participants_vtarget_oxf,
	  attrition_trials_vnone_oxf, 
	  attrition_participants_vnone_oxf,
	  attrition_trials_noeach_oxf,
	  attrition_participants_noeach_oxf,
	  attrition_trials_vnoeach_oxf,
	  attrition_participants_vnoeach_oxf,
	  bvq_data, 
	  gaze_aoi, 
	  looking_times,
	  data_time_related, 
	  data_time_cognate,
	  data_time_related_vtarget,
	  data_time_cognate_vtarget,
	  data_time_related_vnone,
	  data_time_cognate_vnone,
	  data_time_related_noeach, 
	  data_time_cognate_noeach,
	  data_time_related_vnoeach,
	  data_time_cognate_vnoeach,
	  data_time_related_oxf, 
	  data_time_cognate_oxf,
	  data_time_related_vtarget_oxf,
	  data_time_cognate_vtarget_oxf,
	  data_time_related_vnone_oxf,
	  data_time_cognate_vnone_oxf,
	  data_time_related_noeach_oxf, 
	  data_time_cognate_noeach_oxf,
	  data_time_related_vnoeach_oxf,
	  data_time_cognate_vnoeach_oxf
	))

targets::tar_load(
	c(model_fits_related,
	  model_fits_cognate,
	  model_fits_related_vtarget,
	  model_fits_cognate_vtarget,
	  model_fits_related_vnone,
	  model_fits_cognate_vnone,
	  model_fits_related_noeach,
	  model_fits_cognate_noeach,
	  model_fits_related_vnoeach,
	  model_fits_cognate_vnoeach
	  # model_loo_related,
	  # model_loo_cognate,
	  # model_loo_related_vtarget,
	  # model_loo_cognate_vtarget,
	  # model_loo_related_vnone,
	  # model_loo_cognate_vnone,
	  # model_loo_related_noeach,
	  # model_loo_cognate_noeach,
	  # model_loo_related_vnoeach,
	  # model_loo_cognate_vnoeach
	))


library(knitr)
library(kableExtra)
library(ggplot2)
library(gt)
library(patchwork)
library(english)

# set ggplot theme and colour palette ------------------------------------------

my_theme <- theme_minimal() +
	theme(panel.grid = element_blank(),
		  axis.line = element_line(colour = "black"),
		  text = element_text(size = 12, colour = "black"),
		  axis.text = element_text(colour = "black"))

theme_set(my_theme)

clrs <- c("#003f5c", "#58508d", "#bc5090", "#ff6361", "#ffa600")

options(ggplot2.ordinal.fill = clrs[c(1, 4, 5)],
		ggplot2.ordinal.colour = clrs[c(1, 4, 5)],
		ggplot2.discrete.fill = clrs[c(1, 4, 5)],
		ggplot2.discrete.colour = clrs[c(1, 4, 5)],
		ggplot2.continuous.fill = ggplot2::scale_color_gradient,
		ggplot2.continuous.colour = ggplot2::scale_color_gradient)

set.seed(888)

# prepare data
attrition <- lst(participants,
				 attrition_participants,
				 attrition_trials) |> 
	purrr::reduce(left_join, by = join_by(filename))

attrition_vtarget <- lst(participants,
						 attrition_participants_vtarget,
						 attrition_trials_vtarget) |> 
	purrr::reduce(left_join, by = join_by(filename))

attrition_vnone <- lst(participants,
					   attrition_participants_vnone,
					   attrition_trials_vnone) |> 
	purrr::reduce(left_join, by = join_by(filename))

attrition_noeach <- lst(participants,
						attrition_participants_noeach,
						attrition_trials_noeach) |> 
	purrr::reduce(left_join, by = join_by(filename))

attrition_vnoeach <- lst(participants,
						 attrition_participants_vnoeach,
						 attrition_trials_vnoeach) |> 
	purrr::reduce(left_join, by = join_by(filename))

attrition_oxf <- lst(participants_oxf,
					 attrition_participants_oxf,
					 attrition_trials_oxf) |> 
	purrr::reduce(left_join, by = join_by(id))

attrition_vtarget_oxf <- lst(participants_oxf,
							 attrition_participants_vtarget_oxf,
							 attrition_trials_vtarget_oxf) |> 
	purrr::reduce(left_join, by = join_by(id))

attrition_vnone_oxf <- lst(participants_oxf,
						   attrition_participants_vnone_oxf,
						   attrition_trials_vnone_oxf) |> 
	purrr::reduce(left_join, by = join_by(id))

attrition_noeach_oxf <- lst(participants_oxf,
							attrition_participants_noeach_oxf,
							attrition_trials_noeach_oxf) |> 
	purrr::reduce(left_join, by = join_by(id))

attrition_vnoeach_oxf <- lst(participants_oxf,
							 attrition_participants_vnoeach_oxf,
							 attrition_trials_vnoeach_oxf) |> 
	purrr::reduce(left_join, by = join_by(id))


```


# Introduction

## The early lexicon

The formation of a mental lexicon is a critical developmental achievement for infants_ learning words allows infants to retrieve socially relevant concepts from fairly arbitrary linguistic forms embedded in speech.

Learning words allows infants to access the rich world made of concepts through the recognition of fairly arbitrary linguistic forms, i.e., words. This remarkable developmental achievement is 

There is evidence of cascaded activation during lexical access.

@chow2017spoken adapted the Visual World Paradigm from @huettig2007tug to explore 24- to 30-month-old toddlers' visual fixation patterns during a word recognition when presented with phonological and semantic distractors. In each trial, the authors presented participants with four semantically and phonologically pictures. Four seconds after pictures onset, a word-form was auditorily presented. The word did not refer to any of the pictures displayed on the screen, but was phonologically related to one of them (both labels shared phonological onset), and semantically related to another one of the pictures (both referents belonged to the same taxonomic category. For instance, participants might be presented with the pictures of a sandwich, a bus, a cat, and a dress. Then they would hear the carrier phrase "Look at the **bee**!". The authors registered participants fixations to the phonological and semantic distractors, and found evidence of a preference for the phonological distractor at earlier stages of the post-naming phase, and a preference for the semantic distractor at later stages of the trial. These results support a cascaded activation account of lexical access during the first stages of lexical development.



Another important source of evidence in favour of a cascaded activation account comes from studies on implicit naming. @mani2010infant showed that 18 month-old infants implicitly generate the labels of name-known pictures presented in silence. In each trial, infants were presented with prime pictures presented in silence, and then with a target and a distractor picture, both presented side-by-side. Finally, the target picture's label was presented auditorily. The authors manipulated the phonological overlap between the prime label and the target label, so that in half of the trials both labels were phonologically related, sharing phonological onset (*cat*-*cup*), or phonologically unrelated (*ball*-*comb*). Prime and target-distractor pairs were semantically unrelated. Interestingly, infants showed a stronger looking preference for the target picture after phonologically related prime pictures, compared to after phonologically unrelated primes. This suggests that infants implicitly named prime pictures despite such pictures having been presented in silence, and that the phonology of the resulting label interacted with the subsequent auditory recognition of the target label. In particular, the authors found a facilitation effect: target looking preference was stronger in phonologically related primes, indicating that the activated phonological segments of the generated prime label facilitated the subsequent activation of the phonological representation of the target label during recognition.

@mani2011phonological used the same paradigm in 24-months-old toddlers, and also found evidence of implicit naming, but in the opposite direction. After phonologically related primes, infants showed weaker target looking preference than after phonologically unrelated primes. These results interpreted these outcome as the result of the implicitly generated prime label interfering with the subsequent recognition of the (phonologically related) target word. The authors suggested that the shift from facilitation to interference from 18 to 24 months they found in both studies might be the result of a developmental shift in which 18-month-olds' lexicon is not yet organised based on phonological similarity, while 24-month-olds' is. This would lead to the former showing a pre-lexical facilitation effect in which such facilitation occurs via the activation of phonological segments, while the latter would show an interference effect due to lateral links between lexical representation having been established. Both studies by Mani and Plunkett provide evidence of implicit naming of name-known pictures by 18-month old toddlers and older, and that the resulting labels interact with the dynamics of recognition of subsequently presented word-forms.



Evidence from cascaded activation in lexical access is also provided by bilinguals. The bilingual lexicon is language-non selective. There is strong evidence in support of bilinguals activating lexical representations from both languages during both speech production and comprehension. Previous studies on bilingual word production support a cascade account for lexical activation in which the phonology of non-selected lexical representations engages in excitatory or inhibitory dynamics in the lexical selection process.

## Co-activation in adults

How does language co-activation shape lexical development?
Marian and Spivey (1999)
Costa et al. (2000)

## Evidence from co-activation though translation
The role of cognates in lexical processing.

Another source of evidence are studies studies involving phonological priming of non-cognates through translation. [SEE REFERENCES FROM VON HOLZEN 2012]

Using an adaptation of @mani2010infant's implicit naming paradigm, @von2014bilinguals provided evidence that bilingual adults generate implicit labels in both labels for visually fixated pictures. The authors presented German-English bilinguals with 120 prime-target pairs. Primes were presented as familiar pictures in silence. After prime picture offset, target words were presented auditorily. Participants' N400 ERP components were recorded from target word onset. The authors manipulated the phonological relationship between the prime and target word-forms within participants' L1 and across L1 and L2. When prime and target were phonologically identical (*Affe*-*Affe*, German for *monkey*), or similar (*Fahne*-*Sahne*, German for *flag* and *ice-cream*, respectively) within L1, participants' showed a reduced N400 amplitude, compared to when prime and target were phonologically unrelated (*Messer*-*Seil*, German for *knife* and *rope*). Critically, a similar effect was found when prime and target were phonologically related through translation (*Rustsche*-*Kleid*, German for *slide* and *dress*). This suggests that participants activated prime labels in both languages in parallel, and that both labels impacted the dynamics of target words recognition.

Even earlier evidence of implicit naming was provided through ERP registering at 14 months of age. @duta2012erp presented name-known pictures in silence for one second. After one second, the picture's label was presented auditorily, and the infants' N400 component was registered. In some trials the auditory label corresponded to a canonical realisation of the word-form. In other trials, the word was mispronounced. Infants ERP signal differed when presented with correct pronunciations or mispronunciations, indicating that infants had generated expectations at the phonological level about the auditory labels of the picture before they were presented with its auditory label. A later study by @styles2015infant re-analysed the first 1,000 ms of the trials in the previous study (while the picture was being presented before the auditory label was presented), and found that the ERPs of name-known pictures (according to parental reports of receptive vocabulary) differed from those of name-unknown pictures (which infants would not be able to lexicalise). This provides further support to the account that at around 14 months of age, infants already name familiar pictures, even if presented in silence.



Floccia et al. (2020) tested toddlers in a cross-language priming paradigm. A prime word was embedded at the end of a carrier sentence that participants listened to. Then participants were presented with the auditory label of the target word, and two pictures were shown side-by-side, the target picture, and a distractor picture. Some critiques:



Evidence from cognates.

- Since participants heard the auditory label in one of the languages, priming through translation might be compromised.
- Translation equivalents (Exp. 1) are more strongly related at the semantic level with each other than other pairs of semantically related words that are not translations of each other (table-mesa are more strongly associated than table-silla).
- We used longitudinal participants, so we can examine the developmental trajectories of cross-language lateral inhibitory or excitatory connections better.
- Larger sample size.

Onset vs. offset overlap:

- Wu and Thierry (2011): rhyme

# Methods

All materials, data, and reproducible code can be found at the OSF ([https://osf.io/hy984/](https://osf.io/ckydb/)) and GitHub ([https://github.com/gongcastro/cognate-priming](https://github.com/gongcastro/cognate-priming)) repositories. This study was conducted according to guidelines laid down in the Declaration of Helsinki, and was approved by the Drug Research Ethical Committee (CEIm) of the IMIM Parc de Salut Mar, reference 2020/9080/I. Before every testing session, caregivers were asked to read and sign an informed consent form, and were given a token of appreciation at the end of it.

## Participants

```{r}
#| label: participants-numbers
n_participants_total <- length(unique(participants$id))

n_participants_sessions <- count(participants, id, name = "n_sessions") |> 
	count(n_sessions) |> 
	group_split(n_sessions) |> 
	set_names(paste0("session_", 1:3))

n_sessions_total <- count(participants)

n_sessions_age_group <- participants |> 
	summarise(across(age, lst(mean, sd, min, max)),
			  n = n(),
			  .by = c(age_group)) |> 
	mutate(across(age_mean:age_max, \(x) round(x, 2))) |> 
	group_split(age_group) |> 
	set_names(c("age_21", "age_25", "age_30"))

n_sessions_dominance <- count(participants, test_language) |> 
	group_split(test_language) |> 
	set_names(c("catalan", "spanish"))

n_sessions_dominance_age_group <- count(participants, age_group, test_language) |> 
	group_split(test_language) |> 
	set_names(c("catalan", "spanish")) |> 
	map(\(x) group_split(x, age_group) |> 
			set_names(c("age_21", "age_25", "age_30")))

n_sessions_lp <- participants |> 
	count(lp) |> 
	group_split(lp) |> 
	set_names(c("monolingual", "bilingual"))

n_sessions_lp_age_group <- participants |> 
	count(lp, age_group) |> 
	group_split(lp) |> 
	set_names(c("monolingual", "bilingual")) |> 
	map(\(x) group_split(x, age_group) |> 
			set_names(c("age_21", "age_25", "age_30")))
```

We collected data from `r n_participants_total` monolingual and bilingual participants living in the Metropolitan Area of Barcelona (Spain), who were exposed to at least Catalan and/or Spanish from birth. Families were recruited from maternity room in private hospitals in Barcelona, and contacted via phone when the child's age spanned between our age intervals of interest. Families were invited to participate at three age points: 21, 25, and 30 months. `r n_participants_sessions[[1]]$n` participants were tested at one age point,  `r n_participants_sessions[[2]]$n` at two age points, and `r n_participants_sessions[[3]]$n` at the three age points. In total, we gathered data from `r n_sessions_total$n` testing sessions: `r n_sessions_age_group$age_21$n` at 21 months (*Mean* = `r round(n_sessions_age_group$age_21$age_mean, 2)`, *SD* = `r round(n_sessions_age_group$age_21$age_sd, 2)`, *Range* = `r n_sessions_age_group$age_21$age_min`--`r n_sessions_age_group$age_21$age_max`), `r n_sessions_age_group$age_25$n` at 25 months (*Mean* = `r round(n_sessions_age_group$age_25$age_mean, 2)`, *SD* = `r round(n_sessions_age_group$age_25$age_sd, 2)`, *Range* = `r n_sessions_age_group$age_25$age_min`--`r n_sessions_age_group$age_25$age_max`), and `r n_sessions_age_group$age_30$n` at 30 months (*Mean* = `r round(n_sessions_age_group$age_30$age_mean, 2)`, *SD* = `r round(n_sessions_age_group$age_25$age_sd, 2)`, *Range* = `r n_sessions_age_group$age_30$age_min`--`r n_sessions_age_group$age_30$age_max`). 

### Language profile {#sec-lp}

We assessed participants' language profile using the Language Exposure Questionnaire [LEQ, @bosch2001evidence]. Before each experimental session, the experimenter asked the caretakers to estimate the amount of hours per day they and other people in the infant's social circle have spent speaking to the infant in any language since birth. The output of this interview is an estimated degree of exposure (DoE) to each language, indicated by the proportion of time the infant was reported to have listened to each language. According to this estimate, we classified participants as Catalan- or Spanish-dominant if the language with highest DoE was Catalan or Spanish, respectively, and tested the participant in the stimuli set that contained words in their native language. We collected data from `r n_sessions_dominance$catalan$n` Catalan-dominant participants in Catalan (`r n_sessions_dominance_age_group$catalan$age_21$n` at 21 months, `r n_sessions_dominance_age_group$catalan$age_25$n` at 25 months, and `r n_sessions_dominance_age_group$catalan$age_30$n` at 30 months). We further classified participants as monolinguals if the DoE to their dominant language exceeded 80% of the total DoE to Catalan and Spanish, and as bilinguals otherwise. Participants with DoE to language other than Catalan or Spanish were excluded from analyses. This divided the sample into `r n_sessions_lp$monolingual$n` monolinguals (`r n_sessions_lp_age_group$monolinguals$age_21` at 21 months, `r n_sessions_lp_age_group$monolinguals$age_25` at 25 months, and `r n_sessions_lp_age_group$monolinguals$age_30` at 30 months), and `r n_sessions_lp$bilingual$n` bilinguals (`r n_sessions_lp_age_group$monolinguals$age_21` at 21 months, `r n_sessions_lp_age_group$bilingual$age_25` at 25 months, and `r n_sessions_lp_age_group$bilingual$age_30` at 30 months). @tbl-participants-lp shows a detailed description of the linguistic profile of our sample.




### Vocabulary size

```{r vocab-values}
n_imputed <- table(vocabulary$is_imputed)[2]
prop_imputed <- scales::percent(n_imputed/nrow(vocabulary))
n_pool <- nrow(bvq_data$vocabulary)
```

We collected vocabulary data using parental responses to the Barcelona Vocabulary Inventory [BVQ, @garcia-castro2023bvq], an online vocabulary checklist inspired in several adaptations of the the Communicative Developmental Inventory [CDI, @fenson1994variability] developed to assess the vocabulary size of Catalan-Spanish bilingual toddlers. Families received a link to the BVQ immediately after each experimental session, and were given two weeks to fill it.

We calculated several measures of receptive vocabulary size from each participant's vocabulary: L1 vocabulary size (proportion of words  reported as acquired in the checklist of the dominant language), L2 vocabulary size (proportion of words  reported as acquired in the checklist of the non-dominant language), total vocabulary size (proportion of the words in both checklists reported as acquired), conceptual vocabulary (proportion of concepts for which the participant was reported to have acquired at least one label, in any language), and translation equivalent vocabulary (proportion of concepts for which the participant was reported to have acquired at two labels, one in each language).


`r n_imputed` (`r prop_imputed`) Families failed to provide a complete response to the BVQ within the two-week time limit, or did not provide a successful response to the questionnaire. For missing questionnaire responses, we imputed the vocabulary size of the participant using single imputation, using the vocabulary size scores of a pool of `r n_pool` additional participants for which a successful response for the questionnaire had been gathered. We used participants age in months and their language profile (monolingual/bilingual) as predictors. We used the `mice` R package [@van2011mice] to perform imputation using the Bayesian linear regression method. 

```{r tbl-vocabulary}
#| label: tbl-vocabulary
#| tbl-cap: "Summary of participant vocabulary sizes. vocabulary sizes are expressed as percentage points, and summarised as the mean (*M*) and the standard deviation (*SD*). Total: proportion of words in both languages marked as *Understands*. L1: proportion of words in the dominant language marked as *Understands*. L2: proportion of words in the non-cominant language marked as *Understands*. Conceptual: proportion of translation equivalents for which at least one of the words has ben marked as *Understands*. TE: proportion of translation equivalents for which *both* words have been marked as *Understands*."
#| eval: false
vocabulary |> 
	left_join(select(participants, filename, id, age_group, lp),
			  by = join_by(filename)) |> 
	summarise(across(matches("prop"), 
					 tibble::lst(mean, sd)),
			  .by = c(age_group, lp)) |>
	arrange(age_group, lp) |> 
	gt(groupname_col = "age_group",
	   rowname_col = "lp") |> 
	cols_hide(lp) |> 
	tab_spanner("Vocabulary size ", matches("prop")) |> 
	cols_merge(c(total_prop_mean, total_prop_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(l1_prop_mean, l1_prop_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(l2_prop_mean, l2_prop_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(concept_prop_mean, concept_prop_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(te_prop_mean, te_prop_sd),
			   pattern = "{1} ({2})") |> 
	fmt_number(is.numeric,
			   decimals = 1,
			   scale_by = 100,
			   drop_trailing_zeros = FALSE) |>
	cols_label(total_prop_mean = "Total",
			   l1_prop_mean = "L1",
			   l2_prop_mean = "L2",
			   concept_prop_mean = "Concept",
			   te_prop_mean = "TE") |> 
	tab_stub_indent(rows = everything(),
					indent = 2) |> 
	tab_style(cell_text(align = "left"),
			  cells_stub())
```


## Stimuli

```{r stimuli-values}
n_words <- length(unique(with(stimuli, unlist(prime, target, distractor))))
```

We used `r n_words` distinct words included in the BVQ to create the stimuli lists. We created six stimuli lists: three in Catalan, and three in Spanish. Each list contained 32 trials, each involving a prime-target-distractor group. Each word played a role as either prime, *or* as target and distractor across the three lists in their corresponding language. For instance, the Catalan word *cadira* appeared as *prime* in the three lists, but never as *target* or *distractor*; the Catalan word *bici* appeared as *target* and *distractor* across the three lists, but never as a prime. Target-distractor pairings were held constant across the three lists in each language. For instance, in all Catalan lists the word *bici* was paired with the word *porta*. Target-distractor pairings were also yoked, so that each member of the same target-distractor pair appeared once as target and once as distractor in each list. For instance, the *bici*-*porta* paired appeared twice in each of the three Catalan lists: once with *bici* as target and *porta* as distractor, and once with *porta* as target and *bici* as distractor. This counterbalancing avoided participants encountering looking at the target word guided solely by that word having being named in a previous trial. Finally, prime words appeared only once in each list: each target-distractor pair was associated with a different prime word in both appearances. In each list, the same prime word was presented alongside a different target-distractor pair. For instance, the Catalan prime word *barret* was presented with the *bici*-*porta* target-distractor pair in one list, with the *bici*-*porta* pair in another list, and with *berenar*-*amanida* in the remaining list. The order of the trials was randomised across experimental session, so that each time a participant was tested, the order in which the prime-target-distractor was presented was randomised. Each participant was randomly assigned to one of the three lists in the corresponding language (their dominant language, see @sec-lp), and always the same list across their experimental sessions in the case of a recurrent participant.

In 16 of the 32 trials of the same list (henceforth *related* trials), the prime and the target words were phonologically related, sharing phonological onset (at least first phoneme). In the other 16 trials (*unrelated* trials), prime and target did not share phonological onset. 8 of the 16 *related* trials included a cognate prime (*cognate* trials), and the other 8 included a non-cognate trials (*non-cognate* trials). A prime word was considered cognate if its Catalan and Spanish translation shared phonological onset. Especial attention was paid to avoiding semantic or taxonomic relationships between prime and target words, and between prime and distractor words. Target and distractor word pairs were phonologically unrelated (did not share phonological onset). Some of them shared semantic features or a taxonomic relationship. This is the case of words associated with especially salient referents such as animals or food. To avoid infants guiding their gaze to these objects based on their saliency, we paired animals and food items together. The position of the target and distractor pictures (right or left) for each target-distractor pair was alternated, so that in one list the target would appear on the left, in another list it would appear on the right, and so on.

We examined the overall equivalence of the three trial types by comparing them across three variables relating to the target word: lexical frequency, word prevalence, animacy
@tbl-stimuli shows a detailed summary of the stimuli properties, broken down by trial type and testing language. Lexical frequencies were extracted from the Catalan and Spanish corpora of the CHILDES database [@reference; @reference] as counts per million words, and transformed into Zipf scores for easier cross-language comparison [@reference; @reference]. We defined word prevalence as the proportion of same-aged infants who were reported to understand the word in the BVQ database.


### Auditory stimuli

The auditory stimuli were natural exemplars of the selected target words, spoken by Catalan-Spanish proficient bilingual female speaker who was instructed to pronounce each word in a toddler-directed manner. Recordings were made with an Audio-Tecnica 328 microphone (AT2050) at a sampling rate of 44100 Hz, in a soundproof room at the *Laboratori de Recerca en Infancia* at University Pompeu Fabra. We used the Audacity [@reference] and Praat [@boersma2001speak] to record and edit the audio files. The speaker was presented with a list of words in Catalan. The order of the words was pseudo-randomised, and each word was produced three times in a row before moving to the next word in the list. After going through all the words in the list, the speaker went through the word list again generating three tokens for each word, now in an inverse order (from bottom of the list to the top). We then repeated the same procedure for the list of Spanish words. The resulting audios were manually chunked into individual word-forms. For each of the six tokens produced for each word, the most adequate was selected for further processing. The audios were then transformed to stereo by duplicating them into two channels, denoised, and finally normalised. The mean duration of the final audios was `r round(mean(stimuli$duration[stimuli$test_language=="Catalan"]), 2)` (*SD* = `r round(sd(stimuli$duration[stimuli$test_language=="Catalan"]), 2)`) and `r round(mean(stimuli$duration[stimuli$test_language=="Spanish"]), 2)` (*SD* = `r round(sd(stimuli$duration[stimuli$test_language=="Spanish"]), 2)`) seconds for the Catalan and Spanish lists.

To make the pronunciation of the words as familiar as possible to each infant, we generated additional pronunciation variants for some words in Catalan and Spanish. Catalan words involving the /\textipa{L}/ phoneme in their Central Catalan variant (e.g., /\textipa{'Lu.n@}) were also recorded with such phoneme replaced by /j/ (e.g., /\textipa{'ju.n@}), a phonological process common in the Metropolitan Area of Barcelona [@reference]. Spanish words involving the /\textipa{T}/ phoneme were also generated replacing such phoneme with /\textipa{s}/ to better accommodate Latin variants of Spanish. Before every experimental session, caregivers were asked to utter three written words involving the /\textipa{L}/ phoneme (in the case of participants tested in Catalan) or the /\textipa{T}/ phoneme (in the case of participants tested in Spanish). Each token contained the critical phoneme at onset, inter-vocalic position, and coda. The experimenter assigned the participant to the Catalan or Spanish stimuli list involving the closest variant to that of caregivers'.


### Visual stimuli

For each word, we created a picture with a typical referent. To avoid competition between target and distractor pictures, semantically related target-distractor pairs were perceptually distinct [@floccia2020translation; @arias-trejo2010].

```{r tbl-stimuli}
#| label: tbl-stimuli
#| tbl-cap: "Summary of stimuli properties by trial type."
stimuli |> 
	summarise(across(c(matches("familiarity_|freq_|animate_"), duration),
					 tibble::lst(mean, sd, min, max)),
			  .by = c(test_language, trial_type)) |> 
	select(-matches("familiarity_se"), -matches("prime"),
		   -c(is_animate_target_sd,
		      is_animate_target_min,
		      is_animate_target_max),
		   -matches("min"), -matches("max")) |> 
	gt(groupname_col = "test_language",
	   rowname_col = "list") |> 
	fmt_number(is.numeric,
			   decimals = 1) |> 
	fmt_number(matches("familiarity|animate"),
			   scale_by = 100,
			   decimals = 1) |> 
	cols_merge(c(freq_target_mean, freq_target_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(familiarity_target_mean, familiarity_target_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(duration_mean, duration_sd),
			   pattern = "{1} ({2})") |> 
	cols_label(trial_type = "",
			   familiarity_target_mean = "Prevalence (%)",
			   freq_target_mean = "Frequency",
			   is_animate_target_mean = "Animacy (%)",
			   duration_mean = "Duration (s)") 
```


## Procedure

Testing took place in a sound-proof room. Participants sat on their caregivers' lap in a dimly lit testing booth while the experimenter conducted the experiment from outside. Caregivers were instructed to keep their eyes shut (to avoid recording their gaze, instead of the participant's), to be still, and to avoid interacting with the participant verbally or non-verbally. Participants sat at approximately 65 cm from the eye-tracker and a XX-in screen of $1929\times1080$ screen resolution. We used a custom Matlab XXXX script using the PsychToolbox XXX extension [@brainard] to present the stimuli, and the Tobii Analytics SDK 3.0 to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 5-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented. We set a 55% grey background for the calibration and stimuli presentation. Auditory stimuli were presented through two loudspeakers located behind the screen, one to each side. The experimenter monitored the experimental from outside the room using a centrally located video camera place above the screen. After a successful calibration the experimenter triggered the onset of the first trial. Trials were presented uninterruptedly and  without intervention of the experimenter until the 32 trials were presented, or the experimental session had to be stopped because of the participant's behaviour.

![Experimental task design with examples in Catalan. In each trial, the prime image is presented in silence for 3,000 ms. The the auditory target label is presented, and finally the target and distractor pictures are presented side-by-side for 2,000 ms. In cognate trials (*n* = 8), Catalan *and* Spanish prime labels shared phonological onset with the target label. In non-cognate trials (*n* = 8), only the Catalan prime label shared phonological onset with the target label. In unrelated trials (*n* = 32), none of the prime labels shared phonological onset with the target label.](_assets/img/design.png){fig-align="center"}

Each trial started with the presentation of an attention getter for 3,000 milliseconds. Then, the prime picture was presented in silence in the centre of the screen for 1,500 milliseconds. Fifty milliseconds after the offset of the prime image, an auditory label was played from the loudspeakers and, 700 milliseconds after the onset of the auditory label, the target and distractor pictures were presented side-by-side during 1,000 milliseconds until the end of the trial. After this, the attention getter of the next trial was immediately presented. Each experimental session took approximately 10 minutes.

## Data analysis

We defined our time window of interest from 300 ms after the onset of the test phase (target and distractor presentation) until the end of the test phase (2,000 ms). For each trial, we chunked the time domain into 17 time bins of 100 ms of duration. We then calculated, for each experimental session, time bin, and condition, participant's proportion of target and distractor fixations. Finally, we computed the empirical logit of target fixations, which we introduced in the statistical analyses as our response variable. Missing eye-tracker samples were interpolated using the last-observation-carried-forward [see @zettersten2022peekbank for a similar approach].

We conducted two main analyses. First, we estimated the effect of phonological priming on participants' target looking, comparing *related* trials with *unrelated* trials. This analysis included all trials on the data set. Second, we estimated the effect of cognateness on phonological priming, comparing *cognate* with *non-cognate* trials, leaving out *unrelated* trials. In both analyses, we used General Additive Mixed Models (GAMMs) to model the probability of target fixations across the time course of the trial using a normal distribution.

In the first analysis. We included *Relatedness* (`Related` vs. `Unrelated`, sum-coded as `-0.5` and `+0.5`), *Group* (`Monolingual` vs. `Bilingual`, sum-coded as `-0.5` and `+0.5`), and *Age* (participants' standardised age in months) as fixed, main effects. We also included cubic regression splines for the main effect of *Time*, and one for an adjustment of the previous cubic spline by *Group* [@wood2017generalized]. For both splines, we specified $k = 10$ basis functions or *knots*--half the number of time bins, for computational convenience. Finally, we added by-participant random intercepts, and random slopes for the main effect of *Relatedness* and the main effect of *Age*, both including repeated measures per participant.

To test the contribution of each of the predictors of interest--*Relatedness*/*Cognateness*, and *Group*--, we compared each model ($\mathcal{M_0}$) against a simplified model dropping each of the main effects, *Relatedness*/*Cognateness* ($\mathcal{M}_1$) or *Group* ($\mathcal{M_2}$). In both simplified models, the interaction term was dropped. We used leave-one-out cross-validation (LOO-CV) as a benchmark of model performance, using Pareto-smoothed importance sampling (PSIS) to approximate it. We then examined the posterior predictions of the best-performing model for interpretation.

$$
\begin{aligned}
\textbf{Likelihood:} \\
y_i &\sim \mathcal{N}(\mu_i, \sigma_i) \\ \\
\textbf{Linear model} \\
\text{logit}(\mu_i) &= (\beta_0 + u _{0_{i}}) + (\beta_1 + u _{1_{i}}) \cdot \text{Relatedness} + \beta_{2} \cdot \text{Group} + \\
&\beta_{3} \cdot (\text{Relatedness} \times \text{Group}) + (\beta_4 + u_{3_{i}}) \cdot \text{Age} + \\
&\sum_{j = 1}^k b_{j_{1}}(\beta_{5_{k}} + u_{4_{i}}) \cdot \text{Time} + \\
&\sum_{j = 1}^k b_{j_{1}} (\beta_{6_{k }} + u_{5_{i}}) \cdot (\text{Time} \times \text{Group}) \\
\text{where:} \\
&k \text{ is the number of knots in the spline (10)} \\
\textbf{Prior:} \\
\beta_{0-6} &\sim \mathcal{N}(0, 1) \\
b_{0-1} &\sim MVN(0, 1) \\
\sigma_i &\sim Exp(4) 
\end{aligned}
$$

# Results

We know present the results under four different trial-level inclusion criteria. In Analysis 1, the child is required to understand the prime *and* the target words, on top of having to fixate both target and distractor  for at last 50 ms each during the target-distractor phase. In Analysis 2, the child is required to understand the target word, on top of having to fixate both target and distractor  for at last 50 ms each during the target-distractor phase. In Analysis 3, the child is not required to understand any word, but is still required to fixate both target and distractor for at last 50 ms each during the target-distractor phase. In Analysis 4, the child is not required to understand any word, nor to fixate at both target and distractor. In Analysis 5, the child is required to understand the prime *and* target words, but is not required to look at both target *and* distractor in the test phase.

::: {.callout-note}

@floccia2020translation required participants to know prime and target, but not to look at target *and* distractor (looking at at least one of them is enough). @mani2010infants did not require participants to know either word, but required infants to *not* look exclusively to the target or the distractor throughout the trial, and in an alternative analysis, to *not* look exclusively to the distractor.

The fact that in some time course analyses participants seem to be looking predominantly towards one of the objects (despite the target and distractor pictures having been presented less than 300 ms before) is a common finding in previous studies using preferential looking procedures [e.g., @floccia2020translation].

:::

```{r tbl-multi-trials}
#| tbl-cap: "Number of valid trials by age group, profile, and attrition criteria."
tibble::lst(data_time_related,
			data_time_related_oxf,
			data_time_related_vtarget,
			data_time_related_vtarget_oxf,
			data_time_related_vnone,
			data_time_related_vnone_oxf,
			data_time_related_noeach,
			data_time_related_noeach_oxf,
			data_time_related_vnoeach,
			data_time_related_vnoeach_oxf) |> 
	bind_rows(.id = "analysis") |>
	mutate(analysis_lab = case_when(
		analysis=="data_time_related" ~ "Analysis 1",
		grepl("_vtarget", analysis) ~ "Analysis 2",
		grepl("_vnone", analysis) ~ "Analysis 3",
		grepl("_noeach", analysis) ~ "Analysis 4",
		grepl("_vnoeach", analysis) ~ "Analysis 5",
		.default = "Analysis 1"
	),
	lp = case_when(grepl("_oxf", analysis) ~ "Monolingual (Oxford)", 
				   lp=="Bilingual" ~ "Bilingual (Barcelona)",
				   .default = "Monolingual (Barcelona)"),
	lp = factor(lp, 
				levels = c("Monolingual (Oxford)",
						   "Monolingual (Barcelona)",
						   "Bilingual (Barcelona)")),
	condition = factor(condition, levels = c("Related", "Unrelated"))) |> 
	distinct(analysis, analysis_lab, lp, condition, .ntrials) |> 
	summarise(.ntrials = sum(.ntrials),
			  .by = c(lp, analysis_lab, condition)) |> 
	pivot_wider(names_from = c(lp, condition),
				values_from = .ntrials,
				names_repair = janitor::make_clean_names) |> 
	relocate(analysis_lab,
			 monolingual_barcelona_related,
			 monolingual_barcelona_unrelated,
			 bilingual_barcelona_related,
			 bilingual_barcelona_unrelated,
			 monolingual_oxford_related,
			 monolingual_oxford_unrelated) |> 
	gt(rowname_col = "analysis_lab") |> 
	tab_spanner("Bilingual", matches("bilingual")) |> 
	
	tab_spanner("Monolingual", matches("monolingual")) |> 
	tab_spanner("Barcelona", matches("barcelona")) |> 
	tab_spanner("Oxford", matches("oxford")) |> 
	
	
	cols_label(monolingual_oxford_related = "Related",
			   monolingual_oxford_unrelated = "Unrelated",
			   monolingual_barcelona_related = "Related",
			   monolingual_barcelona_unrelated = "Unrelated",
			   bilingual_barcelona_related = "Related",
			   bilingual_barcelona_unrelated = "Unrelated")


```

```{r fig-related-summary}
#| label: fig-related-summary
#| fig-height: 6.5
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
tibble::lst(data_time_related,
			data_time_related_oxf,
			data_time_related_vtarget,
			data_time_related_vtarget_oxf,
			data_time_related_vnone,
			data_time_related_vnone_oxf,
			data_time_related_noeach,
			data_time_related_noeach_oxf,
			data_time_related_vnoeach,
			data_time_related_vnoeach_oxf) |> 
	bind_rows(.id = "analysis") |>
	mutate(analysis_lab = case_when(
		analysis=="data_time_related" ~ "Analysis 1",
		grepl("_vtarget", analysis) ~ "Analysis 2",
		grepl("_vnone", analysis) ~ "Analysis 3",
		grepl("_noeach", analysis) ~ "Analysis 4",
		grepl("_vnoeach", analysis) ~ "Analysis 5",
		.default = "Analysis 1"
	),
	lp = ifelse(grepl("_oxf", analysis), 
				"Monolingual (English)", 
				as.character(lp)),
	lp = factor(lp, levels = c("Monolingual (English)",
							   "Monolingual",
							   "Bilingual"))) |> 
	# summarise(.elog_mean = mean(.elog),
	# 		  n = n(),
	# 		  .elog_std = sd(.elog),
	# 		  .by = c(condition, timebin, analysis, lp)) |>
	# mutate(.elog_se = .elog_std/n) |> 
	ggplot(aes(timebin, .elog,
			   colour = condition,
			   fill = condition,
			   shape = condition)) +
	facet_grid(analysis_lab~lp) +
	geom_hline(yintercept = 0.5, 
			   linewidth = 1/2,
			   colour = "black",
			   linetype = "dotted") +
	geom_smooth(method = lm, 
				se = FALSE, 
				formula = y ~ splines::bs(x, 4)) +
	# geom_errorbar(aes(ymin = .elog_mean - .elog_se*1.96, 
	# 				  ymax = .elog_mean + .elog_se*1.96),
	# 			  width = 0.25,
	# 			  linewidth = 3/4) + 
	# geom_line(size = 3/4) + 
	stat_summary(fun = mean, geom = "point") +
	stat_summary(fun.data = mean_se,
				 geom = "errorbar",
				 width = 0.25) +
	labs(x = "Time (ms)",
		 y = "P(Target looking)",
		 colour = "Condition",
		 fill = "Condition",
		 linetype = "Condition",
		 shape = "Condition") +
	scale_linetype_manual(values = rev(c("solid", "dashed"))) +
	# scale_shape_manual(values = c(1, 2)) +
	scale_x_continuous(labels = \(x) format((x * 1e2)+300, 
											big.mark = ",")) +
	theme(legend.title = element_blank(),
		  axis.title.x = element_blank(),
		  panel.border = element_rect(fill = NA),
		  axis.line = element_line(),
		  legend.position = "top") 
```

```{r fig-cognate-summary}
#| label: fig-cognate-summary
#| fig-height: 6.5
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs. Lines and inetervals indicate the mean and 95% credible intervals of the posterior probability of target looking across the time course of the trial. Points indicate the mean probability of target looking across participants. In Analysis 1, the child is required to understand the prime *and* the target words, on top of having to fixate both target and distractor  for at last 50 ms each during the target-distractor phase. In Analysis 2, the child is required to understand the target word, on top of having to fixate both target and distractor  for at last 50 ms each during the target-distractor phase. In Analysis 3, the child is not required to understand any word, but is still required to fixate both target and distractor for at last 50 ms each during the target-distractor phase. In Analysis 4, the child is not required to understand any word, nor to fixate at both target and distractor. In Analysis 5, the child is required to understand the prime *and* target words, but is not required to look at both target *and* distractor in the test phase."
tibble::lst(data_time_cognate,
			data_time_cognate_oxf,
			data_time_cognate_vtarget,
			data_time_cognate_vtarget_oxf,
			data_time_cognate_vnone,
			data_time_cognate_vnone_oxf,
			data_time_cognate_noeach,
			data_time_cognate_noeach_oxf,
			data_time_cognate_vnoeach,
			data_time_cognate_vnoeach_oxf) |> 
	bind_rows(.id = "analysis") |>
	mutate(analysis_lab = case_when(
		analysis=="data_time_cognate" ~ "Analysis 1",
		grepl("_vtarget", analysis) ~ "Analysis 2",
		grepl("_vnone", analysis) ~ "Analysis 3",
		grepl("_noeach", analysis) ~ "Analysis 4",
		grepl("_vnoeach", analysis) ~ "Analysis 5",
		.default = "Analysis 1"
	),
	lp = ifelse(grepl("_oxf", analysis), 
				"Monolingual (English)", 
				as.character(lp)),
	lp = factor(lp, levels = c("Monolingual (English)",
							   "Monolingual",
							   "Bilingual"))) |> 
	# summarise(.elog_mean = mean(.elog),
	# 		  n = n(),
	# 		  .elog_std = sd(.elog),
	# 		  .by = c(condition, timebin, analysis, lp)) |>
	# mutate(.elog_se = .elog_std/n) |> 
	ggplot(aes(timebin, .elog,
			   colour = condition,
			   fill = condition,
			   shape = condition)) +
	facet_grid(analysis_lab~lp) +
	geom_hline(yintercept = 0.5, 
			   linewidth = 1/2,
			   colour = "black",
			   linetype = "dotted") +
	geom_smooth(method = lm, 
				se = FALSE, 
				formula = y ~ splines::bs(x, 4)) +
	# geom_errorbar(aes(ymin = .elog_mean - .elog_se*1.96, 
	# 				  ymax = .elog_mean + .elog_se*1.96),
	# 			  width = 0.25,
	# 			  linewidth = 3/4) + 
	# geom_line(size = 3/4) + 
	stat_summary(fun = mean, geom = "point") +
	stat_summary(fun.data = mean_se,
				 geom = "errorbar",
				 width = 0.25) +
	labs(x = "Time (ms)",
		 y = "P(Target looking)",
		 colour = "Condition",
		 fill = "Condition",
		 linetype = "Condition",
		 shape = "Condition") +
	scale_linetype_manual(values = rev(c("solid", "dashed"))) +
	# scale_shape_manual(values = c(1, 2)) +
	scale_x_continuous(labels = \(x) format((x * 1e2)+300, 
											big.mark = ",")) +
	theme(legend.title = element_blank(),
		  axis.title.x = element_blank(),
		  panel.border = element_rect(fill = NA),
		  axis.line = element_line(),
		  legend.position = "top")
```

## Analysis 1

::: {.callout-note}

Participants must know **prime** *and* **target** words, and must look at least 10 ms to each target and distractor.

:::

```{r dataset}
n_trials <- nrow(attrition_trials)
n_total <- n_distinct(attrition_trials$id)
n_trials_valid <- inner_join(attrition_participants,
							 attrition_trials,
							 by = join_by(id)) |> 
	filter(is_valid_participant) |> 
	pull(is_valid_trial) |> 
	sum()
n_participants_valid <- sum(attrition_participants$is_valid_participant)
n_exc_prime <- sum(!attrition_trials$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_trials$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_trials$is_valid_gaze_test_each)
n_exc_vocab <- sum(!attrition_trials$is_valid_vocab)
n_exc_cognate <- sum(!attrition_participants$is_valid_cognate)
n_exc_noncognate <- sum(!attrition_participants$is_valid_noncognate)
n_exc_unrelated <- sum(!attrition_participants$is_valid_unrelated)

n_longitudinal <- attrition_participants |>
	filter(is_valid_participant) |>
	count(id, name = "times") |> 
	count(times)
```


We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_total` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). We also excluded trials in which participants did not provide at least 5% of valid samples to *both* target and distractor in the test phase (*n* = `r format(n_exc_test_each, big.mark = ",")`). Finally, we excluded trials in which participants did not understand the prime *or* the target word, according to a supplementary vocabulary checklist filled by their caregivers upon experiment completion (*n* = `r format(n_exc_vocab, big.mark = ",")`). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = `r n_exc_cognate`), the *non-cognate prime* condition (*n* = `r n_exc_noncognate`), or the *unrelated prime* condition (*n* = `r n_exc_unrelated`). The resulting dataset included `r format(n_trials_valid, big.mark = ",")` trials from `r n_participants_valid` participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.

```{r tbl-participants-lp}
#| label: tbl-participants-lp
#| tbl-cap: "Participant details for Analysis 1. Sample sizes indicate the number of participants included and excluded (between parenthesis) after applying inclusion criteria. Age is summarised using the mean and standard deviation (betwen parenthesis) for each age and language group separately."
participants_tmp <- participants |> 
	left_join(attrition_participants, by = join_by(filename)) |> 
	mutate(id = as.character(id))

participants_oxf_tmp <- participants_oxf |> 
	inner_join(attrition_participants_oxf,
			   by = join_by(id)) |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) 

bind_rows(participants_tmp, participants_oxf_tmp) |> 
	add_count(lp, 
			  name = "n_lp") |> 
	add_count(age_group, 
			  name = "n_age_group") |> 
	add_count(age_group,
			  test_language,
			  name = "n_age_test") |> 
	mutate(lp = factor(lp, levels = rev(unique(lp)))) |> 
	summarise(across(c(age), lst(mean, sd)),
			  n_inc = sum(is_valid_participant),
			  n_exc = sum(!is_valid_participant),
			  .by = c(age_group, lp, test_language)) |> 
	pivot_wider(id_cols = c(test_language, lp),
				names_from = c(age_group),
				values_from = c(matches("doe"), age_mean, age_sd, n_inc, n_exc),
				names_repair = janitor::make_clean_names) |>
	relocate(lp, test_language, 
			 n_inc_21_months, n_exc_21_months, age_mean_21_months, age_sd_21_months,
			 n_inc_25_months, n_exc_25_months, age_mean_25_months, age_sd_25_months,
			 n_inc_30_months, n_exc_30_months, age_mean_30_months, age_sd_30_months) |> 
	arrange(lp, test_language) |> 
	gt(rowname_col = "test_language", 
	   groupname_col = "lp", 
	   row_group.sep = ": ") |> 
	tab_spanner(md("21 months"), matches("21")) |> 
	tab_spanner(md("25 months"), matches("25")) |>
	tab_spanner(md("30 months"), matches("30")) |> 
	fmt_number(matches("age"), decimals = 1) |>
	cols_merge(c(n_inc_21_months, n_exc_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_25_months, n_exc_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_30_months, n_exc_30_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_21_months, age_sd_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_25_months, age_sd_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_30_months, age_sd_30_months),
			   pattern = "{1} ({2})") |> 
	cols_label(n_inc_21_months = md("*N*"),
			   n_inc_25_months = md("*N*"),
			   n_inc_30_months = md("*N*"),
			   age_mean_21_months = "Age (months)",
			   age_mean_25_months = "Age (months)",
			   age_mean_30_months = "Age (months)") |> 
	tab_style(cell_text(weight = "bold"),
			  list(cells_column_spanners())) |> 
	tab_style(cell_text(size = "medium"),
			  list(cells_body(),
			  	 cells_stub())) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("n"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	grand_summary_rows(starts_with("n"), 
					   fns = list(label = md("*N*")) ~ sum(.),
					   fmt = ~fmt_integer(.))
```



```{r tbl-attrition-trials}
#| label: tbl-attrition-trials
#| tbl-cap: "Trial attrition rate by condition for included participants in Analysis 1. Additional excluded trials are indicated between parentheses."
attrition_oxf |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) |> 
	bind_rows(mutate(attrition, id = as.character(id))) |> 
	filter(is_valid_participant) |> 
	summarise(n_valid = sum(is_valid_trial),
			  n_total = n(),
			  .by = c(id, age_group, lp, trial_type)) |> 
	summarise(across(n_valid, lst(sum, mean, sd),
					 .names = "{.fn}"),
			  n_total = sum(n_total),
			  .by = c(age_group, lp, trial_type)) |> 
	mutate(n_excluded = n_total-sum) |> 
	select(-c(n_total)) |> 
	pivot_wider(names_from = trial_type,
				values_from = c(sum:sd, n_excluded),
				names_repair = janitor::make_clean_names) |> 
	rename_with(\(x) gsub("non_cognate", "noncognate", x)) |> 
	arrange(age_group) |> 
	relocate(age_group,
			 matches("_cognate"),
			 matches("noncognate")) |> 
	gt(rowname_col = "age_group",
	   groupname_col = "lp") |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("sum"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 matches("mean"), 
				 fns = list(label = md("*Mean*"), id = "totals") ~ mean(.),
				 fmt = ~fmt_number(.)) |> 
	grand_summary_rows(columns = matches("mean_"),
					   fns = lst(Mean ~ mean(.)),
					   fmt = ~fmt_number(.)) |>
	grand_summary_rows(columns = matches("sum_"),
					   fns = lst(Sum ~ sum(.)),
					   fmt = ~fmt_integer(.)) |>
	cols_merge(c(sum_cognate, n_excluded_cognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_noncognate, n_excluded_noncognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_unrelated, n_excluded_unrelated),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(mean_cognate, sd_cognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_noncognate, sd_noncognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_unrelated, sd_unrelated),
			   pattern = "{1} ({2})") |>
	tab_spanner("Cognate trials", ends_with("_cognate")) |>
	tab_spanner("Non-cognate trials", ends_with("noncognate")) |> 
	tab_spanner("Unrelated trials", ends_with("unrelated")) |> 
	tab_spanner("Related trials", matches("cognate")) |>
	fmt_number(matches("mean|sd"), decimals = 1) |> 
	fmt_integer(matches("sum"), sep_mark = ",") |> 
	cols_label(sum_cognate = md("*N*"),
			   sum_noncognate = md("*N*"),
			   sum_unrelated = md("*N*"),
			   mean_cognate = md("*Mean (SD)*"),
			   mean_noncognate = md("*Mean (SD)*"),
			   mean_unrelated = md("*Mean (SD)*"))
```


### Phonological priming: Related vs. Unrelated

```{r fig-related}
#| label: fig-related
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 1. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm <- function(data, model, contrast = "related") {
	epreds <- expand_grid(condition = levels(data$condition),
						  timebin = seq(0, 17, length.out = 100),
						  age = mean(data$age),
						  lp = levels(data$lp),
						  .nsamples = 1) |>
		add_epred_draws(model,
						ndraws = NULL,
						re_formula = NA, 
						value = ".value") |> 
		mutate(lp = factor(lp, levels = c("Monolingual", "Bilingual")))
	
	epreds_diff <- epreds |> 
		pivot_wider(names_from = condition,
					values_from = .value,
					id_cols = c(timebin, age, lp, .draw),
					names_repair = janitor::make_clean_names) 
	
	if (contrast=="related") {
		epreds_diff$diff <- epreds_diff$related - epreds_diff$unrelated
	} else {
		epreds_diff$diff <- epreds_diff$cognate - epreds_diff$non_cognate
	}

	data |> 
		summarise(.prop = mean(.prop),
				  .by = c(id, timebin, lp, condition, age)) |> 
		ggplot(aes(timebin, .prop, 
				   colour = condition,
				   fill = condition,
				   shape = condition,
				   linetype = condition)) +
		facet_wrap(~lp) +
		stat_summary(data = epreds,
					 aes(y = .value),
					 fun.data = \(x) mean_qi(x, .width = 0.95),
					 geom = "ribbon",
					 alpha = 0.5,
					 linewidth = 0) +
		stat_summary(data = epreds,
					 aes(y = .value,
					 	linetype = condition),
					 fun = "mean",
					 geom = "line",
					 linewidth = 3/4) +
		geom_hline(yintercept = 1/2, 
				   linewidth = 1/2,
				   colour = "black",
				   linetype = "dotted") +
		stat_summary(fun.data = mean_se,
					 geom = "errorbar",
					 linetype = "solid",
					 width = 0.25) +
		stat_summary(fun = mean,
					 geom = "point") +
		labs(x = "Time (ms)",
			 y = "P(Target looking)",
			 colour = "Condition",
			 fill = "Condition",
			 linetype = "Condition",
			 shape = "Condition") +
		theme(legend.title = element_blank(),
			  axis.title.x = element_blank()) +
		
		epreds_diff |> 
		ggplot(aes(timebin, diff)) +
		facet_wrap(~lp) +
		stat_lineribbon(.width = 0.95,
						linewidth = 0,
						fill = "grey") +
		stat_summary(data = epreds_diff,
					 fun = "mean",
					 geom = "line",
					 colour = "black",
					 linewidth = 3/4) +
		geom_hline(yintercept = 0, 
				   linewidth = 1/2,
				   colour = "black",
				   linetype = "dotted") +
		labs(x = "Time (ms)",
			 y = "Related - Unrelated",
			 fill = "CrI") +
		theme(strip.text = element_blank(),
			  legend.position = "none") +
		
		plot_layout(ncol = 1) &
		plot_annotation(tag_levels = "A") +
		scale_linetype_manual(values = rev(c("solid", "dashed"))) &
		# scale_shape_manual(values = c(1, 2)) &
		scale_x_continuous(labels = \(x) format((x * 1e2)+300, 
												big.mark = ",")) &
		theme(panel.grid = element_blank(),
			  legend.position = "top") 
}

plot_gamm(data_time_related, model_fits_related[[1]])

```



### Cognate priming: Cognate vs. Non-cognate

```{r fig-cognate}
#| label: fig-cognate
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 1. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_cognate, model_fits_cognate[[1]], contrast = "cognate")
```

{{< pagebreak >}}

## Analysis 2

::: {.callout-note}

Participants must know the target **target** word (no need to know the prime word), and must look at least 10 ms to each target and distractor.

:::

```{r dataset-vtarget}
n_trials <- nrow(attrition_trials_vtarget)
n_trials_valid <- inner_join(attrition_participants_vtarget,
							 attrition_trials_vtarget) |> 
	filter(is_valid_participant) |> 
	pull(is_valid_trial) |> 
	sum()
n_participants_valid <- sum(attrition_participants_vtarget$is_valid_participant)
n_exc_prime <- sum(!attrition_trials_vtarget$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_trials_vtarget$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_trials_vtarget$is_valid_gaze_test_each)
n_exc_vocab <- sum(!attrition_trials_vtarget$is_valid_vocab)
n_exc_cognate <- sum(!attrition_participants_vtarget$is_valid_cognate)
n_exc_noncognate <- sum(!attrition_participants_vtarget$is_valid_noncognate)
n_exc_unrelated <- sum(!attrition_participants_vtarget$is_valid_unrelated)

n_longitudinal <- attrition_participants_vtarget |>
	filter(is_valid_participant) |>
	count(id, name = "times") |> 
	count(times)
```


We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_total` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). We also excluded trials in which participants did not provide at least 5% of valid samples to *both* target and distractor in the test phase (*n* = `r format(n_exc_test_each, big.mark = ",")`). Finally, we excluded trials in which participants did not understand the target word, according to a supplementary vocabulary checklist filled by their caregivers upon experiment completion (*n* = `r format(n_exc_vocab, big.mark = ",")`). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = `r n_exc_cognate`), the *non-cognate prime* condition (*n* = `r n_exc_noncognate`), or the *unrelated prime* condition (*n* = `r n_exc_unrelated`). The resulting dataset included `r format(n_trials_valid, big.mark = ",")` trials from `r n_participants_valid` participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.

```{r tbl-participants-lp-vtarget}
#| label: tbl-participants-lp-vtarget
#| tbl-cap: "Participant details for Analysis 2. Sample sizes indicate the number of participants included and excluded (between parenthesis) after applying inclusion criteria. Age is summarised using the mean and standard deviation (betwen parenthesis) for each age and language group separately."
participants_tmp <- participants |> 
	left_join(attrition_participants_vtarget, by = join_by(filename)) |> 
	mutate(id = as.character(id))

participants_oxf_tmp <- participants_oxf |> 
	inner_join(attrition_participants_vtarget_oxf,
			   by = join_by(id)) |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) 

bind_rows(participants_tmp, participants_oxf_tmp) |> 
	add_count(lp, 
			  name = "n_lp") |> 
	add_count(age_group, 
			  name = "n_age_group") |> 
	add_count(age_group,
			  test_language,
			  name = "n_age_test") |> 
	mutate(lp = factor(lp, levels = rev(unique(lp)))) |> 
	summarise(across(c(age), lst(mean, sd)),
			  n_inc = sum(is_valid_participant),
			  n_exc = sum(!is_valid_participant),
			  .by = c(age_group, lp, test_language)) |> 
	pivot_wider(id_cols = c(test_language, lp),
				names_from = c(age_group),
				values_from = c(matches("doe"), age_mean, age_sd, n_inc, n_exc),
				names_repair = janitor::make_clean_names) |>
	relocate(lp, test_language, 
			 n_inc_21_months, n_exc_21_months, age_mean_21_months, age_sd_21_months,
			 n_inc_25_months, n_exc_25_months, age_mean_25_months, age_sd_25_months,
			 n_inc_30_months, n_exc_30_months, age_mean_30_months, age_sd_30_months) |> 
	arrange(lp, test_language) |> 
	gt(rowname_col = "test_language", 
	   groupname_col = "lp", 
	   row_group.sep = ": ") |> 
	tab_spanner(md("21 months"), matches("21")) |> 
	tab_spanner(md("25 months"), matches("25")) |>
	tab_spanner(md("30 months"), matches("30")) |> 
	fmt_number(matches("age"), decimals = 1) |>
	cols_merge(c(n_inc_21_months, n_exc_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_25_months, n_exc_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_30_months, n_exc_30_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_21_months, age_sd_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_25_months, age_sd_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_30_months, age_sd_30_months),
			   pattern = "{1} ({2})") |> 
	cols_label(n_inc_21_months = md("*N*"),
			   n_inc_25_months = md("*N*"),
			   n_inc_30_months = md("*N*"),
			   age_mean_21_months = "Age (months)",
			   age_mean_25_months = "Age (months)",
			   age_mean_30_months = "Age (months)") |> 
	tab_style(cell_text(weight = "bold"),
			  list(cells_column_spanners())) |> 
	tab_style(cell_text(size = "medium"),
			  list(cells_body(),
			  	 cells_stub())) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("n"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	grand_summary_rows(starts_with("n"), 
					   fns = list(label = md("*N*")) ~ sum(.),
					   fmt = ~fmt_integer(.))
```


```{r tbl-attrition-trials-vtarget}
#| label: tbl-attrition-trials-vtarget
#| tbl-cap: "Trial attrition rate by condition for included participants in Analysis 2. Additional excluded trials are indicated between parentheses."
attrition_vtarget_oxf |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) |> 
	bind_rows(mutate(attrition, id = as.character(id))) |> 
	filter(is_valid_participant) |> 
	summarise(n_valid = sum(is_valid_trial),
			  n_total = n(),
			  .by = c(id, age_group, lp, trial_type)) |> 
	summarise(across(n_valid, lst(sum, mean, sd),
					 .names = "{.fn}"),
			  n_total = sum(n_total),
			  .by = c(age_group, lp, trial_type)) |> 
	mutate(n_excluded = n_total-sum) |> 
	select(-c(n_total)) |> 
	pivot_wider(names_from = trial_type,
				values_from = c(sum:sd, n_excluded),
				names_repair = janitor::make_clean_names) |> 
	rename_with(\(x) gsub("non_cognate", "noncognate", x)) |> 
	arrange(age_group) |> 
	relocate(age_group,
			 matches("_cognate"),
			 matches("noncognate")) |> 
	gt(rowname_col = "age_group",
	   groupname_col = "lp") |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("sum"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 matches("mean"), 
				 fns = list(label = md("*Mean*"), id = "totals") ~ mean(.),
				 fmt = ~fmt_number(.)) |> 
	grand_summary_rows(columns = matches("mean_"),
					   fns = lst(Mean ~ mean(.)),
					   fmt = ~fmt_number(.)) |>
	grand_summary_rows(columns = matches("sum_"),
					   fns = lst(Sum ~ sum(.)),
					   fmt = ~fmt_integer(.)) |>
	cols_merge(c(sum_cognate, n_excluded_cognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_noncognate, n_excluded_noncognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_unrelated, n_excluded_unrelated),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(mean_cognate, sd_cognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_noncognate, sd_noncognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_unrelated, sd_unrelated),
			   pattern = "{1} ({2})") |>
	tab_spanner("Cognate trials", ends_with("_cognate")) |>
	tab_spanner("Non-cognate trials", ends_with("noncognate")) |> 
	tab_spanner("Unrelated trials", ends_with("unrelated")) |> 
	tab_spanner("Related trials", matches("cognate")) |>
	fmt_number(matches("mean|sd"), decimals = 1) |> 
	fmt_integer(matches("sum"), sep_mark = ",") |> 
	cols_label(sum_cognate = md("*N*"),
			   sum_noncognate = md("*N*"),
			   sum_unrelated = md("*N*"),
			   mean_cognate = md("*Mean (SD)*"),
			   mean_noncognate = md("*Mean (SD)*"),
			   mean_unrelated = md("*Mean (SD)*"))
```


### Phonological priming: Related vs. Unrelated


```{r fig-related-vtarget}
#| label: fig-related-vtarget
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 2. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_related_vtarget, 
		  model_fits_related_vtarget[[1]], 
		  contrast = "related")
```



### Cognate priming: Cognate vs. Non-cognate

```{r fig-cognate-vtarget}
#| label: fig-cognate-vtarget
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 2. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_cognate_vtarget, 
		  model_fits_cognate_vtarget[[1]], 
		  contrast = "cognate")
```

{{< pagebreak >}}

## Analysis 3

::: {.callout-note}

Participants do not need to know the prime or target words, but must look at least 10 ms to each target and distractor.

:::

```{r dataset-vnone}
n_trials <- nrow(attrition_trials_vnone)
n_trials_valid <- inner_join(attrition_participants_vnone,
							 attrition_trials_vnone) |> 
	filter(is_valid_participant) |> 
	pull(is_valid_trial) |> 
	sum()
n_participants_valid <- sum(attrition_participants_vnone$is_valid_participant)
n_exc_prime <- sum(!attrition_trials_vnone$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_trials_vnone$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_trials_vnone$is_valid_gaze_test_each)
n_exc_vocab <- sum(!attrition_trials_vnone$is_valid_vocab)
n_exc_cognate <- sum(!attrition_participants_vnone$is_valid_cognate)
n_exc_noncognate <- sum(!attrition_participants_vnone$is_valid_noncognate)
n_exc_unrelated <- sum(!attrition_participants_vnone$is_valid_unrelated)

n_longitudinal <- attrition_participants_vnone |>
	filter(is_valid_participant) |>
	count(id, name = "times") |> 
	count(times)
```


We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_total` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). We also excluded trials in which participants did not provide at least 5% of valid samples to *both* target and distractor in the test phase (*n* = `r format(n_exc_test_each, big.mark = ",")`). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = `r n_exc_cognate`), the *non-cognate prime* condition (*n* = `r n_exc_noncognate`), or the *unrelated prime* condition (*n* = `r n_exc_unrelated`). The resulting dataset included `r format(n_trials_valid, big.mark = ",")` trials from `r n_participants_valid` participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.

```{r tbl-participants-lp-vnone}
#| label: tbl-participants-lp-vnone
#| tbl-cap: "Participant details for Analysis 3. Sample sizes indicate the number of participants included and excluded (between parenthesis) after applying inclusion criteria. Age is summarised using the mean and standard deviation (betwen parenthesis) for each age and language group separately."
participants_tmp <- participants |> 
	left_join(attrition_participants_vnone, by = join_by(filename)) |> 
	mutate(id = as.character(id))

participants_oxf_tmp <- participants_oxf |> 
	inner_join(attrition_participants_vnone_oxf,
			   by = join_by(id)) |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) 

bind_rows(participants_tmp, participants_oxf_tmp) |> 
	add_count(lp, 
			  name = "n_lp") |> 
	add_count(age_group, 
			  name = "n_age_group") |> 
	add_count(age_group,
			  test_language,
			  name = "n_age_test") |> 
	mutate(lp = factor(lp, levels = rev(unique(lp)))) |> 
	summarise(across(c(age), lst(mean, sd)),
			  n_inc = sum(is_valid_participant),
			  n_exc = sum(!is_valid_participant),
			  .by = c(age_group, lp, test_language)) |> 
	pivot_wider(id_cols = c(test_language, lp),
				names_from = c(age_group),
				values_from = c(matches("doe"), age_mean, age_sd, n_inc, n_exc),
				names_repair = janitor::make_clean_names) |>
	relocate(lp, test_language, 
			 n_inc_21_months, n_exc_21_months, age_mean_21_months, age_sd_21_months,
			 n_inc_25_months, n_exc_25_months, age_mean_25_months, age_sd_25_months,
			 n_inc_30_months, n_exc_30_months, age_mean_30_months, age_sd_30_months) |> 
	arrange(lp, test_language) |> 
	gt(rowname_col = "test_language", 
	   groupname_col = "lp", 
	   row_group.sep = ": ") |> 
	tab_spanner(md("21 months"), matches("21")) |> 
	tab_spanner(md("25 months"), matches("25")) |>
	tab_spanner(md("30 months"), matches("30")) |> 
	fmt_number(matches("age"), decimals = 1) |>
	cols_merge(c(n_inc_21_months, n_exc_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_25_months, n_exc_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_30_months, n_exc_30_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_21_months, age_sd_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_25_months, age_sd_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_30_months, age_sd_30_months),
			   pattern = "{1} ({2})") |> 
	cols_label(n_inc_21_months = md("*N*"),
			   n_inc_25_months = md("*N*"),
			   n_inc_30_months = md("*N*"),
			   age_mean_21_months = "Age (months)",
			   age_mean_25_months = "Age (months)",
			   age_mean_30_months = "Age (months)") |> 
	tab_style(cell_text(weight = "bold"),
			  list(cells_column_spanners())) |> 
	tab_style(cell_text(size = "medium"),
			  list(cells_body(),
			  	 cells_stub())) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("n"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	grand_summary_rows(starts_with("n"), 
					   fns = list(label = md("*N*")) ~ sum(.),
					   fmt = ~fmt_integer(.))
```

```{r tbl-attrition-trials-vnone}
#| label: tbl-attrition-trials-vnone
#| tbl-cap: "Trial attrition rate by condition for included participants in Analysis 3. Additional excluded trials are indicated between parentheses."
attrition_vnone_oxf |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) |> 
	bind_rows(mutate(attrition, id = as.character(id))) |> 
	filter(is_valid_participant) |> 
	summarise(n_valid = sum(is_valid_trial),
			  n_total = n(),
			  .by = c(id, age_group, lp, trial_type)) |> 
	summarise(across(n_valid, lst(sum, mean, sd),
					 .names = "{.fn}"),
			  n_total = sum(n_total),
			  .by = c(age_group, lp, trial_type)) |> 
	mutate(n_excluded = n_total-sum) |> 
	select(-c(n_total)) |> 
	pivot_wider(names_from = trial_type,
				values_from = c(sum:sd, n_excluded),
				names_repair = janitor::make_clean_names) |> 
	rename_with(\(x) gsub("non_cognate", "noncognate", x)) |> 
	arrange(age_group) |> 
	relocate(age_group,
			 matches("_cognate"),
			 matches("noncognate")) |> 
	gt(rowname_col = "age_group",
	   groupname_col = "lp") |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("sum"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 matches("mean"), 
				 fns = list(label = md("*Mean*"), id = "totals") ~ mean(.),
				 fmt = ~fmt_number(.)) |> 
	grand_summary_rows(columns = matches("mean_"),
					   fns = lst(Mean ~ mean(.)),
					   fmt = ~fmt_number(.)) |>
	grand_summary_rows(columns = matches("sum_"),
					   fns = lst(Sum ~ sum(.)),
					   fmt = ~fmt_integer(.)) |>
	cols_merge(c(sum_cognate, n_excluded_cognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_noncognate, n_excluded_noncognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_unrelated, n_excluded_unrelated),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(mean_cognate, sd_cognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_noncognate, sd_noncognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_unrelated, sd_unrelated),
			   pattern = "{1} ({2})") |>
	tab_spanner("Cognate trials", ends_with("_cognate")) |>
	tab_spanner("Non-cognate trials", ends_with("noncognate")) |> 
	tab_spanner("Unrelated trials", ends_with("unrelated")) |> 
	tab_spanner("Related trials", matches("cognate")) |>
	fmt_number(matches("mean|sd"), decimals = 1) |> 
	fmt_integer(matches("sum"), sep_mark = ",") |> 
	cols_label(sum_cognate = md("*N*"),
			   sum_noncognate = md("*N*"),
			   sum_unrelated = md("*N*"),
			   mean_cognate = md("*Mean (SD)*"),
			   mean_noncognate = md("*Mean (SD)*"),
			   mean_unrelated = md("*Mean (SD)*"))
```

### Phonological priming: Related vs. Unrelated

```{r fig-related-vnone}
#| label: fig-related-vnone
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 3. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_related_vnone, 
		  model_fits_related_vnone[[1]], 
		  contrast = "related")
```

### Cognate priming: Cognate vs. Non-cognate

```{r fig-cognate-vnone}
#| label: fig-cognate-vnone
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 3. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_cognate_vnone, 
		  model_fits_cognate_vnone[[1]], 
		  contrast = "cognate")
```

{{< pagebreak >}}

## Analysis 4

::: {.callout-note}

Participants do not need to know the prime or target words, and do not need to look to both pictures.

:::

```{r dataset-noeach}
n_trials <- nrow(attrition_trials_noeach)
n_trials_valid <- inner_join(attrition_participants_noeach,
							 attrition_trials_noeach) |> 
	filter(is_valid_participant) |> 
	pull(is_valid_trial) |> 
	sum()
n_participants_valid <- sum(attrition_participants_noeach$is_valid_participant)
n_exc_prime <- sum(!attrition_trials_noeach$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_trials_noeach$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_trials_noeach$is_valid_gaze_test_each)
n_exc_vocab <- sum(!attrition_trials_noeach$is_valid_vocab)
n_exc_cognate <- sum(!attrition_participants_noeach$is_valid_cognate)
n_exc_noncognate <- sum(!attrition_participants_noeach$is_valid_noncognate)
n_exc_unrelated <- sum(!attrition_participants_noeach$is_valid_unrelated)

n_longitudinal <- attrition_participants_noeach |>
	filter(is_valid_participant) |>
	count(id, name = "times") |> 
	count(times)
```


We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_total` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = `r n_exc_cognate`), the *non-cognate prime* condition (*n* = `r n_exc_noncognate`), or the *unrelated prime* condition (*n* = `r n_exc_unrelated`). The resulting dataset included `r format(n_trials_valid, big.mark = ",")` trials from `r n_participants_valid` participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.

```{r tbl-participants-lp-noeach}
#| label: tbl-participants-lp-noeach
#| tbl-cap: "Participant details for Analysis 4. Sample sizes indicate the number of participants included and excluded (between parenthesis) after applying inclusion criteria. Age is summarised using the mean and standard deviation (betwen parenthesis) for each age and language group separately."
participants_tmp <- participants |> 
	left_join(attrition_participants_noeach, by = join_by(filename)) |> 
	mutate(id = as.character(id))

participants_oxf_tmp <- participants_oxf |> 
	inner_join(attrition_participants_noeach_oxf,
			   by = join_by(id)) |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) 

bind_rows(participants_tmp, participants_oxf_tmp) |> 
	add_count(lp, 
			  name = "n_lp") |> 
	add_count(age_group, 
			  name = "n_age_group") |> 
	add_count(age_group,
			  test_language,
			  name = "n_age_test") |> 
	mutate(lp = factor(lp, levels = rev(unique(lp)))) |> 
	summarise(across(c(age), lst(mean, sd)),
			  n_inc = sum(is_valid_participant),
			  n_exc = sum(!is_valid_participant),
			  .by = c(age_group, lp, test_language)) |> 
	pivot_wider(id_cols = c(test_language, lp),
				names_from = c(age_group),
				values_from = c(matches("doe"), age_mean, age_sd, n_inc, n_exc),
				names_repair = janitor::make_clean_names) |>
	relocate(lp, test_language, 
			 n_inc_21_months, n_exc_21_months, age_mean_21_months, age_sd_21_months,
			 n_inc_25_months, n_exc_25_months, age_mean_25_months, age_sd_25_months,
			 n_inc_30_months, n_exc_30_months, age_mean_30_months, age_sd_30_months) |> 
	arrange(lp, test_language) |> 
	gt(rowname_col = "test_language", 
	   groupname_col = "lp", 
	   row_group.sep = ": ") |> 
	tab_spanner(md("21 months"), matches("21")) |> 
	tab_spanner(md("25 months"), matches("25")) |>
	tab_spanner(md("30 months"), matches("30")) |> 
	fmt_number(matches("age"), decimals = 1) |>
	cols_merge(c(n_inc_21_months, n_exc_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_25_months, n_exc_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_30_months, n_exc_30_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_21_months, age_sd_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_25_months, age_sd_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_30_months, age_sd_30_months),
			   pattern = "{1} ({2})") |> 
	cols_label(n_inc_21_months = md("*N*"),
			   n_inc_25_months = md("*N*"),
			   n_inc_30_months = md("*N*"),
			   age_mean_21_months = "Age (months)",
			   age_mean_25_months = "Age (months)",
			   age_mean_30_months = "Age (months)") |> 
	tab_style(cell_text(weight = "bold"),
			  list(cells_column_spanners())) |> 
	tab_style(cell_text(size = "medium"),
			  list(cells_body(),
			  	 cells_stub())) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("n"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	grand_summary_rows(starts_with("n"), 
					   fns = list(label = md("*N*")) ~ sum(.),
					   fmt = ~fmt_integer(.))
```

```{r tbl-attrition-trials-vnone}
#| label: tbl-attrition-trials-noeach
#| tbl-cap: "Trial attrition rate by condition for included participants in Analysis 4. Additional excluded trials are indicated between parentheses."
attrition_noeach_oxf |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) |> 
	bind_rows(mutate(attrition, id = as.character(id))) |> 
	filter(is_valid_participant) |> 
	summarise(n_valid = sum(is_valid_trial),
			  n_total = n(),
			  .by = c(id, age_group, lp, trial_type)) |> 
	summarise(across(n_valid, lst(sum, mean, sd),
					 .names = "{.fn}"),
			  n_total = sum(n_total),
			  .by = c(age_group, lp, trial_type)) |> 
	mutate(n_excluded = n_total-sum) |> 
	select(-c(n_total)) |> 
	pivot_wider(names_from = trial_type,
				values_from = c(sum:sd, n_excluded),
				names_repair = janitor::make_clean_names) |> 
	rename_with(\(x) gsub("non_cognate", "noncognate", x)) |> 
	arrange(age_group) |> 
	relocate(age_group,
			 matches("_cognate"),
			 matches("noncognate")) |> 
	gt(rowname_col = "age_group",
	   groupname_col = "lp") |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("sum"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 matches("mean"), 
				 fns = list(label = md("*Mean*"), id = "totals") ~ mean(.),
				 fmt = ~fmt_number(.)) |> 
	grand_summary_rows(columns = matches("mean_"),
					   fns = lst(Mean ~ mean(.)),
					   fmt = ~fmt_number(.)) |>
	grand_summary_rows(columns = matches("sum_"),
					   fns = lst(Sum ~ sum(.)),
					   fmt = ~fmt_integer(.)) |>
	cols_merge(c(sum_cognate, n_excluded_cognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_noncognate, n_excluded_noncognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_unrelated, n_excluded_unrelated),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(mean_cognate, sd_cognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_noncognate, sd_noncognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_unrelated, sd_unrelated),
			   pattern = "{1} ({2})") |>
	tab_spanner("Cognate trials", ends_with("_cognate")) |>
	tab_spanner("Non-cognate trials", ends_with("noncognate")) |> 
	tab_spanner("Unrelated trials", ends_with("unrelated")) |> 
	tab_spanner("Related trials", matches("cognate")) |>
	fmt_number(matches("mean|sd"), decimals = 1) |> 
	fmt_integer(matches("sum"), sep_mark = ",") |> 
	cols_label(sum_cognate = md("*N*"),
			   sum_noncognate = md("*N*"),
			   sum_unrelated = md("*N*"),
			   mean_cognate = md("*Mean (SD)*"),
			   mean_noncognate = md("*Mean (SD)*"),
			   mean_unrelated = md("*Mean (SD)*"))
```

### Phonological priming: Related vs. Unrelated

```{r fig-related-noeach}
#| label: fig-related-noeach
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 4. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_related_noeach, 
		  model_fits_related_noeach[[1]], 
		  contrast = "related")
```



### Cognate priming: Cognate vs. Non-cognate

```{r fig-cognate-noeach}
#| label: fig-cognate-noeach
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 4. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_cognate_noeach, 
		  model_fits_cognate_noeach[[1]], 
		  contrast = "cognate")
```

{{< pagebreak >}}

## Analysis 5

::: {.callout-note}

Participants need to know the prime or target words, and do not need to look to both pictures.

:::

```{r dataset-vnoeach}
n_trials <- nrow(attrition_trials_vnoeach)
n_trials_valid <- inner_join(attrition_participants_vnoeach,
							 attrition_trials_vnoeach) |> 
	filter(is_valid_participant) |> 
	pull(is_valid_trial) |> 
	sum()
n_participants_valid <- sum(attrition_participants_vnoeach$is_valid_participant)
n_exc_prime <- sum(!attrition_trials_vnoeach$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_trials_vnoeach$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_trials_vnoeach$is_valid_gaze_test_each)
n_exc_vocab <- sum(!attrition_trials_vnoeach$is_valid_vocab)
n_exc_cognate <- sum(!attrition_participants_vnoeach$is_valid_cognate)
n_exc_noncognate <- sum(!attrition_participants_vnoeach$is_valid_noncognate)
n_exc_unrelated <- sum(!attrition_participants_vnoeach$is_valid_unrelated)

n_longitudinal <- attrition_participants_vnoeach |>
	filter(is_valid_participant) |>
	count(id, name = "times") |> 
	count(times)
```


We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_total` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). After applying these trial-level inclusion criteria, we excluded participants who did not provide at least two valid trials in the *cognate prime* condition (*n* = `r n_exc_cognate`), the *non-cognate prime* condition (*n* = `r n_exc_noncognate`), or the *unrelated prime* condition (*n* = `r n_exc_unrelated`). The resulting dataset included `r format(n_trials_valid, big.mark = ",")` trials from `r n_participants_valid` participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.

```{r tbl-participants-lp-vnoeach}
#| label: tbl-participants-lp-vnoeach
#| tbl-cap: "Participant details for Analysis 5. Sample sizes indicate the number of participants included and excluded (between parenthesis) after applying inclusion criteria. Age is summarised using the mean and standard deviation (betwen parenthesis) for each age and language group separately."
participants_tmp <- participants |> 
	left_join(attrition_participants_vnoeach, by = join_by(filename)) |> 
	mutate(id = as.character(id))

participants_oxf_tmp <- participants_oxf |> 
	inner_join(attrition_participants_vnoeach_oxf,
			   by = join_by(id)) |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) 

bind_rows(participants_tmp, participants_oxf_tmp) |> 
	add_count(lp, 
			  name = "n_lp") |> 
	add_count(age_group, 
			  name = "n_age_group") |> 
	add_count(age_group,
			  test_language,
			  name = "n_age_test") |> 
	mutate(lp = factor(lp, levels = rev(unique(lp)))) |> 
	summarise(across(c(age), lst(mean, sd)),
			  n_inc = sum(is_valid_participant),
			  n_exc = sum(!is_valid_participant),
			  .by = c(age_group, lp, test_language)) |> 
	pivot_wider(id_cols = c(test_language, lp),
				names_from = c(age_group),
				values_from = c(matches("doe"), age_mean, age_sd, n_inc, n_exc),
				names_repair = janitor::make_clean_names) |>
	relocate(lp, test_language, 
			 n_inc_21_months, n_exc_21_months, age_mean_21_months, age_sd_21_months,
			 n_inc_25_months, n_exc_25_months, age_mean_25_months, age_sd_25_months,
			 n_inc_30_months, n_exc_30_months, age_mean_30_months, age_sd_30_months) |> 
	arrange(lp, test_language) |> 
	gt(rowname_col = "test_language", 
	   groupname_col = "lp", 
	   row_group.sep = ": ") |> 
	tab_spanner(md("21 months"), matches("21")) |> 
	tab_spanner(md("25 months"), matches("25")) |>
	tab_spanner(md("30 months"), matches("30")) |> 
	fmt_number(matches("age"), decimals = 1) |>
	cols_merge(c(n_inc_21_months, n_exc_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_25_months, n_exc_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_inc_30_months, n_exc_30_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_21_months, age_sd_21_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_25_months, age_sd_25_months),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(age_mean_30_months, age_sd_30_months),
			   pattern = "{1} ({2})") |> 
	cols_label(n_inc_21_months = md("*N*"),
			   n_inc_25_months = md("*N*"),
			   n_inc_30_months = md("*N*"),
			   age_mean_21_months = "Age (months)",
			   age_mean_25_months = "Age (months)",
			   age_mean_30_months = "Age (months)") |> 
	tab_style(cell_text(weight = "bold"),
			  list(cells_column_spanners())) |> 
	tab_style(cell_text(size = "medium"),
			  list(cells_body(),
			  	 cells_stub())) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("n"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	grand_summary_rows(starts_with("n"), 
					   fns = list(label = md("*N*")) ~ sum(.),
					   fmt = ~fmt_integer(.))
```


```{r tbl-attrition-trials-vnoeach}
#| label: tbl-attrition-trials-vnoeach
#| tbl-cap: "Trial attrition rate by condition for included participants in Analysis 4. Additional excluded trials are indicated between parentheses."
attrition_vnoeach_oxf |> 
	mutate(lp = "Monolingual (Oxford)",
		   id = as.character(id)) |> 
	bind_rows(mutate(attrition, id = as.character(id))) |> 
	filter(is_valid_participant) |> 
	summarise(n_valid = sum(is_valid_trial),
			  n_total = n(),
			  .by = c(id, age_group, lp, trial_type)) |> 
	summarise(across(n_valid, lst(sum, mean, sd),
					 .names = "{.fn}"),
			  n_total = sum(n_total),
			  .by = c(age_group, lp, trial_type)) |> 
	mutate(n_excluded = n_total-sum) |> 
	select(-c(n_total)) |> 
	pivot_wider(names_from = trial_type,
				values_from = c(sum:sd, n_excluded),
				names_repair = janitor::make_clean_names) |> 
	rename_with(\(x) gsub("non_cognate", "noncognate", x)) |> 
	arrange(age_group) |> 
	relocate(age_group,
			 matches("_cognate"),
			 matches("noncognate")) |> 
	gt(rowname_col = "age_group",
	   groupname_col = "lp") |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 starts_with("sum"), 
				 fns = list(label = md("*N*"), id = "totals") ~ sum(.)) |> 
	summary_rows(groups = c("Monolingual (Oxford)",
							"Monolingual",
							"Bilingual"),
				 matches("mean"), 
				 fns = list(label = md("*Mean*"), id = "totals") ~ mean(.),
				 fmt = ~fmt_number(.)) |> 
	grand_summary_rows(columns = matches("mean_"),
					   fns = lst(Mean ~ mean(.)),
					   fmt = ~fmt_number(.)) |>
	grand_summary_rows(columns = matches("sum_"),
					   fns = lst(Sum ~ sum(.)),
					   fmt = ~fmt_integer(.)) |>
	cols_merge(c(sum_cognate, n_excluded_cognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_noncognate, n_excluded_noncognate), 
			   pattern = "{1} ({2})") |> 
	cols_merge(c(sum_unrelated, n_excluded_unrelated),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(mean_cognate, sd_cognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_noncognate, sd_noncognate),
			   pattern = "{1} ({2})") |>
	cols_merge(c(mean_unrelated, sd_unrelated),
			   pattern = "{1} ({2})") |>
	tab_spanner("Cognate trials", ends_with("_cognate")) |>
	tab_spanner("Non-cognate trials", ends_with("noncognate")) |> 
	tab_spanner("Unrelated trials", ends_with("unrelated")) |> 
	tab_spanner("Related trials", matches("cognate")) |>
	fmt_number(matches("mean|sd"), decimals = 1) |> 
	fmt_integer(matches("sum"), sep_mark = ",") |> 
	cols_label(sum_cognate = md("*N*"),
			   sum_noncognate = md("*N*"),
			   sum_unrelated = md("*N*"),
			   mean_cognate = md("*Mean (SD)*"),
			   mean_noncognate = md("*Mean (SD)*"),
			   mean_unrelated = md("*Mean (SD)*"))
```


### Phonological priming: Related vs. Unrelated

```{r fig-related-vnoeach}
#| label: fig-related-vnoeach
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 5. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_related_vnoeach, 
		  model_fits_related_vnoeach[[1]], 
		  contrast = "related")
```

### Cognate priming: Cognate vs. Non-cognate

```{r fig-cognate-vnoeach}
#| label: fig-cognate-vnoeach
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 5. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *cognate* and *non-cognate* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
plot_gamm(data_time_cognate_vnoeach, 
		  model_fits_cognate_vnoeach[[1]], 
		  contrast = "cognate")
```

# Discussion

# References


{{< pagebreak >}}

# Appendix

## Appendix A: imputing voabulary size scores

```{r fig-vocabulary-imputation}
vocabulary_tmp <- vocabulary |> 
	left_join(select(participants, child_id = id_db, age, age_group, filename),
			  by = join_by(filename)) |> 
	relocate(child_id) |> 
	select(-filename) |> 
	filter(is_imputed) |> 
	mutate(child_id = as.character(child_id))

bvq_data$vocabulary |> 
	inner_join(distinct(bvq_data$logs, id, age_group, age),
			   by = join_by(id, age_group)) |> 
	rename(child_id = id) |> 
	mutate(is_imputed = FALSE) |> 
	bind_rows(vocabulary_tmp) |> 
	pivot_longer(ends_with("_prop"),
				 names_to = "measure",
				 values_to = "prop") |> 
	drop_na(prop) |> 
	mutate(is_imputed = ifelse(is_imputed, "Imputed", "Observed"),
		   measure = factor(measure,
		   				 levels = c("total_prop",
		   				 		   "l1_prop",
		   				 		   "l2_prop",
		   				 		   "concept_prop",
		   				 		   "te_prop"),
		   				 labels = c("Total",
		   				 		   "L1",
		   				 		   "L2",
		   				 		   "Conceptual",
		   				 		   "TE"))) |> 
	ggplot(aes(age, prop, 
			   colour = is_imputed,
			   fill = is_imputed)) +
	facet_wrap(~measure) +
	geom_point(alpha = 1/4, size = 1) +
	geom_smooth(method = "glm", 
				formula = "y ~ x",
				method.args = list(family = "binomial"), 
				# se = FALSE,
				size = 1) +
	labs(x = "Age (months)",
		 y = "Vocabulary size",
		 fill = "Imputed",
		 colour = "Imputed") +
	theme(legend.position = c(1, 0),
		  legend.justification = c(1, 0),
		  legend.title = element_blank())

```

{{< pagebreak >}}


## Appendix B: distribution of prime and target looking times

```{r fig-dist-prime}
#| label: fig-dist-prime
#| fig-height: 4
#| fig-width: 8
looking_times |> 
	mutate(prime_time = cut(prime_time, 
							seq(0, 1.5, 0.1),
							labels = FALSE,
							include.lowest = TRUE)) |> 
	add_count(lp, age_group, name = "n_total") |> 
	count(lp, age_group, prime_time, n_total) |> 
	mutate(n = n / n_total) |> 
	ggplot(aes(prime_time, n)) +
	facet_grid(lp~age_group) +
	annotate(geom = "rect",
			 fill = "orange",
			 ymin = -Inf,
			 ymax = Inf,
			 xmin = 0,
			 xmax = 0.75*10,
			 alpha = 1/3,
			 colour = NA) +
	# annotate(label = "Excluded trials",
	# 		 geom = "text",
	# 		  x = (0.75/2)*10,
	# 		  y = 1)
	geom_col(fill = "black") +
	labs(x = "Prime looking time (s)",
		 y = "Proportion of trials") +
	scale_x_continuous(labels = \(x) x/10) +
	theme(panel.grid.major.y = element_line(linetype = "dotted",
											colour = "grey"))
```

```{r fig-dist-target}
#| label: fig-dist-target
#| fig-height: 4
#| fig-width: 8
looking_times |> 
	mutate(target_time = cut(target_time, 
							 seq(0, 2, 0.1),
							 labels = FALSE,
							 include.lowest = TRUE)) |> 
	add_count(lp, age_group, name = "n_total") |> 
	count(lp, age_group, target_time, n_total) |> 
	mutate(n = n / n_total) |> 
	ggplot(aes(target_time, n)) +
	facet_grid(lp~age_group) +
	# annotate(label = "Excluded trials",
	# 		 geom = "text",
	# 		  x = (0.75/2)*10,
	# 		  y = 1)
	geom_col(fill = "black") +
	labs(x = "Targets looking time (s)",
		 y = "Proportion of trials") +
	scale_x_continuous(labels = \(x) x/10) +
	theme(panel.grid.major.y = element_line(linetype = "dotted",
											colour = "grey"))
```

{{< pagebreak >}}

## Appendix C: prime and test looking times

```{r fig-looking-times}
#| label: fig-looking-times
#| fig-height: 8
#| fig-width: 8
#| fig-cap: "Looking time (s) to the prime and target AOI against audio duration. In longer audios, participants are expected to look longer to the prime and target picture."

looking_times |>
	left_join(select(attrition_trials, 
					 filename, trial, is_valid_trial),
			  by = join_by(filename, trial)) |>
	filter(is_valid_trial) |> 
	ggplot(aes(duration,
			   prime_time,
			   colour = trial_type, 
			   fill = trial_type,
			   shape = trial_type)) +
	facet_grid(lp~age_group) +
	geom_point(alpha = 0.5, 
			   size = 1) +
	geom_smooth(method = "lm") +
	theme(axis.title.x = element_blank()) +
	
	looking_times |>
	left_join(select(attrition_trials, 
					 filename, trial, is_valid_trial),
			  by = join_by(filename, trial)) |>
	filter(is_valid_trial) |> 
	ggplot(aes(duration,
			   target_time,
			   colour = trial_type, 
			   fill = trial_type,
			   shape = trial_type)) +
	facet_grid(lp~age_group) +
	geom_point(alpha = 0.5,
			   size = 1) +
	geom_smooth(method = "lm",
				formula = "y ~ x") +
	plot_layout(ncol = 1, guides = "collect") &
	plot_annotation(tag_levels = "A") &
	labs(x = "Audio duration (s)",
		 y = "Looking time (1.0-2.0 seconds)",
		 colour = "Prime type",
		 fill = "Prime type",
		 shape = "Prime type") 
```


