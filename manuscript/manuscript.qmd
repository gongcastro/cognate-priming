---
---

```{r setup}
#| label: setup
#| echo: false
#| message: false
#| warning: false
# load objects
targets::tar_config_set(store = here::here("_targets"),
						script = here::here("_targets.R"))

targets::tar_load_globals()

targets::tar_load(
	c(participants,
	  stimuli,
	  vocabulary,
	  attrition_trials,
	  attrition_participants,
	  bvq_data,
	  gaze,
	  data_time_bcn
	))

targets::tar_load(
	c(model_fits_bcn,
	  model_loos_bcn
	))

# prepare data
attrition <- lst(participants,
				 attrition_participants,
				 attrition_trials) |>
	reduce(inner_join, by = join_by(session_id)) |>
	unnest_wider(matches("all"), names_sep = "_") |> 
	rename_with(\(x) gsub("is_valid_gaze_all_|is_valid_vocab_all", "", x))

library(knitr)
library(kableExtra)
library(ggplot2)
library(gt)
library(gtExtras)
library(patchwork)
library(english)
library(gtExtras)

# set ggplot theme and colour palette
my_theme <- theme_minimal() +
	theme(panel.grid = element_blank(),
		  axis.line = element_line(colour = "black"),
		  text = element_text(size = 12, colour = "black"),
		  axis.text = element_text(colour = "black"))

theme_set(my_theme)

clrs <- c("#003f5c", "#58508d", "#bc5090", "#ff6361", "#ffa600")

options(ggplot2.ordinal.fill = clrs[c(1, 4, 5)],
		ggplot2.ordinal.colour = clrs[c(1, 4, 5)],
		ggplot2.discrete.fill = clrs[c(1, 4, 5)],
		ggplot2.discrete.colour = clrs[c(1, 4, 5)],
		ggplot2.continuous.fill = ggplot2::scale_color_gradient,
		ggplot2.continuous.colour = ggplot2::scale_color_gradient)

set.seed(888)
```

# Introduction

Building a mental lexicon is a major achievement in the development of an infant. By storing representations of how familiar words sound and what they mean, an infant is able to make sense of their linguistic input. Infants start forming their first lexical representations before their first year of life [@jusczyk1999; @halle1994; @vihman2004; @parise2012electrophysiological; @bergelson20126; @bergelson2015early]. This initial lexicon consists of only a few items; mainly words for people, interjections, body parts, and food [@tincoff2012six; @tardif2008baby], but it undergoes rapid growth during their second year of life [@ganger2004reexamining; @goldfield1990early; @bloom2002children; @mcmurray2007defusing]. According to parental reports the average 15-month-old infant already understands more than 100 words, and by two years, they understand more than 400 words [@frank2021variability]. This accelerated lexical developmental is reflected in infants' trajectories of word recognition: infants recognise familiar words faster and more efficiently as they approach their second birthday [@fernald1998rapid; @fernald2001half; @hurtado2007spoken].

Despite being exposed to a more complex linguistic input, bilinguals show equivalent trajectories of word acquisition and word recognition to their monolingual peers' [@vihman2007onset; @vihman2013; @legacy2018vocabulary; @hoff2012; @de2014bilingual; @pearson1994patterns; @byers-heinlein2023sometimes]. This is a remarkable deed for two reasons. First, bilingual infants receive a relative impoverished linguistic input in each of their languages compared to monolinguals [@costa2014does]. Second, they face a more complex referential context, since they often learn two labels for each referent, one in each language. The mechanisms that allow bilingual infants to keep up with monolinguals in their lexical development trajectories are still unclear.

Monolinguals and bilinguals share broadly common word-recognition mechanisms. The first step towards spoken word-recognition is the acoustic-phonetic processing of the speech signal, which results in the activation of lexical representations whose associated phonological forms match the acoustic signal. The activated word-forms then compete for selection: the lexical system uses the bottom-up information provided by the auditory input, together with top-down context---provided by grammatical, supra-segmental, and semantic constraints---to select the candidate lexical representation with the best match. This sequence of events occurs in a *cascaded* fashion. As the recognition system accumulates information about the unfolding acoustic signal, matching phonological representations are activated [@marslen1987functional; @marslen1978processing; @grosjean1980spoken], and in turn activate their associated semantic representations [@neely1977semantic]. By the time lexical selection occurs, many non-selected phonological and semantic representations have been activated, potentially modulating the dynamics of word recognition. 

A considerable amount of evidence for such cascaded account of lexical processing has been provided by studies recording eye movements during word recognition. For example, @allopenna1998tracking designed a word-recognition task in which participants were presented, in each trial, with four objects in the screen. Participants would then listen to a command like "Pick up the beaker; now put it below the diamond", and perform the action. The authors manipulated the phonological relationship between the target object's label (e.g., *casket*), and the label of each of the three distractors. Two of the distractors were phonologically related with the target, sharing onset (e.g., *castle*) or offset (e.g., *basket*) with the target word, respectively. The other distractor was phonologically unrelated to the target (e.g., *nickel*). After hearing the target label, phonological distractors attracted participants' eye fixations more than unrelated distractors. Distractors sharing phonological onset did so at an earlier time window than those sharing phonological offset. This time course of distractor fixations suggests that the auditory presentation of the target label activated no only its (subsequently selected) phonological form in participants' lexicon, but also that of phonologically related word-forms, leading to competition for selection between the word forms. These results converge with cascaded models of auditory word recognition, in which the unfolding acoustic input activates multiple phonological word-forms, which in turn compete for selection, like TRACE [@mcclelland1986trace] and Shortlist [@norris1994shortlist].

The developing mental lexicon also seems to operate in this cascaded fashion. Like adults, infants activate non-selected lexical representations. This is reflected by the fact that from 21 months of age, infants' lexicon seems to also be systematically organised according to the semantic and phonological properties of its lexical representations. Priming paradigms of word recognition have provided a strong body of evidence for the existence of phonological and semantic links between early lexical representations between 18 and 21 months of age [@arias2009lexical; @styles2009infants]. For instance, using a word recognition task, @arias2009lexical found that infants' spoken word recognition (e.g., *dot*) was interfered by the previous presentation of a semantically related word (e.g., *cat*). Other studies have provided electrophysiological evidence of semantic priming at earlier ages [e.g., @rama2013development; @friedrich2005lexical]. More recent studies have provided evidence for the emergence of such semantic links, even in the absence of visual referents during the experimental task [@willits2013toddlers].

Phonological priming effects have also been reported in the initial lexicon. @mani2010infant created an implicit naming task in which each trial started with the *silent* presentation of a prime picture. Then, a target-distractor picture pair was presented side-by-side. Finally, the target picture's label was presented auditorily. The authors manipulated the phonological overlap between the prime label and the target label, so that in half of the trials both labels were phonologically related, sharing phonological onset (*cat*-*cup*), or phonologically unrelated (*ball*-*comb*). Prime and target-distractor pairs were semantically unrelated. Interestingly, infants showed a stronger looking preference for the target picture after phonologically related prime pictures, compared to after phonologically unrelated primes. This suggests that infants implicitly named prime pictures despite such pictures having been presented in silence, and that the phonology of the resulting label interacted with the subsequent auditory recognition of the target label.The authors found a facilitation effect: target looking preference was stronger in phonologically related primes, indicating that the activated phonological segments of the generated prime label facilitated the subsequent activation of the phonological representation of the target label during recognition.

In a follow-up study, @mani2011phonological found the opposite effect in older toddlers. After phonologically related primes, 24 month-old toddlers showed weaker target looking preference than after phonologically unrelated primes. These results interpreted these outcome as the result of the implicitly generated prime label interfering with the subsequent recognition of the (phonologically related) target word. The authors suggested that the shift from facilitation to interference from 18 to 24 months they found in both studies might be the result of a developmental shift in which 18-month-olds' lexicon is not yet organised based on phonological similarity, while 24-month-olds' is. This would lead to the former showing a pre-lexical facilitation effect in which such facilitation occurs via the activation of phonological segments, while the latter would show an interference effect due to lateral links between lexical representation having been established.

More recently, @chow2017spoken adapted the Visual World Paradigm from @huettig2007tug to explore 24- to 30-month-old toddlers' visual fixation patterns during a word recognition when presented with phonological and semantic distractors. In each trial, the authors presented participants with four semantically and phonologically pictures. Four seconds after pictures onset, a word-form was auditorily presented. The word did not refer to any of the pictures displayed on the screen, but was phonologically related to one of them (both labels shared phonological onset), and semantically related to another one of the pictures (both referents belonged to the same taxonomic category. For instance, participants might be presented with the pictures of a sandwich, a bus, a cat, and a dress. Then they would hear the carrier phrase "Look at the **bee**!". The authors registered participants fixations to the phonological and semantic distractors, and found evidence of a preference for the phonological distractor at earlier stages of the post-naming phase, and a preference for the semantic distractor at later stages of the trial. These results support a cascaded activation account of lexical access during the first stages of lexical development, paralleling previous findings in adults [@allopenna1998tracking].

Bilinguals provide one of the most interesting pieces of evidence in support of a cascaded account of lexical processing. A critical property the bilingual lexicon is that its representations are accessed in a language-non selective way. Even during monolingual situations, bilinguals access their lexical representations in both of their languages [e.g.; @thierry2007brain; @dunabeitia2009masked]. This is reflected in bilinguals' performance in word recognition and production tasks. For instance, @marian1999activation presented Russian-English bilinguals with a series of trials that started with an auditory instruction like "Poloji marku nije krestika" ["Put the stamp below the cross"]. The instruction would be present in Russian (dominant language for most participants). The target object (*marku* [*stamp*], in this case) would be present in the screen, together with an object whose English label shared phonological onset with the target label (e.g., *mark*), and two unrelated distractors whose labels in Russian and English did not shared phonological relationship with the target label. Converging with @allopenna1998tracking's results in monolingual adults, after hearing the target label bilinguals fixated the cross-language phonological distractor significantly more than the unrelated distractors. These findings suggest that participants activated phonologically related word-forms in both Russian *and* English, which affected their overt visual exploration patterns during the task.

Language non-selectivity in the bilingual lexicon has also been shown to affect top-down lexical access during word production. @costa2000cognate presented Catalan-Spanish bilinguals with a series of pictures of familiar objects. For each object, participants were asked to name it in Catalan (their dominant language). Unbeknownst to participants, the authors manipulated the phonological overlap between the pictures' labels in Catalan and their translations in Spanish. Participants produced faster words that shared phonological overlap with their Spanish translations (e.g., *gat*-*gat* [*cat*]) than those unrelated to their translation (e.g., *taula*-*mesa* [*table*]). Critically, Spanish monolinguals who completed the same task, naming the pictures in Spanish, showed equivalent naming times in both conditions. These results reveal that bilinguals activated their Spanish phonology, despite performing the naming task exclusively in Catalan: the visual recognition of the presented pictures led to the activation of its associated phonological forms in both language sin parallel, which influenced the subsequent the dynamics of word production.

Further support for the parallel retrieval of phonological forms during word production is given by implicit naming paradigms. Using an adaptation of @mani2010infant's task, @von2014bilinguals provided evidence that bilingual adults generate implicit labels in both labels for visually fixated pictures. The authors presented German-English bilinguals with 120 prime-target pairs. Primes were presented as familiar pictures in silence. After prime picture offset, target words were presented auditorily. Participants' N400 ERP components were recorded from target word onset. The authors manipulated the phonological relationship between the prime and target word-forms within participants' L1 and across L1 and L2. When prime and target were phonologically identical (*Affe*-*Affe*, German for *monkey*), or similar (*Fahne*-*Sahne*, German for *flag* and *ice-cream*, respectively) within L1, participants' showed a reduced N400 amplitude, compared to when prime and target were phonologically unrelated (*Messer*-*Seil*, German for *knife* and *rope*). Critically, a similar effect was found when prime and target were phonologically related through translation (*Rustsche*-*Kleid*, German for *slide* and *dress*). This suggests that participants activated prime labels in both languages in parallel, and that both labels impacted the dynamics of target words recognition.

Phonological priming paradigms have also revealed language non-selectivity in the initial bilingual lexicon. For instance, @von2012language found evidence of cross-language phonological priming in 21- to 42-months-old children learning German and English. At the beginning of each trial, the authors auditorily presented an English prime word embedded in a carrier phrase. Then, the target label was auditorily presented in German. Finally the target and distractor pictures were presented side-by-side. The authors manipulated the phonological overlap between the prime and target labels. The novelty in this study lied in the orthogonal manipulation of the phonological overlap between both labels in English and German. In some trials, the auditorily presented prime and target labels were phonologically related (e.g., *slide*-*Klide* [*dress*]). In some other trials, both labels were phonologically related through translation: the auditorily presented prime label did *not* overlap with the target label (e.g., *leg*-*Stein* [*stone*]), but its translation in German did [*Bein*]. In the rest of the trials prime and target labels were phonologically unrelated in both languages. The authors found a facilitation effect of cross-language priming when both prime and target auditory labels overlapped phonologically, as revealed by a stronger target picture looking preference, as compared to that of unrelated trials. Interestingly, participants showed a weaker target preference in priming through translation trials. Since participants' target recognition was interfered by the non-presented prime translation, such an inhibitory effect must stem at the lexical level. The fact that phonological priming facilitated the recognition of the target words (both labels belong to different languages), and that phonological priming through translation interfered target recognition (translation and target belong to the same language) points to cross-language connections playing an excitatory role, and to within-language connections playing an inhibitory role.

@floccia2020translation tested 27-month-old simultaneous bilinguals in a cross-language priming paradigm. The two languages participants were learning were English, and an Additional Language (either Cantonese, Dutch, French, German, Greek, Italian, Mandarin, Polish, Portuguese, or Spanish). A prime word was embedded at the end of a carrier sentence that participants listened to. Then participants were presented with the auditory label of the target word, and two pictures were shown side-by-side, the target picture, and a distractor picture. In Study 1, the target word was the translation equivalent of the prime word (*cheese*-*fromage* for an English-French bilingual). In other trials, prime and target words were unrelated (e.g., *sock*-*fromage*). There was no phonological overlap at onset between prime and target or distractor labels in either of the two conditions. Participants were presented with two blocks of related and unrelated trials. In one of the blocks, participants were presented with English prime words and Home Language target words (*sock*-*fromage*), and in the other block they were presented with Additional Language prime words and English target words (*fromage*-*sock*). The authors found a cross-linguistic priming effect, in which participants showed a stronger preference for the target picture in the post-naming phase in related trials, as compared to unrelated trials. This effect was found regardless of the language of the prime (English or Home Language), or the dominance of the language of the prime (i.e., whether the prime word belonged to the dominant language). Target preference exceeded chance level in both conditions. In Study 2, the authors tested a similar group of bilinguals in a cross-linguistic semantic priming task, in which participants were primed with words in English, and tested with semantically related words in the Additional Language (or vice versa). This time, prime and target words were not translation equivalents, but rather words whose referents shared semantic features. Results from Study  2 were parallel to those from Study 1. The authors found a strong semantic priming effect across languages, regardless of the language of the prime or the dominance of the language of the prime. Overall these results suggest that bilinguals recognised target words in both conditions, and benefited from a cross-linguistic facilitation effect from translation equivalents. The symmetry of such effect across both languages suggests that participants lexical access occurred in parallel for the two members of translation equivalents. As @floccia2020translation note, the stimuli set of Study 2 contains multiple cognates, especially in languages with a larger degree of phonological overlap across translation pairs, like English and Dutch. The authors run *post hoc* analyses exploring the effect of cognateness on the cross-language priming effects found, which showed no evidence of a cognateness effect on target preference. However, the cross-language effects reported in Study 2 might still reflect the confounding influence of cognateness, as the resulting effect might have been generated by an interaction by the phonological and semantic overlap between cognate primes and targets.

The aforementioned studies use priming-though-translation paradigms. In these paradigms, cross-linguistic priming results from activation spreading from the lexical representation of the the (auditorily presented) prime word to the lexical representation of its translation through semantic associations (e.g., translation equivalence). When prime words are auditorily presented, the task design constraints the naming context to one of the languages. The consequence is a potential asymmetry between the activation dynamics of the lexical representation of both labels: while the participant has heard one label, the activation of its translation must spread across semantic links. This might lead to a lower strength, and higher latency of the activation of the translation. 

Priming through translation paradigms prove the existence of cross-language phonological associations at the lexical level, as suggested by the fact that non-presented prime translations can interfere with subsequent target recognition. However, since participants are auditorily presented with a prime label, the contribution of sub-lexical facilitation through acoustic similarity cannot be ruled out. For instance, it is possible that the inhibitory priming through translation found by @von2012language is the result

THERE IS NO EVIDENCE OF IMPLICIT NAMING IN BILINGUALS

In the present study, we use an adaptation of an implicit naming paradigm by @mani2010infant, in which participants are primed with a picture, instead of an auditorily presented label. This paradigm prevents infants from activating the prime label in any of their two languages, and therefore makes it more likely that they will activate the prime labels in both languages in parallel. Infants implicitly named prime pictures despite such pictures having been presented in silence, and that the phonology of the resulting label interacted with the subsequent auditory recognition of the target label. In particular, the authors found a facilitation effect: target looking preference was stronger in phonologically related primes, indicating that the activated phonological segments of the generated prime label facilitated the subsequent activation of the phonological representation of the target label during recognition.


When extended to the bilingual case, this implicit naming task may offer bilingual participants with an unconstrained naming context in which the activation of both labels may occur in a truly cascaded fashion for both languages in parallel: the recognition of the prime object depicted activates the (common) semantic representation for both members of the translation equivalent, and this in turn activates the two available phonological word-forms, one in each language. 





This study also provides a more suitable design for drawing conclusions about developmental change in word recognition trajectories for two reasons. First, it extends the age range of participants, compared to previous studies. Second, participants were tested at three selected age points to ensure a more balanced sample size across ages. Third, the partially longitudinal design allows modelling the performance of participants across testing sessions altogether.

In order to circumvent the problem of limited vocabulary knowledge
in the non-dominant language, we propose to test participants only in their dominant language, therefore
directing our research to the question of how possessing a second language affects processing of the
dominant one in bilingual toddlers [@costa2014does provide a fuller description of the
advantages of such approach].


The present study is aimed at investigating the developmental trajectories of word recognition in bilingualism, and how (if at all) language non-selectivity shapes them. Using an adaptation of [@mani2010infants], we presented 20- to 32-months-old toddlers with a cross-linguistic phonological priming paradigm. We manipulated both the phonological overlap between the prime word and target word, and the cognate status of the prime word, to test the hypothesis that bilingual toddlers implicitly name familiar pictures in both languages. If so, phonological priming effect should be larger when the prime label in  both languages shares phonological overlap with the target words (cognate condition), compared to when only the label of the prime in one language overlaps phonologically with the target (non-cognate condition). We also also included a control *Unrelated* condition in which regardless of the cognate status of the prime word, neither of the prime labels in any language overlapped phonologically with the target word.

We compared the explanatory power of three measures of vocabulary size on participants' trajectories of word recognition: L1 vocabulary and total vocabulary.Previous studies suggest that same-language vocabulary size predicts better bilingual infants' performance in word recognition tasks, as compared to cross-language vocabulary size [@marchman2010vocabulary]

Hypothesis 1: if lexical representations linked through inhibitory links (compete for selection), like in the adult lexicon, target looking should increase faster in *Unrelated* trials compared to *Related* trials. If lexical representations are linked through excitatory links, target preference should increase faster in *Related* trials, compared to *Unrelated* trials. If lexical representations are sparsely connected, participants should show equivalent patterns of target looking in *Related* and *Unrelated* trials.

Hypothesis 2: if bilinguals' lexical representations linked across languages through inhibitory links (compete for selection), target looking should increase faster in this group in *Related/Non-cognate* trials compared to *Related/Cognate* trials. If lexical representations are linked across languages through excitatory links, target preference should increase faster in *Related/Cognate* trials, compared to *Unrelated/Cognate* trials. If lexical representations are sparsely connected across languages, bilinguals' patterns of target looking should be equivalent for *Related/Cognate* and *Related/Non-cognate* trials. This pattern is also expected for monolingual infants.

Hypothesis 3: if the emergence of within-language or cross-language phonological links is explained (if at all) by the growth of within-language vocabulary size, the difference in target looking between *Related* and *Unrelated*, or between *Related/Cognate* and *Related/Non-cognate* trials should be larger in participants with larger vocabulary sizes in their dominant language, in which they were tested. This should be reflected by a $\text{Condition} \times \text{L1 vocabulary}$ two -way interaction, or a $\text{Condition} \times \text{Group} \times \text{Dominant vocabulary}$ three-way interaction.

Hypothesis 4: if the emergence of within-language or cross-language phonological links is explained better by the growth of cross-language vocabulary size, compared to within-language vocabulary size, a model that incorporates total vocabulary size as a predictor instead of dominant vocabulary size should show better predictive performance. If the emergence of such links is explained at all by the growth of vocabulary size, both models incorporating vocabulary size as a predictor should show better predictive performance than a model incorporating participants' age.

# Study 1

## Methods

All materials, data, and reproducible code can be found at the OSF ([https://osf.io/hy984/](https://osf.io/ckydb/)) and GitHub ([https://github.com/gongcastro/cognate-priming](https://github.com/gongcastro/cognate-priming)) repositories. This study was conducted according to guidelines laid down in the Declaration of Helsinki, and was approved by the Drug Research Ethical Committee (CEIm) of the IMIM Parc de Salut Mar, reference 2020/9080/I. Before every testing session, caregivers were asked to read and sign an informed consent form, and were given a token of appreciation at the end of it.

### Participants

```{r}
#| label: participants-numbers
participants_bcn <- filter(participants, location=="Barcelona")

n_participants_total <- nrow(distinct(participants_bcn, child_id))
n_sessions_total <- count(participants_bcn)

n_participants_lp <- participants_bcn |> 
	distinct(lp, child_id) |> 
	count(lp)

n_participants_lp_sex <- participants_bcn |> 
	distinct(lp, sex, child_id) |> 
	count(lp, sex)

n_participants_sessions <- participants_bcn |> 
	count(child_id, name = "n_sessions") |> 
	count(n_sessions) |> 
	group_split(n_sessions) |> 
	set_names(paste0("session_", 1:3)) |> 
	map("n")

n_sessions_lp <- participants_bcn |> 
	summarise(across(age, lst(mean, sd, min, max)), n = n(), .by = c(lp)) |> 
	mutate(across(age_mean:age_max, \(x) round(x, 2))) |> 
	group_split(lp) |> 
	set_names(janitor::make_clean_names(unique(participants_bcn$lp)))

n_sessions_dominance_lp <- count(participants_bcn, lp, test_language) |> 
	group_split(test_language) |> 
	set_names(c("catalan", "spanish")) |> 
	map(group_split, lp) 

n_sessions_lp <- participants_bcn |> 
	count(lp) |> 
	group_split(lp) |> 
	set_names(c("monolingual", "bilingual")) |> 
	map("n")
```

We collected data from `r n_participants_total$n[1]` children living in the Metropolitan Area of Barcelona (Spain), tested at the Laboratori de Recerca en InfÃ ncia at the Universitat Pompeu Fabra. Families were recruited from maternity rooms in private hospitals and social media, and contacted via phone when the child's age spanned between 20 and 32 months. From the `r n_participants_total$n` children that participated, `r n_participants_sessions$session_1` participated once, `r n_participants_sessions$session_2` participated twice, and `r n_participants_sessions$session_3` participated three times. Recurrent participants were tested with at least XXX months of difference. We gathered a total of `r n_sessions_total$n` testing sessions. Participants were divided into monolinguals and bilinguals based on their relative degree of exposure to Catalan and Spanish, estimated using the Language Exposure Questionnaire [LEQ, @bosch2001evidence]. We categorised participants as monolingual if exposed to more than 80% or more of the time to their dominant language, and as bilingual otherwise. `r Words::English(n_participants_lp$n[1])` of the participants were categorised as monolinguals (`r n_participants_lp_sex[1]` female, `r n_participants_lp_sex[2]` male) and `n_participants_lp$n[2]` as Catalan/Spanish bilinguals (`r n_participants_lp_sex[3]` female, `r n_participants_lp_sex[4]` male) (see @tbl-participants for a detailed summary of participants' age and language profile). Participants' vision was normal, none used glasses or any other type of vision corrector.

```{r tbl-participants}
#| label: tbl-participants
#| tbl-cap: "Demographic and linguistic profile of testing sessions."
participants_bcn |> 
	unnest_wider(doe) |> 
	select(-matches("others")) |> 
	arrange(lp, test_language) |> 
	summarise(n = n(),
			  n_participants = n_distinct(child_id),
			  across(age, lst(mean, sd, min, max)),
			  across(matches("doe_"), lst(mean, sd)),
			  age_vctr = list(age),
			  .by = c(lp, test_language)) |> 
	gt(rowname_col = "test_language",
	   groupname_col = "lp") |> 
	gt_plt_dist(age_vctr, type = "histogram") |>
	fmt_number(is.numeric, decimals = 1) |> 
	fmt_integer(c(n, n_participants)) |> 
	fmt_number(matches("doe"), decimals = 1, scale_by = 100) |> 
	cols_merge_range(age_min, age_max) |> 
	cols_merge_uncert(age_mean, age_sd) |> 
	cols_merge_uncert(doe_catalan_mean, doe_catalan_sd) |> 
	cols_merge_uncert(doe_english_mean, doe_english_sd) |> 
	cols_merge_uncert(doe_spanish_mean, doe_spanish_sd) |> 
	tab_spanner("Age (months)", matches("age")) |> 
	tab_spanner("Catalan", matches("catalan")) |> 
	tab_spanner("English", matches("english")) |> 
	tab_spanner("Spanish", matches("spanish")) |> 
	tab_spanner("Degree of Exposure (%)", matches("doe")) |> 
	cols_label(n = "N sessions",
			   n_participants = "N participants",
			   age_mean = "M (SD)",
			   age_min = "Range",
			   age_vctr = "Distribution",
			   doe_catalan_mean = "M (SD)",
			   doe_english_mean = "M (SD)",
			   doe_spanish_mean = "M (SD)") |> 
	tab_style(cell_text(style = "italic"),
			  cells_column_labels()) |> 
	tab_style(cell_text(weight = "bold"),
			  cells_column_spanners())
```

### Vocabulary size

```{r vocab-values}
vocabulary_bcn <- inner_join(vocabulary, 
							 select(participants_bcn, session_id),
							 by = join_by(session_id))

n_imputed <- table(vocabulary_bcn$is_imputed)[2]
prop_imputed <- scales::percent(n_imputed/nrow(vocabulary_bcn))
n_pool <- nrow(bvq_data$vocabulary)
```

We collected vocabulary data using parental responses to the Barcelona Vocabulary Inventory [BVQ, @garcia-castro2023bvq], an online vocabulary checklist inspired in several adaptations of the the Communicative Developmental Inventory [CDI, @fenson1994variability] developed to assess the vocabulary size of Catalan-Spanish bilingual toddlers. Families received a link to the BVQ immediately after each experimental session, and were given two weeks to fill it. We calculated two measures of receptive vocabulary size for each participant: *L1 vocabulary size* (proportion of words  reported as acquired in the checklist of the dominant language), and *total vocabulary size* (proportion of the words in both checklists reported as acquired) (see @fig-vocabulary).

`r n_imputed` (`r prop_imputed`) Families failed to provide a complete response to the BVQ within the two-week time limit, or did not provide a successful response to the questionnaire. For missing questionnaire responses, we imputed the vocabulary size of the participant using single imputation, using the vocabulary size scores of a pool of `r n_pool` additional participants for which a successful response for the questionnaire had been gathered. We used participants age in months and their language profile (monolingual/bilingual) as predictors. We used the `mice` R package [@van2011mice] to perform imputation using the Bayesian linear regression method. 

```{r fig-vocabulary}
#| label: fig-vocabulary
#| fig-cap: "Participant vocabulary sizes across ages and language profiles. Vocabulary size scores are presented using two measures: L1 vocabulary size (proportion of words marked as *Understands* in the vocabulary checklist of the dominant language), and total vocabulary size (proportion of words marked as *Understands* in vocabulary checklists of both dominant and non-dominant languages). Vocabulary size scores from the recurrent participants are shown linked."
#| eval: false
#| fig-width: 8
#| fig-height: 4.5
vocabulary_bcn |> 
	inner_join(select(participants, child_id, session_id, age, lp),
			   by = join_by(child_id, session_id)) |> 
	pivot_longer(c(total_prop, l1_prop),
				 names_to = "measure",
				 values_to = "prop",
				 names_transform = \(x) gsub("_prop", "", x)) |> 
	mutate(measure = if_else(measure=="l1", 
							 "L1 vocabulary", 
							 "Total vocabulary"),
		   is_imputed = if_else(is_imputed, "Imputed", "Observed") |> 
		   	factor(levels = c("Observed", "Imputed"))) |> 
	ggplot(aes(age, prop, colour = is_imputed)) +
	facet_grid(measure ~ lp) +
	geom_line(aes(group = child_id),
			  alpha = 1/2,
			  colour = "grey") +
	geom_point() +
	labs(x = "Age (months)",
		 y = "Vocabulary size (%)") +
	theme(panel.grid.major = element_line(linetype = "dotted",
										  colour = "grey"),
		  legend.position = "top",
		  legend.title = element_blank())

```


### Stimuli

```{r stimuli-values}
n_words <- length(unique(with(stimuli, unlist(prime, target, distractor))))
```

We used `r n_words` distinct words included in the BVQ to create the stimuli lists. We created six stimuli lists: three in Catalan, and three in Spanish. Each list contained 32 trials, each involving a prime-target-distractor group. Each word played a role as either prime, *or* as target and distractor across the three lists in their corresponding language. For instance, the Catalan word *cadira* appeared as *prime* in the three lists, but never as *target* or *distractor*; the Catalan word *bici* appeared as *target* and *distractor* across the three lists, but never as a prime. Target-distractor pairings were held constant across the three lists in each language. For instance, in all Catalan lists the word *bici* was paired with the word *porta*. Target-distractor pairings were also yoked, so that each member of the same target-distractor pair appeared once as target and once as distractor in each list. For instance, the *bici*-*porta* paired appeared twice in each of the three Catalan lists: once with *bici* as target and *porta* as distractor, and once with *porta* as target and *bici* as distractor. This counterbalancing avoided participants encountering looking at the target word guided solely by that word having being named in a previous trial. Finally, prime words appeared only once in each list: each target-distractor pair was associated with a different prime word in both appearances. In each list, the same prime word was presented alongside a different target-distractor pair. For instance, the Catalan prime word *barret* was presented with the *bici*-*porta* target-distractor pair in one list, with the *bici*-*porta* pair in another list, and with *berenar*-*amanida* in the remaining list. The order of the trials was randomised across experimental session, so that each time a participant was tested, the order in which the prime-target-distractor was presented was randomised. Each participant was randomly assigned to one of the three lists in the corresponding language (their dominant language, see @sec-lp), and always the same list across their experimental sessions in the case of a recurrent participant.

In 16 of the 32 trials of the same list (henceforth *related* trials), the prime and the target words were phonologically related, sharing phonological onset (at least first phoneme). In the other 16 trials (*unrelated* trials), prime and target did not share phonological onset. 8 of the 16 *related* trials included a cognate prime (*cognate* trials), and the other 8 included a non-cognate trials (*non-cognate* trials). A prime word was considered cognate if its Catalan and Spanish translation shared phonological onset. Especial attention was paid to avoiding semantic or taxonomic relationships between prime and target words, and between prime and distractor words. Target and distractor word pairs were phonologically unrelated (did not share phonological onset). Some of them shared semantic features or a taxonomic relationship. This is the case of words associated with especially salient referents such as animals or food. To avoid infants guiding their gaze to these objects based on their saliency, we paired animals and food items together. The position of the target and distractor pictures (right or left) for each target-distractor pair was alternated, so that in one list the target would appear on the left, in another list it would appear on the right, and so on.

We examined the overall equivalence of the three trial types by comparing them across three variables relating to the target word: lexical frequency, word prevalence, animacy
@tbl-stimuli shows a detailed summary of the stimuli properties, broken down by trial type and testing language. Lexical frequencies were extracted from the Catalan and Spanish corpora of the CHILDES database [@reference; @reference] as counts per million words, and transformed into Zipf scores for easier cross-language comparison [@reference; @reference]. We defined word prevalence as the proportion of same-aged infants who were reported to understand the word in the BVQ database.


#### Auditory stimuli

The auditory stimuli were natural exemplars of the selected target words, spoken by Central Catalan-Spanish proficient bilingual female speaker who was instructed to pronounce each word in a toddler-directed manner. Recordings were made with an Audio-Tecnica 328 microphone (AT2050) at a sampling rate of 44100 Hz, in a soundproof room at the *Laboratori de Recerca en Infancia* at University Pompeu Fabra. We used the Audacity and Praat [@boersma2001speak] software packages to record and edit the audio files. The speaker was presented with a list of words in Catalan. The order of the words was pseudo-randomised, and each word was produced three times in a row before moving to the next word in the list. After going through all the words in the list, the speaker went through the word list again generating three tokens for each word, now in an inverse order (from bottom of the list to the top). We then repeated the same procedure for the list of Spanish words. The resulting audios were manually chunked into individual word-forms. For each of the six tokens produced for each word, the most adequate was selected for further processing. The audios were then transformed to stereo by duplicating them into two channels, denoised, and finally normalised. The mean duration of the final audios was `r round(mean(stimuli$duration[stimuli$test_language=="Catalan"]), 2)` (*SD* = `r round(sd(stimuli$duration[stimuli$test_language=="Catalan"]), 2)`) and `r round(mean(stimuli$duration[stimuli$test_language=="Spanish"]), 2)` (*SD* = `r round(sd(stimuli$duration[stimuli$test_language=="Spanish"]), 2)`) seconds for the Catalan and Spanish lists.

To make the pronunciation of the words as familiar as possible to each infant, we generated additional pronunciation variants for some words in Catalan and Spanish. Catalan words involving the /\textipa{L}/ phoneme in their Central Catalan variant (e.g., /\textipa{'Lu.n@}) were also recorded with such phoneme replaced by /j/ (e.g., /\textipa{'ju.n@}), a phonological process common in the Metropolitan Area of Barcelona [@reference]. Spanish words involving the /\textipa{T}/ phoneme were also generated replacing such phoneme with /\textipa{s}/ to better accommodate Latin variants of Spanish. Before every experimental session, caregivers were asked to utter three written words involving the /\textipa{L}/ phoneme (in the case of participants tested in Catalan) or the /\textipa{T}/ phoneme (in the case of participants tested in Spanish). Each token contained the critical phoneme at onset, inter-vocalic position, and coda. The experimenter assigned the participant to the Catalan or Spanish stimuli list involving the closest variant to that of caregivers'.


#### Visual stimuli

For each word, we created a picture with a typical referent. To avoid competition between target and distractor pictures, semantically related target-distractor pairs were perceptually distinct [@floccia2020translation; @arias-trejo2010].

```{r tbl-stimuli}
#| label: tbl-stimuli
#| tbl-cap: "Summary of stimuli properties by trial type."
stimuli |> 
	summarise(across(c(matches("familiarity_|freq_|animate_"), duration),
					 tibble::lst(mean, sd, min, max)),
			  .by = c(test_language, trial_type)) |> 
	select(-matches("familiarity_se"), -matches("prime"),
		   -c(is_animate_target_sd,
		      is_animate_target_min,
		      is_animate_target_max),
		   -matches("min"), -matches("max")) |> 
	gt(groupname_col = "test_language",
	   rowname_col = "list") |> 
	fmt_number(is.numeric,
			   decimals = 1) |> 
	fmt_number(matches("familiarity|animate"),
			   scale_by = 100,
			   decimals = 1) |> 
	cols_merge(c(freq_target_mean, freq_target_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(familiarity_target_mean, familiarity_target_sd),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(duration_mean, duration_sd),
			   pattern = "{1} ({2})") |> 
	cols_label(trial_type = "",
			   familiarity_target_mean = "Prevalence (%)",
			   freq_target_mean = "Frequency",
			   is_animate_target_mean = "Animacy (%)",
			   duration_mean = "Duration (s)") 
```


### Procedure

Testing took place in a sound-proof room. Participants sat on their caregivers' lap in a dimly lit testing booth while the experimenter conducted the experiment from outside. Caregivers were instructed to keep their eyes shut (to avoid recording their gaze, instead of the participant's), to be still, and to avoid interacting with the participant verbally or non-verbally. Participants sat at approximately 65 cm from the eye-tracker and a XX-in screen of $1929\times1080$ screen resolution. We used a custom Matlab XXXX script using the PsychToolbox-3 extension [@kleiner2007s; @brainard1997psychophysics; @pelli1997videotoolbox] to present the stimuli, and the Tobii Analytics SDK 3.0 to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 5-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented. We set a 55% grey background for the calibration and stimuli presentation. Auditory stimuli were presented through two loudspeakers located behind the screen, one to each side. The experimenter monitored the experimental from outside the room using a centrally located video camera place above the screen. After a successful calibration the experimenter triggered the onset of the first trial. Trials were presented uninterruptedly and  without intervention of the experimenter until the 32 trials were presented, or the experimental session had to be stopped because of the participant's behaviour.

![Experimental task design with examples in Catalan. In each trial, the prime image is presented in silence for 3,000 ms. The the auditory target label is presented, and finally the target and distractor pictures are presented side-by-side for 2,000 ms. In cognate trials (*n* = 8), Catalan *and* Spanish prime labels shared phonological onset with the target label. In non-cognate trials (*n* = 8), only the Catalan prime label shared phonological onset with the target label. In unrelated trials (*n* = 32), none of the prime labels shared phonological onset with the target label.](_assets/img/design.png){fig-align="center"}

Each trial started with the presentation of an attention getter for 3,000 milliseconds. Then, the prime picture was presented in silence in the centre of the screen for 1,500 milliseconds. Fifty milliseconds after the offset of the prime image, an auditory label was played from the loudspeakers and, 700 milliseconds after the onset of the auditory label, the target and distractor pictures were presented side-by-side during 1,000 milliseconds until the end of the trial. After this, the attention getter of the next trial was immediately presented. Each experimental session took approximately 10 minutes.

### Apparatus

see https://link.springer.com/article/10.3758/s13428-021-01762-8

### Data processing

```{r dataset}
n_trials <- nrow(attrition)
n_sessions <- n_distinct(attrition$session_id)
n_participants <- n_distinct(attrition$child_id)
n_trials_valid <- nrow(filter(attrition,
							  is_valid_participant,
							  is_valid_trial))
n_sessions_valid <- sum(attrition_participants$is_valid_participant)
n_participants_valid <- n_distinct(
	attrition[attrition$is_valid_participant, ]$child_id)

n_exc_prime <- sum(!attrition$is_valid_gaze_prime)
n_exc_test <- sum(!attrition$is_valid_gaze_test)
n_exc_test_any <- sum(!attrition$is_valid_gaze_test_any)
n_exc_participants <- sum(!attrition_participants$is_valid_participant) 

n_longitudinal <- attrition |>
	filter(is_valid_participant,
		   is_valid_trial) |>
	distinct(child_id, session_n) |> 
	count(child_id, name = "times") |> 
	count(times)
```

We defined a time windows of interest from 200 ms after target and distractor pictures onset until the end of the trial at 2,000 ms when  both pictures disappeared from screen. To avoid modelling fixations driven by processes other than auditory word recognition [@fernald1998rapid; @fernald2001half]. Missing eye-tracker samples were interpolated using the last-observation-carried-forward [see @zettersten2022peekbank for a similar approach], with a maximum of 20 maximum consecutive missing samples being interpolated (an equivalent of 166.67 ms).

We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_sessions` testing sessions, generated from `r n_participants` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples (equivalent to 750 ms) during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or 50% valid samples (equivalent to 1,000 ms) during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). We also excluded trials in which participants did not provide at least 5% of valid samples (equivalent to 100 ms) of target or distractor looking in the test phase (*n* = `r format(n_exc_test_any, big.mark = ",")`) [see @floccia2020translation for a similar approach].

After trials that matched any of the aforementioned exclusion criteria from the dataset, we excluded participants who did not provide at least two valid trials in the *Cognate* condition, the *Non-cognate* condition, or the  *Unrelated* condition (*n* = `r n_exc_participants`). The final dataset included `r format(n_trials_valid, big.mark = ",")` trials from `r n_sessions_valid` testing sessions, generated by `r format(n_participants_valid, big.mark = ",")` distinct participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. @tbl-attrition-trials shows a detailed description of the trial attrition.


```{r tbl-attrition}
#| label: tbl-attrition
#| tbl-cap: "Participant-level and trial-level sample size after applying inclusion criteria. The number of excluded participants and trials is indicated between parentheses."
expanded <- expand(attrition, lp, trial_type, is_valid_trial)

n_lp <- attrition |> 
	distinct(is_valid_participant, lp, session_id) |> 
	count(is_valid_participant, lp) |> 
	pivot_wider(names_from = is_valid_participant,
				values_from = n,
				names_repair = janitor::make_clean_names) |> 
	mutate(n_participants_true = true,
		   n_participants_false = false) |> 
	select(lp, true, false)

attrition |> 
	summarise(n_trials_true = sum(is_valid_trial),
			  n_trials_false = sum(!is_valid_trial),
			  .by = c(lp, trial_type)) |> 
	arrange(desc(lp)) |> 
	# across(n_trials, lst(mean, sd, sum), na.rm = TRUE),
	
	pivot_wider(id_cols = lp,
				names_from = c(trial_type),
				values_from = matches("trials"),
				names_repair = janitor::make_clean_names) |> 
	left_join(n_lp, by = join_by(lp)) |> 
	mutate(lp = case_when(
		lp=="Monolingual" ~ "Monolingual (Catalan or Spanish)",
		lp=="Bilingual" ~ "Bilingual (Catalan-Spanish)",
		.default = lp)) |>
	select(lp, true, false,
		   matches("n_trials")) |> 
	gt(rowname_col = "lp") |> 
	tab_spanner("Participants", matches("participant")) |> 
	tab_spanner("Trials", matches("trial")) |> 
	fmt_integer(everything()) |> 
	cols_merge(c(true, false),
			   pattern = "{1} ({2})") |> 
	cols_merge(c(n_trials_true_cognate,
				 n_trials_false_cognate),
				 pattern = "{1} ({2})") |> 
	cols_merge(c(n_trials_true_non_cognate,
				 n_trials_false_non_cognate),
				 pattern = "{1} ({2})") |> 
	cols_merge(c(n_trials_true_unrelated, 
				 n_trials_false_unrelated),
				 pattern = "{1} ({2})") |> 
	cols_label(true = "N", 
			   n_trials_true_cognate = "Cognate",
			   n_trials_true_non_cognate = "Non-cognate",
			   n_trials_true_unrelated = "Unrelated") |> 
	tab_style(cell_text(style = "italic"),
			  cells_column_labels()) |>
	grand_summary_rows(fns = list(label = md("*N*")) ~ sum(.),
					   fmt = ~ fmt_integer(.))
```



### Data analysis

We used multilevel General Additive Models (GAMs) to model our data and test our hypotheses [@pedersen2019hierarchical]. First, we defined our response variable as the empirical logit of target looking using @eq-elogit across all eye-tracking samples for each each participant in each condition [@barr2008analyzing; @agresti2012categorical]. We used a Gaussian distribution to model our response variable. To test our hypotheses, we then included *Condition*, *Group*, and either *Age* ($\mathcal{M}_0$), *L1 vocabulary* ($\mathcal{M}_1$), or *Total vocabulary* ($\mathcal{M}_2$) as fixed effects in the model. We also added all two-way and three-way interactions between the predictors. We set two *a priori* contrasts for the *Condition* predictor: one comparing *Unrelated* and *Related/Non-cognate* trials (sum-coded as `-0.5` and `+0.5`, with *Related/Cognate* trials coded as `0`), and another comparing *Related/Non-cognate* and *Related/Cognate* trials (sum-coded as `-0.5` and `+0.5`, with *Unrelated* trials coded as `0`). We also set two *a priori* contrasts for the *Group* predictor: one comparing *Monolingual (ENG)* with *Monolingual (CAT/SPA)* participants (sum-coded as `-0.5` and `+0.5`, with *Bilingual (CAT-SPA)* participants coded as `0`), and another comparing *Monolingual (ENG)* with *Bilingual (CAT-SPA)* participants (sum-coded as `-0.5` and `+0.5`, with *Monolingual (CAT/SPA)* participants coded as `0`). Before entering the model, the numeric predictors *Age*, *L1 vocabulary*, and *Total vocabulary* were standardised by subtracting from each observation the mean of the predictor, and dividing the result from the standard deviation of the predictor.

$$
\eta' = \ln\bigg(\frac{\text{Target} + 0.5}{ \text{Distractor} + 0.5}\bigg)
$$ {#eq-elogit}

We added *Session* as grouping variable, by by-session intercept and *Condition* slopes. Each level in the *Session* variable uniquely indexes all observations generated by a participant in a single testing session. Testing sessions from the same participant are identified by different indexes. For computational limitations, adding both participants and testing sessions as grouping variable in the random effects structure of the model was not possible. We instead included testing sessions alone, as observations from the same testing session are more likely to be highly correlated than those from the same participant in different testing sessions (which were recorded at least four months apart). To model the time course of target looking across time bins, we included cubic regression splines for the main effect of *Time*, and one for an adjustment of the *Time* cubic spline by *Group* and *Relatedness* [@wood2017generalized]. For both splines, we specified $k = 9$ basis functions or *knots*--half the number of time bins---for computational convenience. @eq-model shows a formal implementation of the model.

$$
\begin{aligned}
\textbf{Likelihood:} \\
y_i &\sim \mathcal{N}(\mu_i, \sigma_i) \\ \\
\textbf{Linear model:} \\
\eta'(\mu_i) &= (\beta_0 + u _{0_{i}}) +
(\beta_1 + u _{1_{i}}) \cdot \text{Condition} +\\
&\beta_{2} \cdot \text{Group} +
\beta_{3} \cdot X + \beta_{4} \cdot (\text{Condition} \times \text{Group}) +\\
&\beta_{5} \cdot (\text{Condition} \times X) + \beta_{6} \cdot (\text{Group} \times X) +\\
&\beta_{7} \cdot (\text{Condition} \times \text{Group} \times X) +\\
& \sum_{j = 1}^k b_{j_{0}} \cdot \beta_{8_{k}} \cdot \text{Time} +
\sum_{j = 1}^k b_{j_{1}} \cdot\beta_{9_{k}} \cdot (\text{Time} \times \text{Group}) \\
\text{where:} \\
&\eta'\text{ is the empirical logit of target fixations} \\
&X \in \{\text{Age}, \text{L1 vocabulary}, \text{Total vocabulary}\} \\
&k \text{ is the number of knots in the spline (10)} \\
\textbf{Prior:} \\
\beta_{0-9} &\sim \mathcal{N}(0, 0.5) \\
u_{0-2} &\sim \mathcal{N}(0, \sigma_{0-2})\\
b_{0-1} &\sim \text{MVN}(0, \tau_{0-1}) \\
\sigma_{0-2}, \tau_{0-1} &\sim \text{Exponential}(6)\\
\rho_{0-2} &\sim LKJCorr(6)\\
\text{where:}\\
&\rho_{0-2} \text{ are the correlation parameters for } \sigma_{0-2}
\end{aligned}
$$ {#eq-model}

The comparison between the three models including *Age*, *L1 vocabulary*, *Total vocabulary* as predictors was performed using leave-one-out cross-validation (LOO-CV) as a benchmark of model performance, using Pareto-smoothed importance sampling (PSIS) to approximate it [@vehtari2017practical]. We implemented the model using `brms` [@burkner2017brms], an R interface to the Stan probabilistic language (`r stan_version`) [@carpenter2017stan]. We ran `r english::words(dim(model_fit$fit_0)[2])` iteration chains using the by-default No U-Turn Sampler algorithm with `r format(niterations(model_fit$fit_0), big.mark = ",")` iterations each and an additional `r format(niterations(model_fits$fit_0), big.mark = ",")` warm-up iterations per chain.


## Results

```{r fig-ptlt-recognition}
#| label: fig-ptlt-recognition-aggr
#| fig-cap: "Average probability of target looking across the time course of the trial. Points an whiskers indicate the mean and standard error of the mean."
#| fig-width: 11
#| fig-height: 4
data_time_bcn |> 
	drop_na(.prop) |> 
	summarise(.prop = mean(.prop),
			  .by = c(lp, timebin, session_id)) |> 
	ggplot(aes(timebin, .prop)) +
	facet_wrap(~lp, nrow = 1, scales = "free_x") +
	geom_line(aes(group = session_id),
			  colour = "grey",
			  alpha = 1/10) +
	geom_hline(yintercept = 0.5, linetype = "dashed") +
	stat_summary(fun.data = "mean_se",
				 geom = "errorbar",
				 width = 0.35,
				 linewidth = 2/4) +
	stat_summary(fun = "mean",
				 geom = "point",
				 size = 1.2) +
	stat_summary(fun = "mean",
				 geom = "line",
				 linewidth = 2/4) +
	labs(x = "Time (ms)",
		 y = "PTLT") +
	scale_x_continuous(breaks = seq(0, 20, 2),
					   labels = \(x) format(x*100+300, big.mark = ",")) +
	scale_y_continuous(labels = scales::percent,
					   breaks = seq(0, 1, 0.2),
					   limits = c(0, 1)) +
	theme(panel.grid.major.y = element_line(colour = "grey",
											linetype = "dotted"),
		  legend.position = "none")
```


```{r tbl-coefs}
post <- gather_draws(fit_1, `b_.*`, regex = TRUE)  

ggplot(post, aes(.value)) +
	facet_wrap(~.variable, scales = "free") +
	geom_histogram(bins = 15, colour = "white",
				   position = position_nudge(y = 0.1),
				   fill = "grey80") +
	geom_errorbar(data = mean_qi(post),
				  aes(xmin = .lower, xmax = .upper, y = 0),
				  width = 1,
				  linewidth = 3/4) +
	geom_point(data = mean_qi(post),
			   aes(x = .value, y = 0),
			   size = 2) +
	scale_y_continuous(limits = c(0, 500))
```

### Hypothesis 1: within-language phonological priming

```{r fig-ptlt-recognition-condition}
#| label: fig-ptlt-recognition-condition
#| fig-cap: "Average probability of target looking across the time course of the trial. Points an whiskers indicate the mean and standard error of the mean."
#| fig-width: 11
#| fig-height: 4
data_time_bcn |> 
	summarise(.prop = mean(.prop),
			  .by = c(lp, timebin, condition, session_id)) |> 
	ggplot(aes(timebin, .prop, colour = condition)) +
	facet_grid(~lp) +
	# geom_rug(aes(x = timebin[is.na(.prop)])) +
	# geom_line(aes(group = interaction(condition, session_id)),
	# 		  alpha = 1/8) +
	geom_hline(yintercept = 0.5, linetype = "dashed") +
	stat_summary(fun.data = "mean_se",
				 geom = "errorbar",
				 width = 0.35,
				 linewidth = 2/4) +
	stat_summary(fun = "mean",
				 geom = "point",
				 size = 1.2) +
	stat_summary(fun = "mean",
				 geom = "line",
				 linewidth = 2/4) +
	labs(x = "Time (ms)",
		 y = "PTLT",
		 colour = "Condition") +
	scale_x_continuous(breaks = seq(0, 20, 4),
					   labels = \(x) format(x*100+200, big.mark = ",")) +
	scale_y_continuous(labels = scales::percent,
					   breaks = seq(0, 1, 0.05)) +
	theme(legend.position = "top",
		  panel.grid.major.y = element_line(colour = "grey",
		  								  linetype = "dotted"))
```

### Hypothesis 2: cross-language phonological priming


```{r fig-time}
#| label: fig-time
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 1. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
make_std <- function(x, mean, sd) (x - mean) / sd

timebin_values <- make_std(seq(0, 17, length.out = 100),
						   mean(data_time$timebin),
						   sd(data_time_bcn$timebin))

age_values <- make_std(c(21, 25, 30),
					   mean(data_time_bcn$age),
					   sd(data_time_bcn$age))

nd <- expand_grid(condition = levels(fit_3$data$condition),
				  timebin_std = timebin_values,
				  age_std = age_values,
				  # sesion_id = first(data$session_id),
				  # age = c(21, 25, 30),
				  lp = levels(fit_3$data$lp)) 

epreds <- add_epred_draws(newdata = nd,
						  object = fit_3,
						  ndraws = NULL,
						  re_formula = NA,
						  value = ".value") |> 
	mutate(.value = plogis(.value)) |> 
	mean_qi() |> 
	mutate(lp = factor(lp, 
					   levels = c("Monolingual (English)",
					   		   "Monolingual",
					   		   "Bilingual")),
		   age_std = factor(age_std, 
		   				 levels = age_values,
		   				 labels = paste0(c(21, 25, 30), " months")))

epreds |> 
	ggplot(aes(timebin_std, .value,
			   colour = condition,
			   fill = condition)) +
	facet_grid(lp~age_std) +
	geom_hline(yintercept = 0.5,
			   linetype = "dashed") +
	geom_ribbon(aes(ymin = .lower, ymax = .upper),
				alpha = 0.5,
				linewidth = 0) +
	geom_line(linewidth = 3/4) +
	# stat_summary(data = data_time_bcn,
	# 			 aes(y = .elog),
	# 			 fun = mean,
	# 			 geom = "point",
	# 			 size = 2) +
	labs(x = "Time (ms)",
		 y = "Logit (Target looking)",
		 colour = "Condition",
		 fill = "Condition") +
	scale_x_continuous(breaks = make_std(seq(0, 17, 2),
										 mean(data_time$timebin),
										 sd(data_time$timebin)),
					   labels = \(x) format(seq(0, 17, 2)*100+200, big.mark = ",")) +
	theme(legend.position = "top",
		  panel.grid.major.y = element_line(colour = "grey",
		  								linetype = "dotted"))

ggsave(file.path("img", "model-time.jpeg"),
	   height = 4, width = 10,
	   dpi = 800)
```


### Hypothesis 3: emergence of phonological association

### Hypothesis 4: the compating role of age and vocabulary

In a first analysis, we examined the effect of phonological priming. We compared participants' looking preference for the target in related and unrelated trials. We first compared the aggregated probability of target looking across time bins in both conditions for each language group.  


```{r fig-time-total}
#| label: fig-time-total
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "Marginal posterior predictions of the GAMMs in Analysis 1. (A) Mean posterior probability of target looking across the time course of the trial. Black lines and intervals indicate the psoterior mean and 95% credible intervals. Points indicate the mean probability of target looking across participants. (B) Difference in posterior probability of target looking between *related* and *unrelated* trials. The yellow rectangle indicates, in both A and B, the range of time points in which the 95% credible interval of the differences excluded zero."
voc_values <- seq(0.25, 1, 0.25)

nd <- expand_grid(condition = levels(model_fits_time$fit_time_2$data$condition),
				  timebin = seq(0, 17, length.out = 100),
				  voc_total = voc_values,
				  # sesion_id = first(data$session_id),
				  # age = c(21, 25, 30),
				  lp = levels(model_fits_time$fit_time_2$data$lp)) 

epreds <- add_epred_draws(newdata = nd,
						  object = model_fits_time$fit_time_2,
						  ndraws = 20,
						  re_formula = NA,
						  value = ".value") |> 
	mean_qi() |> 
	mutate(lp = factor(lp, 
					   levels = c("Monolingual (English)",
					   		   "Monolingual",
					   		   "Bilingual")),
		   voc_total = factor(x = voc_total, 
		   				   levels = voc_values,
		   				   labels = scales::percent(voc_values)))

epreds |> 
	ggplot(aes(timebin, .value,
			   colour = condition,
			   fill = condition)) +
	facet_grid(lp~voc_total) +
	geom_hline(yintercept = 0,
			   linetype = "dashed") +
	geom_ribbon(aes(ymin = .lower, ymax = .upper),
				alpha = 0.5,
				linewidth = 0) +
	geom_line(linewidth = 3/4) +
	labs(x = "Time (ms)",
		 y = "Logit (Target looking)",
		 colour = "Condition",
		 fill = "Condition") +
	scale_x_continuous(breaks = seq(0, 20, 4),
					   labels = \(x) format(x*100+200, big.mark = ",")) +
	theme(legend.position = "top",
		  panel.grid.major = element_line(colour = "grey",
		  								linetype = "dotted"))

ggsave(file.path("img", "model-time-voc-total.jpeg"),
	   height = 5.5, width = 10,
	   dpi = 800)
```


{{< pagebreak >}}



## Discussion

# Study 2

## Methods

### Participants

```{r}
#| label: participants-numbers-oxf
participants_oxf <- filter(participants, location=="Oxford")

n_participants_total <- nrow(distinct(participants_oxf, child_id))
n_sessions_total <- count(participants_oxf)

n_participants_sex <- participants_oxf |> 
	distinct(sex, child_id) |> 
	count(sex)

n_participants_sessions <- participants_oxf |> 
	count(child_id, name = "n_sessions") |> 
	count(n_sessions) |> 
	group_split(n_sessions) |> 
	set_names(paste0("session_", 1:2)) |> 
	map("n")

ages <- participants_oxf |> 
	summarise(n = n(),
			  n_participants = n_distinct(child_id),
			  across(age, lst(mean, sd, min, max)),
			  across(matches("doe_"), lst(mean, sd)),
			  age_vctr = list(age),
			  .by = c(lp, test_language))

```

We collected data from `r n_participants_total$n[1]` children (`r n_participants_sex[1]` female, `r n_participants_sex[2]` male, `r n_participants_sex[3]` sex not reported, age: *Mean* = `r round(ages$age_mean, 2)` months, *SD* = `r round(ages$age_sd, 2)`, *Range* = [`r round(ages$age_min, 2)`-`r round(ages$age_max, 2)`]), living in the Oxfordshire area (United Kingdom), tested at the Oxford BabyLab at the University of Oxford. Families were recruited from maternity rooms in private hospitals and social media, and contacted via phone when the child's age spanned between 20 and 32 months. From the `r n_participants_total$n` children that participated, `r n_participants_sessions$session_1` participated once, and `r n_participants_sessions$session_2` participated twice. Recurrent participants were tested with at least XXX months of difference. We gathered a total of `r n_sessions_total$n` testing sessions. All participants were being raised in exclusively British English monolingual homes.

### Vocabulary size

```{r vocab-values}
vocabulary_oxf <- inner_join(vocabulary, 
							 select(participants_oxf, session_id),
							 by = join_by(session_id))
```

We collected vocabulary data using parental responses to the Oxford Communicative Development Inventory (OCDI) [@hamilton2000infant]. Families were sent the questionnaire immediately after each experimental session, and were given two weeks to fill it. Since all vocabulary sizes of English monolingual infants were only assessed in English, both *L1 vocabulary* and *total vocabulary* sizes were identical (see @fig-vocabulary-oxf).

```{r fig-vocabulary-oxf}
#| label: fig-vocabulary
#| fig-cap: "Participant vocabulary sizes across ages and language profiles. Vocabulary size scores are presented using two measures: L1 vocabulary size (proportion of words marked as *Understands* in the vocabulary checklist of the dominant language), and total vocabulary size (proportion of words marked as *Understands* in vocabulary checklists of both dominant and non-dominant languages). Vocabulary size scores from the recurrent participants are shown linked."
#| eval: false
#| fig-width: 4
#| fig-height: 4
vocabulary_oxf |> 
	inner_join(select(participants, child_id, session_id, age, lp),
			   by = join_by(child_id, session_id)) |> 
	ggplot(aes(age, total_prop)) +
	geom_line(aes(group = child_id),
			  alpha = 1/2,
			  colour = "grey") +
	geom_point(colour = clrs[1]) +
	labs(x = "Age (months)",
		 y = "Vocabulary size (%)") +
	theme(panel.grid.major = element_line(linetype = "dotted",
										  colour = "grey"),
		  legend.position = "top",
		  legend.title = element_blank())
```


### Stimuli

New stimuli lists were generated to adapt the experimental procedure to English-learning infants. Stimuli lists were created following the same constraints as in Study 1. Auditory stimuli were recorded following the same procedure as in Study 1, produced by Southern British English native female speaker in a toddler-directed manner. Audio and picture processing were performed following the same workflow as in Study 1.

### Procedure and apparatus

Same as in Study 1. The study was run using a custom Matlab script, PresentMate, based on the PsychToolbox-3 extension [@kleiner2007s; @brainard1997psychophysics; @pelli1997videotoolbox]. Visual fixations were recorded using a Tobii TX 300 eye-tracker and a 23-in screen of 1920 $\times$ 1080 resolution. The Tobii Analytics SDK 3.0 was used to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 9-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented. 

### Data processing

Same as in Study 1.

### Data analysis

## Results

# General discussion

IMPLICIT NAMING
Even earlier evidence of implicit naming was provided through ERP registering at 14 months of age. @duta2012erp presented name-known pictures in silence for one second. After one second, the picture's label was presented auditorily, and the infants' N400 component was registered. In some trials the auditory label corresponded to a canonical realisation of the word-form. In other trials, the word was mispronounced. Infants ERP signal differed when presented with correct pronunciations or mispronunciations, indicating that infants had generated expectations at the phonological level about the auditory labels of the picture before they were presented with its auditory label. A later study by @styles2015infant re-analysed the first 1,000 ms of the trials in the previous study (while the picture was being presented before the auditory label was presented), and found that the ERPs of name-known pictures (according to parental reports of receptive vocabulary) differed from those of name-unknown pictures (which infants would not be able to lexicalise). This provides further support to the account that at around 14 months of age, infants already name familiar pictures, even if presented in silence.


THE ROLE OF COGNATENESS IN WORD ACQUISITION

For instance, previous work on lexical acquisition has provided some insight into how  found that English-Spanish bilinguals' vocabulary in English was influenced by the words they had already acquired in Spanish. This is consistent with previous accounts of lexical acquisition in which infants acquire new words through preferential acquisition [@hill2013, @fourtassi2020]. 

A monograph by @floccia2018introduction provided evidence of a language distance effect, where bilinguals learning two languages sharing higher lexical similarity knew more words in their less dominant language than those learning two language with lower lexical similarity. Later work by @mitchell2022cognate and @garcia-castro@cognate provided evidence for a more direct facilitation effect of cognateness. Cognates are form-similar translation equivalents. Cognateness is suggested to facilitate word acquisition through parallel activation: the co-activation of translation equivalents in speech might lead to an faster accumulation of learning instances with words, which ultimately results in an earlier age of acquisition.


Some recent studies have investigated the recognition of mispronounced words comparing monolingual and bilingual toddlers. Overall, these studies do not find differences between monolinguals and bilinguals [@von2019impact; @wewalaarachchi2017vowels]. Evidence for differential processing of cognate and non-cognate words is provided by Ramon-Casas and colleagues who observed that Spanish-Catalan 24-month-olds were more prone to accept mispronunciations when the stimuli involved cognate words than when they involved non-cognate words [@ramon2009vowel; @ramon2010non].

## Summary

## Context

## Facilitation vs. inhibition

## Onsets vs. offsets

## Problems and generalisatility

## Future steps

## Conclusions

# References


{{< pagebreak >}}

# Appendix

## Appendix A: imputing voabulary size scores

```{r fig-vocabulary-imputation}
vocabulary_tmp <- vocabulary |> 
	left_join(select(participants, child_id, vocab_id, age),
			  by = join_by(child_id, vocab_id)) |> 
	relocate(child_id) |> 
	filter(is_imputed)

bvq_data$vocabulary |> 
	inner_join(distinct(bvq_data$logs, child_id, response_id, lp, age),
			   by = join_by(response_id)) |> 
	mutate(is_imputed = FALSE) |> 
	bind_rows(vocabulary_tmp) |> 
	pivot_longer(ends_with("_prop"),
				 names_to = "measure",
				 values_to = "prop") |> 
	drop_na(prop) |> 
	mutate(is_imputed = ifelse(is_imputed, "Imputed", "Observed"),
		   measure = factor(measure,
		   				 levels = c("total_prop",
		   				 		   "l1_prop",
		   				 		   "l2_prop",
		   				 		   "concept_prop",
		   				 		   "te_prop"),
		   				 labels = c("Total",
		   				 		   "L1",
		   				 		   "L2",
		   				 		   "Conceptual",
		   				 		   "TE"))) |> 
	ggplot(aes(age, prop, 
			   colour = is_imputed,
			   fill = is_imputed)) +
	facet_wrap(~measure) +
	geom_point(alpha = 1/4, size = 1) +
	geom_smooth(method = "glm", 
				formula = "y ~ x",
				method.args = list(family = "binomial"), 
				# se = FALSE,
				size = 1) +
	labs(x = "Age (months)",
		 y = "Vocabulary size",
		 fill = "Imputed",
		 colour = "Imputed") +
	theme(legend.position = c(1, 0),
		  legend.justification = c(1, 0),
		  legend.title = element_blank())

```

{{< pagebreak >}}


## Appendix B: distribution of prime and target looking times

```{r fig-dist-prime}
#| label: fig-dist-prime
#| fig-height: 4
#| fig-width: 8
looking_times |> 
	mutate(prime_time = cut(prime_time, 
							seq(0, 1.5, 0.1),
							labels = FALSE,
							include.lowest = TRUE)) |> 
	add_count(lp, age_group, name = "n_total") |> 
	count(lp, age_group, prime_time, n_total) |> 
	mutate(n = n / n_total) |> 
	ggplot(aes(prime_time, n)) +
	facet_grid(lp~age_group) +
	annotate(geom = "rect",
			 fill = "orange",
			 ymin = -Inf,
			 ymax = Inf,
			 xmin = 0,
			 xmax = 0.75*10,
			 alpha = 1/3,
			 colour = NA) +
	# annotate(label = "Excluded trials",
	# 		 geom = "text",
	# 		  x = (0.75/2)*10,
	# 		  y = 1)
	geom_col(fill = "black") +
	labs(x = "Prime looking time (s)",
		 y = "Proportion of trials") +
	scale_x_continuous(labels = \(x) x/10) +
	theme(panel.grid.major.y = element_line(linetype = "dotted",
											colour = "grey"))
```

```{r fig-dist-target}
#| label: fig-dist-target
#| fig-height: 4
#| fig-width: 8
looking_times |> 
	mutate(target_time = cut(target_time, 
							 seq(0, 2, 0.1),
							 labels = FALSE,
							 include.lowest = TRUE)) |> 
	add_count(lp, age_group, name = "n_total") |> 
	count(lp, age_group, target_time, n_total) |> 
	mutate(n = n / n_total) |> 
	ggplot(aes(target_time, n)) +
	facet_grid(lp~age_group) +
	# annotate(label = "Excluded trials",
	# 		 geom = "text",
	# 		  x = (0.75/2)*10,
	# 		  y = 1)
	geom_col(fill = "black") +
	labs(x = "Targets looking time (s)",
		 y = "Proportion of trials") +
	scale_x_continuous(labels = \(x) x/10) +
	theme(panel.grid.major.y = element_line(linetype = "dotted",
											colour = "grey"))
```

{{< pagebreak >}}

## Appendix C: prime and test looking times

```{r fig-looking-times}
#| label: fig-looking-times
#| fig-height: 8
#| fig-width: 8
#| fig-cap: "Looking time (s) to the prime and target AOI against audio duration. In longer audios, participants are expected to look longer to the prime and target picture."

looking_times |>
	left_join(select(attrition_trials, 
					 filename, trial, is_valid_trial),
			  by = join_by(filename, trial)) |>
	filter(is_valid_trial) |> 
	ggplot(aes(duration,
			   prime_time,
			   colour = trial_type, 
			   fill = trial_type,
			   shape = trial_type)) +
	facet_grid(lp~age_group) +
	geom_point(alpha = 0.5, 
			   size = 1) +
	geom_smooth(method = "lm") +
	theme(axis.title.x = element_blank()) +
	
	looking_times |>
	left_join(select(attrition_trials, 
					 filename, trial, is_valid_trial),
			  by = join_by(filename, trial)) |>
	filter(is_valid_trial) |> 
	ggplot(aes(duration,
			   target_time,
			   colour = trial_type, 
			   fill = trial_type,
			   shape = trial_type)) +
	facet_grid(lp~age_group) +
	geom_point(alpha = 0.5,
			   size = 1) +
	geom_smooth(method = "lm",
				formula = "y ~ x") +
	plot_layout(ncol = 1, guides = "collect") &
	plot_annotation(tag_levels = "A") &
	labs(x = "Audio duration (s)",
		 y = "Looking time (1.0-2.0 seconds)",
		 colour = "Prime type",
		 fill = "Prime type",
		 shape = "Prime type") 
```


## Appendix D: vocabulary checklist validity

```{r fig-validity-target}
gaze_tmp <- gaze |> 
	filter(phase=="Target-Distractor",
		   between(timestamp, time_subset[1], time_subset[2])) |> 
	select(session_id, trial, phase, timestamp,
		   is_gaze_target, is_gaze_distractor, trial_type) |> 
	mutate(condition = recode_condition(trial_type))

vocabulary_tmp <- rename_with(vocabulary,  
							  \(x) gsub("_prop", "", paste0("voc_", x)), 
							  matches("_prop"))

participants_tmp <- participants |> 
	select(child_id, session_id, age_group, age, lp)

attrition_trials_tmp <- get_attrition_trials(
	participants = participants,
	vocabulary = vocabulary,
	vocabulary_by = c("target"),
	aoi_coords = aoi_coords,
	gaze = gaze,
	min_looking = c(prime = 0.75,
					test = 1.00,
					test_each = 0.00,
					test_any = 0.1)) |> 
	select(session_id, trial, samples, is_valid_vocab_all) |> 
	unnest_wider(is_valid_vocab_all) |> 
	rename_with(\(x) gsub("is_valid_vocab_", "", x)) 

attrition_participants_tmp <- attrition_participants |> 
	filter(is_valid_participant) |> 
	select(session_id)

data <- gaze_tmp |>
	inner_join(attrition_trials_tmp, by = join_by(session_id, trial)) |> 
	inner_join(attrition_participants_tmp, by = join_by(session_id)) |> 
	mutate(condition = recode_condition(trial_type)) |> 
	select(session_id, trial, condition, is_gaze_target, is_gaze_distractor,
		   is_valid_vocab_all) |> 
	# aggregated across trials by participant, time bin and condition
	# see Chow et al. (2018)
	summarise(sum_target = sum(is_gaze_target, na.rm = TRUE),
			  sum_distractor = sum(is_gaze_distractor, na.rm = TRUE),
			  .nsamples = sum(is_gaze_target | is_gaze_distractor, na.rm = TRUE),
			  .ntrials = length(unique(trial)),
			  .by = c(session_id, condition, is_valid_vocab_all)) |> 
	# empirical logit with adjustment
	# see Barr et al. (2008)
	mutate(.nsamples = sum_target + sum_distractor,
		   .prop = ifelse(.nsamples==0, 0, sum_target / .nsamples),
		   .elog = log((sum_target + .5)/(sum_distractor + .5))) |> 
	rename(.sum = sum_target) |> 
	arrange(desc(session_id), condition) |> 
	inner_join(participants_tmp, by = join_by(session_id)) |> 
	inner_join(vocabulary_tmp, by = join_by(child_id, session_id)) |> 
	mutate(across(c(.nsamples), as.integer),
		   across(c(child_id, session_id, lp, condition, age_group), as.factor),
		   across(c(age, voc_l1),
		   	   \(x) scale(x, scale = TRUE)[, 1],
		   	   .names = "{.col}_std")) |> 
	select(child_id, session_id, age_group, age, voc_l1, voc_total, lp,
		   condition,  .sum, .prop, .elog, .nsamples,
		   matches("std"), is_valid_vocab_all) 

# set a priori contrasts
contrasts(data$condition) <- cbind(c(-0.5, 0.5, 0),
								   c(0, -0.5, 0.5))
contrasts(data$lp) <- cbind(c(-0.5, 0.25, 0.25),
							c(0, -0.5, 0.5))
contrasts(data$age_group) <- cbind(c(-0.5, 0.5, 0),
								   c(0, -0.5, 0.5))

data |> 
	unnest_wider(is_valid_vocab_all) |>
	rename_with(\(x) gsub("is_valid_vocab_", "", x)) |> 
	select(session_id, lp, .elog, target) |> 
	arrange(session_id, target) |> 
	summarise(.elog_mean = mean(.elog),
			  .elog_sd = sd(.elog),
			  n = n(),
			  .by = c(lp, target)) |> 
	mutate(target = ifelse(target, "Yes", "No"),
		   .elog_se = .elog_sd/sqrt(n),
		   .elog_lower = .elog_mean - .elog_se*1.96,
		   .elog_upper = .elog_mean + .elog_se*1.96,
	) |> 
	ggplot(aes(lp, .elog_mean, 
			   ymin = .elog_lower,
			   ymax = .elog_upper,
			   colour = target)) +
	facet_wrap(~lp, ncol = 1, scales = "free_x") +
	geom_errorbar(width = 0.2, linewidth = 3/4, 
				  position = position_dodge(width = 0.25)) +
	geom_point(size = 2,
			   position = position_dodge(width = 0.25)) +
	geom_hline(yintercept = 0,
			   linetype = "dashed") +
	labs(x = "Condition",
		 y = "P(Target looking)", 
		 colour = "Knows the target word") +
	theme(legend.position = "none",
		  panel.grid.major.y = element_line(colour = "grey",
		  								  linetype = "dotted")) 

get_data_time(gaze = gaze,
			  participants = participants,
			  stimuli = stimuli,
			  vocabulary = vocabulary,
			  attrition_trials = attrition_trials,
			  attrition_participants = attrition_participants,
			  time_subset = c(0, 2),
			  contrast = "related",
			  is_valid_vocab_all,
			  clean = FALSE) |> 
	unnest_wider(is_valid_vocab_all) |>
	select(session_id, age, lp, timebin, .elog, target) |> 
	arrange(session_id, target) |> 
	summarise(.elog_mean = mean(.elog),
			  .elog_sd = sd(.elog),
			  n = n(),
			  .by = c(timebin, lp, target)) |> 
	mutate(target = ifelse(target, "Yes", "No"),
		   .elog_se = .elog_sd/sqrt(n),
		   .elog_lower = .elog_mean - .elog_se*1.96,
		   .elog_upper = .elog_mean + .elog_se*1.96,
	) |> 
	ggplot(aes(timebin, .elog_mean,
			   ymin = .elog_lower,
			   ymax = .elog_upper,
			   colour = target,
			   fill = target)) +
	facet_wrap(~lp, ncol = 1, scales = "free_x") +
	geom_line(linewidth = 1/2) +
	geom_ribbon(alpha = 1/2,
				colour = NA) +
	geom_point(size = 2) +
	geom_hline(yintercept = 0,
			   linetype = "dashed") +
	labs(x = "Condition",
		 y = "P(Target looking)", 
		 fill = "Knows the target word",
		 colour = "Knows the target word") +
	theme(legend.position = "top",
		  panel.grid.major.y = element_line(colour = "grey",
		  								  linetype = "dotted"),
		  axis.title.y = element_blank(),
		  axis.line.x = element_line()) +
	
	plot_layout(ncol = 2,
				widths = c(0.2, 0.8)) &
	scale_y_continuous(limits = c(-0.5, 1.25))
```

