---
author: "Gonzalo García-Castro"
date: "25/01/2021"
output: html_document
bibliography: "../../references.bib"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = TRUE,
	warning = TRUE, 
	cache.extra = knitr::rand_seed,
	out.width = "80%",
	results = "asis",
	dpi = 300,
	dev.args = list(png = list(type = "cairo"))
)
options(
	knitr.kable.NA = '-',
	knitr.duplicate.label = "allow",
	ggplot2.discrete.fill = ggsci::pal_futurama()(7),
	ggplot2.discrete.colour = ggsci::pal_futurama()(7)
)


```



```{r params, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

# load objects
tar_load_globals()
tar_load_all()

theme_set(theme_minimal()) # in utils.R

attrition <- attrition %>% 
	mutate(
		valid_gaze = valid_gaze_prime & valid_gaze_target,
		valid_status = case_when(
			!valid_vocab ~ "Invalid vocabulary",
			!valid_gaze ~ "Invalid gaze",
			!valid_participant ~ "Invalid participant",
			TRUE ~ "Valid"
		))


participants <- participants %>% 
	left_join(distinct(attrition, participant, valid_participant)) %>% 
	drop_na(participant) %>% 
	left_join(vocabulary) %>% 
	mutate(
		vocab_size_l1_center = scale(vocab_size_l1)[,1],
		vocab_size_total_center = scale(vocab_size_total)[,1]
	)


```

## Background

Infants learning two languages face the challenge of having to learn two distinct sets of words. Some of the words across both languages refer to similar concepts: for instance, *chair* and *silla* (in Spanish). These pairs of words are called *translation equivalents*. Sometimes, translation equivalents also overlap in form, frequently due to their shared etymological origin. These form-similar translation equivalents, such as *boot* and *bota* (in Spanish), are referred to as *cognates*.

There is extensive literature on how cognateness impacts the dynamics of lexical access during words comprehension and production. One of its main findings is that bilinguals process cognates (such as *boot* and *bota*) more differently than non-cognates (such as *chair* and *silla*). For instance, @costa2000cognate asked Spanish-Catalan bilinguals to name a series of familiar pictures in Spanish. Part of the pictures referred to objects whose labels in Spanish and Catalan were cognates, whereas the other pictures referred to non-cognates. On average, participants named cognate pictures faster than non-cognate pictures. This effect was independent of lexical frequency and, critically, was not observed when Spanish monolinguals performed the same task. This suggests that bilinguals activated labels in both languages, and that their phonology interacted to facilitate naming.

Later studies provided evidence that the locus of this facilitation effect was at the lexical level, and not just at the articulatory level [reference needed here]: this effect has also been reported during comprehension, at both the visual-orthographic and the auditory-phonology modalities) [e.g., @thierry2007brain]. Overall, these findings have led researchers to hypothesise that lexical access is language-non selective, that is, bilinguals activate lexical representations in both languages in parallel during comprehension and production, based on their semantic and phonological overlap.

This cross-talk between languages has also been suggested to be present in children's and toddlers' lexicon [@von2012language; @bosma2020cognate], but it is still unclear how it impacts the trajectories of language acquisition at these early ages. In this study we sought to investigate the developmental trajectories of lexical access in a cohort of Catalan-Spanish and English-Spanish bilinguals.

To do this, we used an adaptation of @mani2010infant's priming paradigm. This paradigm consists of a spoken word recognition task in which participants are first presented with a picture in silence in the centre of the screen for 1.5 seconds. Then, two other pictures are presented side-by-side during 2 seconds, and one of them is named. The other is not. Looking times to the target picture are recorded from name onset. From now on, I will refer to the silent picture presented first as the *prime*, to the named picture as the *target*, and to the non-named picture presented next to the target as *distractor*. 

In their experiment, Mani and Plunkett manipulated the phonological overlap between the prime label and the target label: in some trials, both labels shared phonological onset (*bee*-*ball*), whereas in other trials they did not share phonological onset (*cow*-*book*). In all trials, the distractor label did not share onset with either of the prime or target labels (e.g., *teeth*). The authors registered 18 month-old participants' looking preference for the target object after name onset, as a proxy of word recognition, and found that target preference was stronger after a phonologically related prime than after a phonologically unrelated prime. There results have three main implications:

1) Phonologically related prime pictures facilitated target recognition
2) This is only possible if participants lexicalised the prime pictures, even though this picture was presented in silence
3) The label participants generated upon prime picture presentation was phonologically detailed, and this phonological form interacted with the auditory recognition of a subsequently presented word

In a subsequent study, the authors found the inverse effect in 24 month-old toddlers: target looking preference was weaker after a phonologically related prime picture compared to after an unrelated one [@mani2011phonological]. The authors suggested that the change in the direction of the effect observed between 18 and 24 month-old participants was due to the increment in vocabulary size and the establishment of (inhibitory) links between phonologically related lexical entries that might have occurred between both ages. Supporting this account, the inhibition effect they reported was stronger as the number of phonological neighbours of the target increased: the recognition of words surrounded by more phonologically related neighbours suffered the most from the priming effect.

We adapted this paradigm to test the language-non selectivity account in bilingual toddlers. Following Mani & Plunkett's original implementation, In our task half of the prime-target pairs in the trial lists shared phonological onset, and the other half did not share phonological onset. We added a novel manipulation: half of the primes in the phonologically related condition were cognates and the other half were non-cognates. We classified two translation equivalents as cognates if they shared phonological onset. Here is an illustration of each trial type:

```{r trials, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

design <- tribble(
	~trial_type, ~prime, ~target, ~distractor,
	"Cognate (N = 8)", "flower (flor)", "fork", "balloon",
	"Non-cognate (N = 8)", "tree (árbol)", "truck", "phone",
	"Unrelated (N = 16)", "penguin (pingüino)", "table", "shoe"
) %>% 
	gt() %>% 
	cols_label(
		trial_type = "Prime type",
		prime = "Prime",
		target = "Target",
		distractor = "Distractor"
		
	)

gtsave(design, here("presentations", "2022-01-25_lacre", "img", "design.png"))
```


This is what a trial looks like [see figure below]:

![](img/task.png)

## Hypotheses

If participants lexicalise the prime pictures in a language-non selective way, they should generate two labels upon prime picture presentation: one in each language. Therefore, if lexical access is language non-selective, in cognate trials two prime labels should interfere with target recognition (since both prime labels share onset with the target). In non-cognate trials, only one prime label should interfere with the target. Finally, in unrelated trials no prime labels should interfere with the target. As a result, we expect bilingual participants' target looking preference to be weaker in cognate trials than in non-cognate trials, and in cognate and non-cognate trials than in unrelated trials.

![](img/diagram.png)

We also collected data from same-aged monolingual participants as a control group: in this group we also expect to find weaker target looking in cognate and non-cognate trials, compared to unrelated trials, but no differences between cognate and non-cognate trials (these participants should be insensitive to the cognate status of the primes).


## Participants

We planned to collect data from participants learning English and/or Spanish in Oxford, and from participants learning Catalan and/or Spanish in Barcelona. Due to limitations imposed by the pandemic and lockdown, data collection in Oxford was severely interrupted, so I will present preliminary data from participants tested in Barcelona exclusively. 

We tested participants at three age points: 21, 25, and 30 months, to explore their trajectories of lexical access through these sensitive ages in which participants' vocabulary size is growing a full speed [Reference here.]

We classified participants as monolinguals or bilinguals by estimating their overall exposure to each of their languages using @bosch2001evidence. Following the consensus reached by the ManyBabies consortium [@byers2021multilab], participants exposed to any languages more than 80% of the time were classified as monolinguals. Otherwise, participants were classified as bilinguals. Participants exposed more than 10% to a third language or a language other than Catalan and Spanish (in Barcelona) or English and Spanish (in Oxford) were excluded from data analysis.

This is how testing sessions are distributed across ages and language profiles:


```{r participants, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
participants_data <- fit_l1$data %>% 
	distinct(participant, lp) %>% 
	left_join(select(participants, participant, age_group, lp, test_language, vocab_size_total, vocab_size_l1))

participants_design <- participants_data %>% 
	count(participant, lp, name = "n_sessions") %>% 
	mutate(is_longitudinal = n_sessions > 1) %>% 
	left_join(select(participants_data, participant, age_group, lp)) %>% 
	count(age_group, lp, is_longitudinal, name ="n_longitudinal") %>% 
	filter(is_longitudinal)

participants_tab <- participants_data %>% 
	count(age_group, lp) %>%
	left_join(participants_design) %>% 
	filter(is_longitudinal) %>% 
	mutate(n_label = paste0(n, " (", n_longitudinal, ")")) %>% 
	select(age_group, lp, n_label) %>% 
	pivot_wider(names_from = age_group, values_from = n_label) %>% 
	rowwise() %>% 
	# mutate(N = sum(`n_21 months`, `n_25 months`, `n_30 months`)) %>% 
	ungroup() %>% 
	relocate(lp) %>% 
	gt() %>% 
	cols_label(lp = "Group") %>% 
	# summary_rows(columns = 2:4, fns = list(N = "sum"), decimals = 0)
	tab_source_note(md("(*) The number of longitudinal participants in each <br>group is indicated between parentheses.")) %>% 
	tab_style(
		cell_text(weight = "bold"),
		cells_column_labels()
	)

gtsave(participants_tab, here("presentations", "2022-01-25_lacre", "img", "participants_tab.png"))




n_total <- participants %>% 
	left_join(distinct(attrition, participant, age_group, valid_participant)) %>% 
	filter(location=="Barcelona", valid_participant) %>% 
	distinct(participant) %>% 
	count()

n_total_cohort <- participants %>% 
	left_join(distinct(attrition, participant, age_group, valid_participant)) %>% 
	filter(location=="Barcelona", valid_participant) %>% 
	distinct(participant, age_group) %>%
	count(participant) %>% 
	count(n, name = "n_cohort") %>% 
	group_split(n)

```

These 156 testing sessions correspond to `r n_total$n` distinct participants. Of these participants, `r n_total_cohort[[1]]` only participated once (I will refer top these participants as cross-sectional participants), `r n_total_cohort[[2]]` participated twice, and `r n_total_cohort[[3]]` participated three times.


## Vocabulary

```{r vocabulary_total, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=4}
sample_size <- participants %>% 
	filter(participant %in% fit_total$data$participant) %>% 
	count(age_group, location)

sample_size_lp <- participants %>% 
	filter(participant %in% fit_total$data$participant) %>% 
	count(age_group, lp, location) %>% 
	mutate(
		lp_label = paste0(lp, " (N = ", n, ")"),
		age_group_label = case_when(
			age_group=="21 months" ~ paste0(age_group, " (N = ", sample_size$n[1], ")"),
			age_group=="25 months" ~ paste0(age_group, " (N = ", sample_size$n[2], ")"),
			age_group=="30 months" ~ paste0(age_group, " (N = ", sample_size$n[3], ")")
		)
	) 

# vocabulary
participants %>% 
	drop_na(lp) %>%
	filter(valid_participant) %>% 
	select(participant, lp, age_group, vocab_size_l1, vocab_size_total) %>% 
	pivot_longer(c(vocab_size_l1, vocab_size_total), names_to = "measure", values_to = "value") %>% 
	left_join(sample_size_lp) %>% 
	mutate(
		measure = str_replace_all(measure, c("vocab_size_l1" = "L1", "vocab_size_total" = "Total"))
	) %>% 
	ggplot() +
	aes(lp, value, color = lp, fill = lp) +
	facet_grid(measure~age_group) +
	geom_hline(yintercept = 0.5, colour = "black", linetype = "dotted") +
	stat_slab(position = position_dodge(width = 0.75), slab_color = "white", slab_size = 1) +
	# geom_violin(position = position_dodge(width = 1)) +
	stat_pointinterval(
		position = position_dodge(width = 0.75),
		.width = c(0.95, 0.89, 0.50),
		point_size = 2,
		color = "black"
	) +
	# geom_point(
	# 	size = 1,
	# 	alpha = 0.5
	# ) +
	# geom_text(
	# 	data = sample_size_lp,
	# 	aes(x = 1.5, y = 0, label = paste0("N = ", n), group = lp),
	# 	show.legend = FALSE, position = position_dodge(width = 2),
	# 	inherit.aes = FALSE
	# ) +
	labs(
		y = "Receptive vocabulary", colour = "Group", fill = "Group",
		title = "Vocabulary size",
		subtitle = "Percentage of words reported to be understood from the vocabulary checklist"
	) +
	guides(colour = "none") +
	scale_color_manual(aesthetics = "slab_color", values = pal_futurama()(2)) +
	scale_y_continuous(limits = c(0, 1), labels = percent) +
	theme(
		legend.title = element_blank(),
		legend.position = c(0.5, 0.6),
		panel.grid.major.x = element_blank(),
		axis.title.x = element_blank(),
		axis.text = element_text(size = 9),
		panel.border = element_rect(fill = NA, color = "grey")
	)

ggsave(here("presentations", "2022-01-25_lacre", "img", "vocab_all.png"), dpi = 600)
```


## Data analysis

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
n_obs <- nrow(fit_l1$data)

n_trials_total <- distinct(fit_l1$data, participant, target, trial_type) %>% 
	count() %>% 
	pull(n)

n_trials <- distinct(gaze, participant, trial, trial_type) %>% 
	count(trial_type) %>% 
	pull(n, name = trial_type)
```


```{r participants_lp, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

participants_data

```

In each testing session, participants were presented with 32 trials (8 cognate, 8 non-cognate and 16 unrelated). In each trial, we used an eye-tracker to register participants' looking time to the target picture. We delimited a time window of interest between 250 ms after the target onset and 150 ms before the target offset. This resulted in a 1,500 ms long time window. We divided this time window into 15 time bins of 100 ms each, and calculated the adjusted logit of the samples in which participants' gaze was located in the target coordinates, out of the total of valid samples in that time bin. This resulted in 15 observations per participant, per age group, and per trial. Our final dataset comprised `r n_obs` data points from `r n_trials_total` distinct trials: `r n_trials["Cognate"]`, cognate trials, `r n_trials["Non-cognate"]` trials, and `r n_trials["Unrelated"]` trials.

To model these data we used Growth Curve Analysis [@mirman2017growth]. First, we included `time_bin` as a fixed effect in our model to account for the correlation between the data points collected within each trial. We included this variable as a third degree polynomial, in order to account for the possibly non-linearity of the target fixations across the same trial (target fixations might increase rapidly at the beginning of the trial and decrease at the end of it. We then included our predictors of interest: age group (`age_group`), language profile (`lp`), trial type (`trial_type`), and the two-way interaction between language profile and trial type. Finally, we added random intercepts and slopes by participant and by target picture, to account for the possible correlation between time series from the same participant or trial (more details of the model at the end).

We estimated our model using the Bayesian framework, under which we estimate the probability of each value of the sampling space of each parameter, given the data we have observed. to do this, we used the brms R package [@burkner2017brms].


# Results

## Model comparison

```{r model-comparison, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

waics_l1 %>% 
	map("estimates") %>% 
	map(function(x) as.data.frame(x) %>% rownames_to_column("variable")) %>% 
	bind_rows(.id = "model") %>%
	clean_names() %>% 
	pivot_wider(names_from = variable, values_from = c(estimate, se)) %>% 
	relocate(model, matches("estimate"), matches("elpd"), matches("_p_")) %>% 
	gt() %>% 
	fmt_number(-model) %>% 
	tab_spanner("WAIC", matches("waic")) %>% 
	tab_spanner(md("WAIC<sub>ELPD</sub>"), matches("elpd")) %>% 
	tab_spanner(md("WAIC<sub>*p*</sub>"), matches("_p_")) %>% 
	cols_label(
		model = "Model",
		estimate_elpd_waic = "Estimate",
		estimate_waic = "Estimate",
		estimate_p_waic = "Estimate",
		se_elpd_waic = md("*SE*"),
		se_waic = md("*SE*"),
		se_p_waic = md("*SE*"),
	) %>% 
	as_raw_html()


```


## Fixed effects


```{r fixed_effects_table, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
str_repl <- c(
	
	# 3-way interactions
	"b_time_bin_center:trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab (total)",
	"b_time_bin_center:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab (L1)",
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_l1_center" =
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab (L1)",
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_l1_center" =
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab (L1)",
	
	# 2-way interactions
	"b_time_bin_center:trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (L1)",
	"b_time_bin_center:trial_typePrimeNCvs.C:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (L1)",
	
	"b_time_bin_center:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_time_bin_center:trial_typePrimeNCvs.C:lpLPMonvs.Bil" = 
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_time_bin_center:trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (L1)",
	"b_time_bin_center:trial_typePrimeNCvs.C:vocab_size_l1_center" =
		"Trial type (C vs. NC) \u00d7 Vocab (L1)",
	
	"b_time_bin_center:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" =
		"Trial type (U vs. C+NC) \u00d7 Group",  
	"b_time_bin_center:lpLPMonvs.Bil:vocab_size_l1_center" =
		"Group \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (L1)",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:lpLPMonvs.Bil" =
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (L1)",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",  
	"b_Itime_bin_centerE2:lpLPMonvs.Bil:vocab_size_l1_center" = 
		"Group \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (L1)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:lpLPMonvs.Bil" = 
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab (L1)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab (L1)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",  
	"b_Itime_bin_centerE3:lpLPMonvs.Bil:vocab_size_l1_center" = 
		"Group \u00d7 Vocab (L1)",
	
	
	# main effects (linear)
	"b_time_bin_center:trial_typePrimeUvs.CPNC" =
		"Trial type (U vs. C+NC)",
	"b_time_bin_center:trial_typePrimeNCvs.C" = 
		"Trial type (C vs. NC)",
	"b_Itime_bin_centerE2:trial_typePrimeUvs.CPNC" = 
		"Trial type (U vs. C+NC)",
	"b_Itime_bin_centerE2:trial_typePrimeNCvs.C" = 
		"Trial type (C vs. NC)",
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC" = 
		"Trial type (U vs. C+NC)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C" = 
		"Trial type (C vs. NC)",
	
	"b_time_bin_center:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	"b_Itime_bin_centerE2:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	"b_Itime_bin_centerE3:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	
	"b_time_bin_center:vocab_size_l1_center" = 
		"Vocab. (L1, +1 SD)",
	"b_Itime_bin_centerE2:vocab_size_l1_center" = 
		"Vocab. (L1, +1 SD)",
	"b_Itime_bin_centerE3:vocab_size_l1_center" = 
		"Vocab. (L1, +1 SD)",
	
	
	# 3-way interaction linear effects
	"b_trial_typePrimeUvs.CPNC:lpLPMonvs.Bil:vocab_size_l1_center" =
		"Trial type (U vs. C+NC) \u00d7 Group \u00d7 Vocab. (L1, +1 SD)",
	"b_trial_typePrimeNCvs.C:lpLPMonvs.Bil:vocab_size_l1_center" =
		"Trial type (C vs. NC) \u00d7 Group \u00d7 Vocab. (L1, +1 SD)",
	
	# 2-way interaction linear effects
	"b_trial_typePrimeUvs.CPNC:lpLPMonvs.Bil" = 
		"Trial type (U vs. C+NC) \u00d7 Group",
	"b_trial_typePrimeNCvs.C:lpLPMonvs.Bil" = 
		"Trial type (C vs. NC) \u00d7 Group",
	
	"b_trial_typePrimeUvs.CPNC:vocab_size_l1_center" = 
		"Trial type (U vs. C+NC) \u00d7 Vocab. (L1, +1 SD)",
	"b_trial_typePrimeNCvs.C:vocab_size_l1_center" = 
		"Trial type (C vs. NC) \u00d7 Vocab. (L1, +1 SD)",
	
	
	"b_lpLPMonvs.Bil:vocab_size_l1_center" =
		"Group \u00d7 Vocab. (L1, +1 SD)",
	
	"b_Itime_bin_centerE3:trial_typePrimeUvs.CPNC" =
		"Trial type (U vs. C+NC)",
	"b_Itime_bin_centerE3:trial_typePrimeNCvs.C" =
		"Trial type (C vs. NC)",
	
	"b_Itime_bin_centerE3:lpLPMonvs.Bil" = 
		"Group (Mon. vs. Bil.)",
	
	# main linear effects
	"b_Intercept" = "Intercept",
	"b_Itime_bin_centerE2" = "Time bin 2",
	"b_Itime_bin_centerE3" = "Time bin 3",
	"b_time_bin_center" = "Time bin",
	"b_vocab_size_l1_center" = "Vocab. (L1, +1 SD)",
	
	"b_trial_typePrimeUvs.CPNC" = "Trial type (U vs. C+NC)",
	"b_trial_typePrimeNCvs.C" = "Trial type (C vs. NC)",
	"b_lpLPMonvs.Bil" = "Group (Mon. vs. Bil.)",
	
	# sigma
	"sigma" = "Sigma"
)





draws <- gather_draws(fit_l1, `b_.*`, `sigma`, regex = TRUE) %>% 
	mutate(
		.value = ifelse(.variable=="sigma", inv_logit(.value), .value),
		.variable_name = str_replace_all(.variable, str_repl),
		type = case_when(
			str_detect(.variable, "E2") ~ "Quadratic time",
			str_detect(.variable, "E3") ~ "Cubic time",
			str_detect(.variable, "time_bin") ~ "Linear time",
			str_detect(.variable, "sigma") ~ "Error",
			TRUE ~ "Main effects"
		) %>% 
			factor(levels = c("Main effects", "Linear time", "Quadratic time", "Cubic time", "Error"), ordered = TRUE)
	)

```


```{r main_effects_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.height=10, fig.width=10}

draws_intercept <- draws %>% 
	filter(str_detect(.variable, "Intercept")) %>% 
	ggplot(aes(.value, .variable_name)) +
	geom_vline(xintercept = 0.5, colour = "black", linetype = "dashed") +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		size = 0.5, slab_size = 1,
		color = "white",
		fill = "#FF6F00FF"
	) +
	labs(
		x = "Value", 
		y = "Variable", 
		fill = "CrI", 
		title = "Intercept",
		alpha = "CrI"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent, limits = c(0, 1)) +
	theme(
		axis.title.y = element_blank(),
		panel.grid.major.y = element_blank()
	)

ggsave(
	here("presentations", "2022-01-25_lacre", "img", "post_intercept.png"), 
	draws_intercept, 
	height = 2,
	width = 7,
	dpi = 600
)


predictors_order <- c(
	"Trial type (U vs. C+NC)",
	"Trial type (C vs. NC)",
	"Group (Mon. vs. Bil.)",
	"Vocab. (total, +1 SD)",
	"Trial type (U vs. C+NC) × Group",
	"Trial type (C vs. NC) × Group",
	"Trial type (U vs. C+NC) × Vocab. (total, +1 SD)",
	"Trial type (C vs. NC) × Vocab. (total, +1 SD)",
	"Group × Vocab. (total, +1 SD)",
	"Trial type (U vs. C+NC) × Group × Vocab. (total, +1 SD)",
	"Trial type (C vs. NC) × Group × Vocab. (total, +1 SD)"
)

draws_predictors <- draws %>% 
	filter(str_detect(.variable, "Intercept|sigma|sd|time_bin", negate = TRUE)) %>% 
	mutate(.variable_name = factor(.variable_name, levels = predictors_order, ordered = TRUE)) %>% 
	ggplot(aes(.value, fct_rev(.variable_name))) +
	geom_vline(xintercept = 0, colour = "black", linetype = "dashed") +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(0.95, 0.8, 0.5), labels = percent_format()))),
		size = 0.5, 
		color = "white", 
		fill = "#C71000FF"
	) +
	labs(
		x = "Value", 
		y = "Variable", 
		fill = "CrI", 
		alpha = "CrI",
		title = "Main effects"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent, limits = c(-0.4, 0.4)) +
	theme(
		axis.title.y = element_blank(),
		panel.grid.major.y = element_blank()
	) 


ggsave(
	here("presentations", "2022-01-25_lacre", "img", "post_predictors.png"), 
	draws_predictors, 
	height = 7,
	width = 7,
	dpi = 600
)


predictors_order <- c(
	"Time bin",
	"Time bin 2",
	"Time bin 3",
	"Trial type (U vs. C+NC)",
	"Trial type (C vs. NC)",
	"Group (Mon. vs. Bil.)",
	"Vocab. (total, +1 SD)",
	"Trial type (U vs. C+NC) × Group",
	"Trial type (C vs. NC) × Group",
	"Trial type (U vs. C+NC) × Vocab (total)",
	"Trial type (C vs. NC) × Vocab (total)",
	"Group × Vocab (total)",
	"Trial type (U vs. C+NC) × Group × Vocab (total)",
	"Trial type (C vs. NC) × Group × Vocab (total)"
)

draws_time <- draws %>%
	filter(str_detect(.variable, "time_bin")) %>% 
	mutate(.variable_name = factor(.variable_name, levels = predictors_order, ordered = TRUE)) %>%
	ggplot(aes(.value, fct_rev(.variable_name))) +
	facet_wrap(~type, scales = "free_x") +
	geom_vline(xintercept = 0, colour = "black", linetype = "dashed") +
	stat_interval(size = 3, labels = percent_format()) +
	# stat_pointinterval(
	# 	color = "#008EA0FF",
	# 	fill = "#008EA0FF",
	# 	point_size = 1.5
	# ) +
	labs(
		x = "Value", 
		y = "Variable", 
		fill = "CrI", 
		color = "CrI",
		alpha = "CrI",
		title = "Polynomial effects"
	) +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_color_manual(values = c("#b7eded", "#4cb0b0", "#007373"), ) +
	scale_x_continuous(labels = percent) +
	theme(
		axis.title.y = element_blank(),
		panel.grid.major.y = element_blank(),
		panel.border = element_rect(fill = NA, color = "grey")
	) 


ggsave(
	here("presentations", "2022-01-25_lacre", "img", "post_poly.png"), 
	draws_time, 
	height = 5,
	width = 9,
	dpi = 600
)

draws_sigma <- draws %>% 
	filter(str_detect(.variable, "sigma")) %>% 
	ggplot(aes(.value, .variable_name)) +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		size = 0.5, 
		color = "#8A4198FF", 
		fill = "#8A4198FF"
	) +
	labs(
		x = "Value", 
		y = "Variable", 
		alpha = "CrI",
		fill = "CrI", 
		title = "Error"
	) +
	guides(fill = "none", color = "none") +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_fill_brewer(direction = -1, na.translate = FALSE) +
	scale_x_continuous(labels = percent, limits = c(0.92, 0.97)) +
	theme(
		axis.title.y = element_blank(),
		panel.grid.major.y = element_blank()
		
	) 

ggsave(
	here("presentations", "2022-01-25_lacre", "img", "post_sigma.png"), 
	draws_sigma, 
	height = 2,
	width = 7,
	dpi = 600
)


((draws_intercept / draws_sigma / guide_area()) | draws_predictors) /
	draws_time + 
	plot_layout(heights = c(0.5, 0.5)) &
	guides(fill = "none", color = "none") &
	theme(
		panel.background = element_rect(fill = NA, colour = "grey"),
		axis.text.y = element_text(size = 7),
		axis.text.x = element_text(size = 7),
		axis.title = element_blank(),
		legend.position = c(1, 1.2),
		legend.direction = "horizontal",
		legend.justification = "right",
		legend.key.size = unit(0.35, "cm"),
		legend.text = element_text(size = 7),
		legend.title = element_text(size = 7),
		panel.grid.major.y = element_blank()
	)

```







## Margin means

### Posterior predictions (after seeing the data)

```{r gaze_time, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=6, fig.width=11}
sample_size <- participants %>% 
	filter(valid_participant) %>% 
	count(lp, vocab_size_l1_center)

n <- expand_grid(
	lp = c("Monolingual", "Bilingual"),
	vocab_size_l1_center = c(-1, 0, 1),
	trial_type = unique(gaze$trial_type),
	time_bin_center = seq(min(gaze$time_bin_center), max(gaze$time_bin_center), 0.1)
)

m <- epred_draws(object = fit_l1, newdata = n, ndraws = 50, re_formula = NA) %>% 
	mutate(
		.value = logit_to_prob(.epred),
		vocab_size_l1_center = case_when(
			vocab_size_l1_center==-1 ~ "Low vocabulary size (-1 SD)",
			vocab_size_l1_center==1 ~ "High vocabulary size (+1 SD)",
			vocab_size_l1_center==0 ~ "Mean vocabulary size (0 SD)"
		) %>% 
			factor(levels = c(
				"Low vocabulary size (-1 SD)",
				"Mean vocabulary size (0 SD)",
				"High vocabulary size (+1 SD)"
			), ordered = TRUE)
	)

ggplot(m, aes(time_bin_center, .value)) +
	facet_grid(fct_rev(lp)~vocab_size_l1_center) +
	geom_hline(yintercept = 0.5, colour = "black") +
	geom_line(
		aes(group = interaction(vocab_size_l1_center, trial_type, lp, .draw),
			colour = trial_type),
		alpha = 0.5, size = 0.65
	) +
	labs(x = "Time bin (100 ms)", y = "Expected posterior mean PTLT", colour = "Trial type",
		 fill = "Trial type", shape = "Trial type", linetype = "Trial type") +
	scale_color_futurama() +
	scale_x_continuous(
		breaks = min(gaze$time_bin_center):max(gaze$time_bin_center), 
		labels = 1:20
	) +
	scale_y_continuous(limits = c(0, 1), labels = percent) + 
	theme_minimal() +
	theme(
		legend.position = "top",
		legend.title = element_blank(),
		axis.text.x = element_text(size = 7),
		panel.grid.major.x = element_blank(),
		panel.grid.minor.x = element_blank(),
		panel.background = element_rect(fill = "white", colour = NA),
		plot.background = element_rect(fill = "white", colour = NA)
	) 

```


## Marginal means {.tabset }

```{r gaze_marginal, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=4, fig.width=9}

m <- emmeans(fit_l1, ~trial_type | lp, epred = TRUE) 

m_draws <- gather_emmeans_draws(m) %>% 
	mutate(.value = logit_to_prob(.value)) %>% 
	as_tibble() %>% 
	mutate_at(vars(.value), function(x) ifelse(x < 0, 0, x)) %>% 
	mutate_at(vars(.value), function(x) ifelse(x > 1, 1, x))

ggplot(m_draws, aes(.value, trial_type, colour = trial_type, fill = trial_type)) +
	facet_wrap(~fct_rev(lp)) +
	stat_slab(
		aes(alpha = stat(cut_cdf_qi(cdf, .width = c(.95, .8, .5), labels = percent_format()))),
		color = "white"
	) +
	stat_pointinterval(
		color = "black", 
		position = position_dodge(width = 0.5)
	) +
	labs(
		x = "Expected posterior mean PTLT", y = "Trial type",
		colour = "Trial type", fill = "Trial type",
		alpha = "CrI"
	) +
	scale_alpha_discrete(range = c(0.8, 0.2), na.translate = FALSE) +
	scale_x_continuous(limits = c(0.6, 0.8), labels = percent)  +
	theme(
		axis.title.y = element_blank(),
		legend.position = "right",
		panel.grid.major.y = element_blank(),
		panel.grid.minor.y = element_blank(),
		panel.grid.minor.x = element_blank(),
		panel.background = element_rect(fill = NA, colour = "grey")
	)


```